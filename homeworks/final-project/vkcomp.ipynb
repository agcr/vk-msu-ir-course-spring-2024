{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Импорт используемых библиотек"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:25:38.439106Z","iopub.status.busy":"2024-05-07T13:25:38.438797Z","iopub.status.idle":"2024-05-07T13:25:55.169421Z","shell.execute_reply":"2024-05-07T13:25:55.168509Z","shell.execute_reply.started":"2024-05-07T13:25:38.439079Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting lightning\n","  Downloading lightning-2.2.4-py3-none-any.whl.metadata (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m46.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\n","Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\n","Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\n","Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\n","Requirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\n","Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\n","Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n","Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n","Downloading lightning-2.2.4-py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning\n","Successfully installed lightning-2.2.4\n"]}],"source":["!pip install lightning"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-07T13:27:08.375423Z","iopub.status.busy":"2024-05-07T13:27:08.374846Z","iopub.status.idle":"2024-05-07T13:27:08.381989Z","shell.execute_reply":"2024-05-07T13:27:08.381075Z","shell.execute_reply.started":"2024-05-07T13:27:08.375395Z"},"trusted":true},"outputs":[],"source":["import torch\n","import transformers\n","from torch import nn\n","from torch.utils import data\n","from torch.utils.data import Dataset, Sampler, DataLoader\n","import numpy as np\n","import pandas as pd\n","import random\n","from time import time\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.metrics import roc_auc_score\n","# PyTorch TensorBoard support\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from lightning.pytorch import Trainer\n","from lightning.pytorch.callbacks import ModelCheckpoint\n","\n","import datetime\n","import os\n","\n","import lightning as L\n","\n","import gc"]},{"cell_type":"markdown","metadata":{},"source":["# Данные"]},{"cell_type":"markdown","metadata":{},"source":["Считаем данные и соберем из них тренировочный датафрейм сколонками\n","- qid\n","- query\n","- text\n","- label"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:55:31.982852Z","iopub.status.busy":"2024-05-07T13:55:31.982190Z","iopub.status.idle":"2024-05-07T13:55:31.987807Z","shell.execute_reply":"2024-05-07T13:55:31.986886Z","shell.execute_reply.started":"2024-05-07T13:55:31.982821Z"},"trusted":true},"outputs":[],"source":["data_folder = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024\"\n","docs_file = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024/vkmarco-docs.tsv\"\n","qrels_file = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024/vkmarco-doctrain-qrels.tsv\"\n","queries_file = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024/vkmarco-doctrain-queries.tsv\"\n","\n","submission_queries = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024/vkmarco-doceval-queries.tsv\"\n","submission_qdocs = \"/kaggle/input/text-reranking-competition-ir-msu-spring-2024/sample_submission.csv\""]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T05:46:21.577009Z","iopub.status.busy":"2024-05-07T05:46:21.576574Z","iopub.status.idle":"2024-05-07T05:46:21.597816Z","shell.execute_reply":"2024-05-07T05:46:21.596657Z","shell.execute_reply.started":"2024-05-07T05:46:21.576973Z"},"trusted":true},"outputs":[],"source":["def read_tsv(docs_file, queries_file, qrels_file):\n","    from time import time\n","    start = time()\n","    print(f\"Reading {docs_file}...\")\n","    df_docs = pd.read_csv(docs_file, delimiter='\\t', header=None)\n","    elapsed = time() - start\n","    print(f\"\\tDone! time elapsed: \", elapsed)\n","    \n","    print(f\"Reading {queries_file}...\")\n","    df_queries = pd.read_csv(queries_file, delimiter='\\t', header=None)\n","    elapsed_queries = time() - (start + elapsed)\n","    print(f\"\\tDone! time elapsed: \", elapsed_queries)\n","    \n","    print(f\"Reading {queries_file}...\")\n","    df_qrels = pd.read_csv(qrels_file, delimiter=' ', header=None)\n","    elapsed_qrels = time() - (start + elapsed + elapsed_queries)\n","    print(f\"\\tDone! time elapsed: \", elapsed_qrels)\n","    \n","    return (df_docs, df_queries, df_qrels)\n","\n","def create_base_df(df_docs, df_queries, df_qrels):\n","    # maybe add title to text field\n","    df_docs.rename(columns={0 : 'doc_id', 1 : 'url', 2 : 'title', 3 : 'text'}, inplace=True)\n","    df_docs_droped = df_docs.drop('url', axis=1)\n","\n","    df_queries = df_queries.rename(columns={0: \"qid\", 1: \"query\"})\n","\n","    df_qrels.rename(columns={0:'qid', 1:'unknown', 2:'doc_id', 3:'label'}, inplace=True)\n","    df_qrels_droped = df_qrels.drop(['unknown'], axis=1)\n","    \n","    df_qrels_query = df_qrels_droped.join(df_queries.set_index(['qid']), on='qid')\n","    df_qrels_query_docs = df_qrels_query.join(df_docs.set_index('doc_id'), on='doc_id')\n","    \n","    needed_cols = ['qid', 'query', 'text', 'label']\n","    to_drop = list(set(df_qrels_query_docs) - set(needed_cols))\n","    df_final = df_qrels_query_docs.drop(to_drop, axis=1)\n","    return df_final\n","\n","def create_submission_df(df_docs, df_queries, df_qdocs, with_docid=False):\n","    df_docs.rename(columns={0 : 'doc_id', 1 : 'url', 2 : 'title', 3 : 'text'}, inplace=True)\n","    df_docs_droped = df_docs.drop('url', axis=1)\n","    \n","    df_queries.rename(columns={0: \"qid\", 1: \"query\"}, inplace=True)\n","    \n","    df_qdocs.rename(columns={\"QueryId\":'qid', \"DocumentId\":'doc_id'}, inplace=True)\n","    \n","    df_qdocs_query = df_qdocs.join(df_queries.set_index(['qid']), on='qid')\n","    df_qdocs_query_docs = df_qdocs_query.join(df_docs.set_index('doc_id'), on='doc_id')\n","\n","    needed_cols = ['qid', 'query', 'text']\n","    if with_docid:\n","        needed_cols.append('doc_id')\n","\n","    to_drop = list(set(df_qdocs_query_docs) - set(needed_cols))\n","    df_final = df_qdocs_query_docs.drop(to_drop, axis=1)\n","    return df_final"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_docs, df_queries, df_qrels = read_tsv(docs_file, queries_file, qrels_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df_docs.info())\n","df_docs.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df_queries.info())\n","df_queries.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df_qrels.info())\n","df_qrels.head()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-05T13:12:36.418229Z","iopub.status.busy":"2024-05-05T13:12:36.417628Z","iopub.status.idle":"2024-05-05T13:12:36.429085Z","shell.execute_reply":"2024-05-05T13:12:36.426852Z","shell.execute_reply.started":"2024-05-05T13:12:36.418189Z"}},"source":["Создадим тренировочный датафрейм"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train = create_base_df(df_docs, df_queries, df_qrels)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(df_train.info())\n","df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train.to_csv('df_train.csv', sep='\\t', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Сравним данный датасет с ранее созданным из домашки по nn-rerank"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train = pd.read_csv(\"/kaggle/input/vk-marco-formatted/train/kaggle/working/df_train.csv\",\n","                       delimiter='\\t',\n","                       dtype={'qid':'int32', 'label':'int8', 'text':'str', 'query':'str'})"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T11:29:03.742312Z","iopub.status.busy":"2024-05-06T11:29:03.741772Z","iopub.status.idle":"2024-05-06T11:29:05.704425Z","shell.execute_reply":"2024-05-06T11:29:05.702993Z","shell.execute_reply.started":"2024-05-06T11:29:03.742277Z"},"trusted":true},"outputs":[],"source":["# если сохраненноый df_train не нужен:\n","!rm \"/kaggle/working/df_train.csv\""]},{"cell_type":"markdown","metadata":{},"source":["Создадим датафрейм для сабмита"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_subm_queries = pd.read_csv(submission_queries, delimiter='\\t', header=None)\n","df_subm_qdocs = pd.read_csv(submission_qdocs, delimiter=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_subm_queries, df_subm_qdocs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_subm = create_submission_df(df_docs, df_subm_queries, df_subm_qdocs)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_subm.to_csv(\"df_subm.csv\", sep='\\t', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Попробуем использовать XLM-roBERTa для ранжирования"]},{"cell_type":"markdown","metadata":{},"source":["Обучаем без нулевых лейблов. (По исследованию из прошлой домашки, они составляли ~4% от всего датасета)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:13.490474Z","iopub.status.busy":"2024-05-07T13:27:13.490030Z","iopub.status.idle":"2024-05-07T13:27:13.499872Z","shell.execute_reply":"2024-05-07T13:27:13.498037Z","shell.execute_reply.started":"2024-05-07T13:27:13.490414Z"},"trusted":true},"outputs":[],"source":["class RankDataset(Dataset):\n","    def __init__(self, data, neg_p=1.0, bienc_mode=False):\n","        self.neg_p = neg_p\n","        if self.neg_p < 1.:\n","            self.data = pd.concat([data[data['label'] == 3],\n","                                   data[data['label'] == 2],\n","                                   data[data['label'] == 1].sample(frac=self.neg_p),])\n","        else:\n","            self.data = data\n","        self.bienc_mode = bienc_mode\n","        \n","    def __getitem__(self, index):\n","        query, text, label, qid = self.data.iloc[index, [2, 3, 1, 0]]\n","#         if bienc_mode:\n","#             return query.lower(), text.lower(), label, qid\n","        return [query.lower(), text.lower()], label, qid\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:13.657336Z","iopub.status.busy":"2024-05-07T13:27:13.656526Z","iopub.status.idle":"2024-05-07T13:27:13.663097Z","shell.execute_reply":"2024-05-07T13:27:13.662214Z","shell.execute_reply.started":"2024-05-07T13:27:13.657308Z"},"trusted":true},"outputs":[],"source":["class SubmitDataset(RankDataset):\n","    def __init__(self, data, neg_p=1.0, bienc_mode=False):\n","        super().__init__(data, neg_p, bienc_mode)\n","        \n","    def __getitem__(self, index):\n","        query, text, qid = self.data.iloc[index, [1, 2, 0]]\n","        return [query.lower(), text.lower()], qid\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:14.936029Z","iopub.status.busy":"2024-05-07T13:27:14.935516Z","iopub.status.idle":"2024-05-07T13:27:14.964867Z","shell.execute_reply":"2024-05-07T13:27:14.963857Z","shell.execute_reply.started":"2024-05-07T13:27:14.935999Z"},"trusted":true},"outputs":[],"source":["class VKMarcoDataModule(L.LightningDataModule):\n","    \"\"\"\n","    it needs to be defined before class RankDataset()\n","    and before class BatchSampler() [its going to DataLoader]\n","    \"\"\"\n","    def __init__(self, setup_dir=\"/kaggle/input/vk-marco-formatted\",\n","                       subm_dir=\"/kaggle/input/vkcomp-subm-df\",\n","                       tkn_max_len=64,\n","                       tokenizer_str='xlm-roberta-base',\n","                       batch_size=64,\n","                       test_batch_size=1024,\n","                       skip_prepare=True,\n","                       df_train=None,\n","                       df_test=None,\n","                       bienc_mode=False):\n","        super().__init__()\n","#         self.raw_dir = raw_dir\n","        self.setup_dir = setup_dir\n","        self.subm_dir = subm_dir\n","\n","        # for tokenizer\n","        self.tkn_max_len = tkn_max_len \n","        self.batch_size = batch_size\n","        self.test_batch_size = test_batch_size\n","        self.skip_prepare = skip_prepare\n","        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_str)\n","        self.df_train=df_train\n","        self.df_test=df_test\n","        self.bienc_mode = bienc_mode\n","        \"\"\"\n","        working on kaggle:\n","        if skip_prepare==True, then \n","            df_train and df_test will be readed from \n","            f'{setup_dir}/df_train.csv' and f'{setup_dir}/df_test.csv'\n","        else,\n","            df_train and df_test will be\n","            saved in (if file persistence is not setted) \n","            session-temporary -- current working directory and\n","            can be readed from f'./df_train.csv' and f'./df_test.csv'\n","        \"\"\"\n","    \n","    def prepare_data(self):\n","        pass\n","        \n","    def setup(self, stage:str, force=True):\n","        inter_folders = \"kaggle/working\"\n","        if stage == \"fit\":\n","            # it takes 6-7 minutes to read df_train\n","            if self.df_train is not None and not force:\n","                return\n","            print(\"Reading df_train...\")\n","            start = time()\n","            self.df_train = pd.read_csv(f\"{self.setup_dir}/train/{inter_folders}/df_train.csv\",\n","                                        delimiter='\\t',\n","                                        dtype={'qid':'int32', 'label':'int8', 'text':'str', 'query':'str'})\n","            elapsed = time() - start\n","            print(\"df_train is readed, time elsapsed: \", elapsed)\n","        if stage == \"submit\":\n","            if self.df_test is not None and not force:\n","                return\n","            print(\"Reading df_subm...\")\n","            start = time()\n","            self.df_test = pd.read_csv(f\"{self.subm_dir}/df_subm.csv\",\n","                                       delimiter='\\t',\n","                                       dtype={'qid':'int32', 'text':'str', 'query':'str'})\n","            elapsed = time() - start\n","            print(\"df_test is readed, time elapsed: \", elapsed)\n","    \n","    def train_length(self):\n","        if self.df_train is not None:\n","            return len(self.df_train.index)\n","        return 0\n","        #raise Exception(\"train df is empty, can't compiute train_length\")\n","    \n","    def simple_train_dataloader(self, num_workers=1):\n","        train_dataset = RankDataset(self.df_train, neg_p=0.8, bienc_mode=self.bienc_mode)\n","        return DataLoader(train_dataset, shuffle=True, batch_size=self.batch_size, collate_fn=self._compose_batch, num_workers=num_workers)\n","    \n","    def test_dataloader(self, num_workers=1):\n","        # it's specific as test_step in LightningModule\n","        test_dataset = SubmitDataset(self.df_test, neg_p=1., bienc_mode=self.bienc_mode)\n","        return DataLoader(test_dataset, batch_size=self.test_batch_size, collate_fn=self._compose_submit_batch, num_workers=num_workers)\n","    \n","    def _compose_submit_batch(self, batch):\n","        qids = [z for _, z in batch]\n","        texts = [x for x, _ in batch]\n","        \n","        tokens = self.tokenizer(texts, padding=True, truncation=True, max_length=self.tkn_max_len, return_tensors='pt')\n","        return tokens, qids\n","    \n","    def _compose_batch(self, batch):\n","        # print(\"VKMARCO bienc_mode:\", self.bienc_mode)\n","        qids = [z for _, _, z in batch]\n","        texts = [x for x, _, _ in batch]\n","        ys = np.array([y for _, y, _ in batch])\n","        \n","        # from [3] -> [0, 0, 0, 1]\n","        # from [2] -> [0, 0, 1, 0]\n","        # from [1] -> [0, 1, 0, 0]\n","        # from [0] -> [1, 0, 0, 0]\n","        \n","        # to probabilities of labels\n","        coded_ys = np.zeros((ys.shape[0], 4))\n","        indexes = np.full((coded_ys.shape[0], ), coded_ys.shape[1])\n","        indexes[0] = 0\n","        indexes = np.cumsum(indexes) + ys\n","        np.put(coded_ys, indexes, 1)\n","   \n","        coded_ys = torch.tensor(coded_ys).float()\n","\n","        tokens = self.tokenizer(texts, padding=True, truncation=True, max_length=self.tkn_max_len, return_tensors='pt')\n","        return tokens, coded_ys, qids\n","    \n","    def teardown(self, stage):\n","        if stage == 'submit':\n","            del self.df_test\n","            gc.collect()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T11:32:39.940880Z","iopub.status.busy":"2024-05-07T11:32:39.940267Z","iopub.status.idle":"2024-05-07T11:38:12.754979Z","shell.execute_reply":"2024-05-07T11:38:12.753962Z","shell.execute_reply.started":"2024-05-07T11:32:39.940853Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading df_train...\n","df_train is readed, time elsapsed:  331.2066693305969\n"]}],"source":["dm = VKMarcoDataModule()\n","dm.setup(\"fit\")\n","df_tr = dm.df_train"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:16.878481Z","iopub.status.busy":"2024-05-07T13:27:16.878087Z","iopub.status.idle":"2024-05-07T13:27:17.412092Z","shell.execute_reply":"2024-05-07T13:27:17.411158Z","shell.execute_reply.started":"2024-05-07T13:27:16.878430Z"},"trusted":true},"outputs":[],"source":["from torchtext.models import RobertaClassificationHead\n","\n","\n","class RankBert(nn.Module):\n","    def __init__(self, labels_num=4, train_layers_count=2):\n","        super(RankBert, self).__init__()\n","\n","        self.bert = AutoModel.from_pretrained(\"xlm-roberta-base\")\n","        self.config = self.bert.config\n","        self.labels_num = labels_num\n","\n","        # freeze all layers without bias and LN\n","        for name, par in self.bert.named_parameters():\n","            if 'bias' in name or 'LayerNorm' in name:\n","                continue\n","            par.requires_grad = False\n","\n","        layer_count = self.config.num_hidden_layers\n","        print(\"train_layers_count type:\", type(train_layers_count), train_layers_count)\n","        print(\"labels_num type:\", type(labels_num), labels_num)\n","\n","        for i in range(train_layers_count): #unfreeze somw layers\n","            for par in self.bert.encoder.layer[layer_count - 1 - i].parameters():\n","                par.requires_grad = True\n","\n","        self.head = RobertaClassificationHead(num_classes=labels_num, input_dim=self.config.hidden_size)\n","        \n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n","        x = self.bert(input_ids=input_ids,\n","                      token_type_ids=token_type_ids,\n","                      attention_mask=attention_mask)[0]\n","#                       )[0][:, 0, :] #hidden_state of [CLS]\n","        x = self.head(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:17.629495Z","iopub.status.busy":"2024-05-07T13:27:17.628901Z","iopub.status.idle":"2024-05-07T13:27:17.664279Z","shell.execute_reply":"2024-05-07T13:27:17.663587Z","shell.execute_reply.started":"2024-05-07T13:27:17.629440Z"},"trusted":true},"outputs":[],"source":["class LightningModel(L.LightningModule):\n","    def __init__(self, model, amp_enable, optim, scheduler, loss_fn, device, tb_writer, config, bienc_mode=False):\n","        super().__init__()\n","        self.uninitialized_model = model\n","        self.amp_enable = amp_enable\n","        self.optim = optim\n","        self.scheduler = scheduler\n","        self.loss_fn = loss_fn\n","        self.config = config\n","        self.bienc_mode = bienc_mode\n","        self.tb_writer = tb_writer\n","\n","        self.running_loss = 0.0\n","        self.running_auc = 0.0\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n","        return self.model(input_ids, token_type_ids, attention_mask)\n","    \n","    def _move_batch_to_device(self, batch, device):\n","        if self.bienc_mode:\n","            batch_q, y, qid, batch_t = batch\n","            for key in batch_q:\n","                batch_q[key] = batch_q[key].to(device)\n","            for key in batch_t:\n","                batch_t[key] = batch_t[key].to(device)\n","            batch_x = [batch_q, batch_t]\n","        else:\n","            batch_x, y, qid = batch\n","\n","            for key in batch_x:\n","                batch_x[key] = batch_x[key].to(device)\n","        y = y.to(device)\n","        return batch_x, y, qid\n","    \n","    def _move_submit_batch_to_device(self, batch, device):\n","        batch_x, qid = batch\n","\n","        for key in batch_x:\n","            batch_x[key] = batch_x[key].to(device)\n","        return batch_x, qid\n","\n","    def training_step(self, batch, batch_idx):\n","        batch_x, y, qids = self._move_batch_to_device(batch, self.config.DEVICE)\n","        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=self.amp_enable):\n","            outputs = self.model(**batch_x)\n","            loss = loss_fn(outputs, y.detach())\n","\n","        self.running_loss += loss.detach().item()\n","\n","        y = y.detach().cpu().int().numpy()\n","        forauc_outputs = outputs.detach().clone().cpu()\n","        if y.sum() > 0:\n","            #compute metric\n","            with torch.no_grad(): \n","                auc = roc_auc_score(y.T,\n","                                    forauc_outputs.T,\n","                                    labels=np.array([range(0, self.model.labels_num)]),\n","                                    multi_class='ovr')\n","            self.running_auc += np.mean(auc)\n","        else:\n","            self.running_auc += 1\n","        \n","        #logging to tb\n","        tb_x = self.current_epoch * config.TRAIN_LENGTH + batch_idx + 1\n","        self.tb_writer.add_scalar('lr', self.scheduler.get_last_lr()[0], tb_x)\n","\n","        self.tb_writer.add_scalar('Train/loss', loss, tb_x)\n","        self.tb_writer.add_scalar('Train/auc', auc, tb_x)\n","        \n","        if batch_idx % config.LOG_INTERVAL == self.config.LOG_INTERVAL - 1:\n","            last_loss = self.running_loss / self.config.LOG_INTERVAL # loss per batch\n","            last_auc = self.running_auc / self.config.LOG_INTERVAL # loss per batch\n","\n","            print('  batch {} loss: {}'.format(batch_idx + 1, last_loss))\n","            print('  batch {} auc: {}'.format(batch_idx + 1, last_auc))\n","            \n","            self.tb_writer.add_scalar('Train/running_loss', last_loss, tb_x)\n","            self.tb_writer.add_scalar('Train/running_auc', last_auc, tb_x)\n","            \n","            self.log(\"rloss\", last_loss, on_step=True, prog_bar=True)\n","            self.log(\"rauc\", last_auc, on_step=True, prog_bar=True)\n","\n","            self.running_loss = 0.\n","            self.running_auc = 0.\n","        \n","        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n","        self.log(\"train_auc\", auc, on_step=True, prog_bar=True)\n","\n","        if batch_idx % 10 == 0:\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","        return loss\n","    \n","    def on_test_start(self):\n","        # in format: [p1, p2, p3]. For label 1 prediciton is p1, 2 - p2, 3 - p3\n","        self.y_test_triplet = []\n","        self.qids = []\n","    \n","    def test_step(self, batch, batch_idx):\n","        batch_x, qid = self._move_submit_batch_to_device(batch, config.DEVICE)\n","        preds = self.model(**batch_x)\n","        \n","        preds = preds.cpu()\n","        self.y_test_triplet += [preds]\n","\n","        self.qids.extend(qid)\n","        \n","    def on_test_end(self):\n","        self.y_test_triplet = torch.cat(self.y_test_triplet).view(-1).cpu()\n","        self.y_test_triplet = self.y_test_triplet.view(\n","                                    len(self.y_test_triplet)//self.config.LABELS_NUM, \n","                                    self.config.LABELS_NUM\n","                                    ).cpu()\n","\n","        self.qids = torch.LongTensor(self.qids).view(-1).cpu()\n","        return self.y_test_triplet\n","    \n","    def _compute_final_metrics(self):\n","        auc = self._get_auc_score()\n","\n","        # y_test_triplet[i] (=: output) is triplet of probabilities of labels 1, 2 and 3 ([p1, p2, p3])\n","        # in torch NDCG preds must be probabilities of relevance, and they are sorted\n","        # by it. So, to compute NDCG I will use next preprocessing algorithm:\n","        # get argmax of triplet: from [p1, p2, p3] to [label]\n","        # get softmax to norm the values to [0, 1]. It will save the order of targets. We need to sort \n","        # between different labels, not between same labels.\n","        # Order of targets is only matters in NDCG\n","        y_test_labels = self.y_test_triplet.argmax(axis=1) + 1\n","        y_test = torch.softmax(y_test_labels.float(), dim=0)\n","        print(\"in _compute_final_metrics: y_test\", type(y_test), y_test)\n","        print(\"in _compute_final_metrics shapes of preds, target and qids: \", y_test.shape, self.y_true.shape, self.qids.shape)\n","\n","        mrr = self._MRR(y_test, self.y_true, self.qids)\n","        ndcg = self._NDCG(y_test, self.y_true, self.qids)\n","        \n","        return {\"auc\": auc,\n","                \"MRR@10\": mrr,\n","                \"NDCG@10\": ndcg}\n","\n","    def configure_model(self):\n","        # initialize self.model\n","        self.model = self.uninitialized_model(labels_num=self.config.LABELS_NUM, train_layers_count=self.config.TRAIN_LAYERS)\n","    \n","    def configure_optimizers(self):\n","        self.optimizer = self.optim(self.model.parameters(), lr=self.config.LR, weight_decay=self.config.WD)\n","        self.scheduler = self.scheduler(self.optimizer,\n","                                   pct_start=0.1,\n","                                   max_lr=self.config.LR,\n","                                   epochs=self.config.EPOCHS, \n","                                   steps_per_epoch=self.config.TRAIN_LENGTH)\n","        return {\n","                    'optimizer': self.optimizer,\n","                    'lr_scheduler': {\n","                        'scheduler': self.scheduler,\n","                        'interval': 'step'\n","                    }\n","               }"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T17:12:14.709690Z","iopub.status.busy":"2024-05-06T17:12:14.708908Z","iopub.status.idle":"2024-05-06T17:12:14.719852Z","shell.execute_reply":"2024-05-06T17:12:14.718620Z","shell.execute_reply.started":"2024-05-06T17:12:14.709651Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["y_true = np.array([[0, 0, 0, 1],\n","                   [1, 0, 0, 0]])\n","y_pred = np.array([[0.2, 0.2, 0.2, 0.4],\n","          [0.6, 0.0, 0.0, 0.4]])\n","print(roc_auc_score(y_true.T, y_pred.T, labels=[0, 1, 2, 3], multi_class=\"ovo\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Обучение"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_tr"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:34.405490Z","iopub.status.busy":"2024-05-07T13:27:34.404718Z","iopub.status.idle":"2024-05-07T13:27:37.666785Z","shell.execute_reply":"2024-05-07T13:27:37.665987Z","shell.execute_reply.started":"2024-05-07T13:27:34.405435Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b2bff0ade28466bbddbf56cbf9bb066","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e0714669ebd45baa1d3253ca5dbd68f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"756798ce2a0c4f0d9230a84d08ae4db0","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8254cbd21a6f4b73a4e587f7df3e710f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dm = VKMarcoDataModule()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:37.668593Z","iopub.status.busy":"2024-05-07T13:27:37.668255Z","iopub.status.idle":"2024-05-07T13:27:37.718477Z","shell.execute_reply":"2024-05-07T13:27:37.717783Z","shell.execute_reply.started":"2024-05-07T13:27:37.668567Z"},"trusted":true},"outputs":[],"source":["class config:\n","    EPOCHS=5\n","    LR=5e-5\n","    WD=0.01\n","    SAVE_DIR=\"./cross_encоder_checkpoint/\"\n","    BATCH_SIZE=64\n","    TRAIN_LENGTH=dm.train_length()\n","    DEVICE=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","    LOG_INTERVAL=250\n","    TRAIN_LAYERS=2\n","    LABELS_NUM=4\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# this instances will be initialized inside of LightningModule\n","bert_model = RankBert                           # check configure_model()\n","optimizer = torch.optim.AdamW                   # check configure_optimizers\n","scheduler = torch.optim.lr_scheduler.OneCycleLR # check configure_optimizers\n","\n","cur_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M\").__str__()\n","codename=f\"amp_cross__{cur_date}\"\n","writer = SummaryWriter(f'{config.SAVE_DIR}{codename}')\n","lightning_model = LightningModel(bert_model,\n","                       amp_enable=True,\n","                       optim=optimizer,\n","                       scheduler=scheduler,\n","                       loss_fn=loss_fn,\n","                       device=config.DEVICE,\n","                       tb_writer=writer,\n","                       config=config,)\n","checkpoint_callback = ModelCheckpoint(monitor='train_loss',\n","                                      save_top_k=1,\n","                                      mode='min',\n","                                      dirpath=f'ckpt/{codename}',\n","                                      filename=codename + \"-{epoch:02d}-{train_loss:.2f}\",\n","                                      every_n_train_steps=6500,\n","                                      save_on_train_epoch_end=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T11:38:13.684010Z","iopub.status.busy":"2024-05-07T11:38:13.683722Z","iopub.status.idle":"2024-05-07T11:38:14.878158Z","shell.execute_reply":"2024-05-07T11:38:14.877265Z","shell.execute_reply.started":"2024-05-07T11:38:13.683983Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n"]}],"source":["gc.collect()\n","\n","trainer = Trainer(max_epochs=config.EPOCHS, callbacks=[checkpoint_callback], )\n","train_dataloader = dm.simple_train_dataloader(num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T11:38:14.879618Z","iopub.status.busy":"2024-05-07T11:38:14.879325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: Restoring states from the checkpoint path at /kaggle/working/ckpt/amp_cross__2024-05-07_06:19/amp_cross__2024-05-07_06:19-epoch=02-val_loss=0.00.ckpt\n"]},{"name":"stdout","output_type":"stream","text":["train_layers_count type: <class 'int'> 2\n","labels_num type: <class 'int'> 4\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:361: The dirpath has changed from '/kaggle/working/ckpt/amp_cross__2024-05-07_06:19' to '/kaggle/working/ckpt/amp_cross__2024-05-07_11:38', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: \n","  | Name    | Type             | Params\n","---------------------------------------------\n","0 | loss_fn | CrossEntropyLoss | 0     \n","1 | model   | RankBert         | 278 M \n","---------------------------------------------\n","14.9 M    Trainable params\n","263 M     Non-trainable params\n","278 M     Total params\n","1,114.549 Total estimated model params size (MB)\n","INFO: Restored all states from the checkpoint at /kaggle/working/ckpt/amp_cross__2024-05-07_06:19/amp_cross__2024-05-07_06:19-epoch=02-val_loss=0.00.ckpt\n","/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bda70b6c06d4bbaaadf88fb4ba89113","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:161: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.\n"]},{"name":"stdout","output_type":"stream","text":["  batch 12500 loss: 0.420988166809082\n","  batch 12500 auc: 0.42438541666666646\n","  batch 12750 loss: 0.8371126499176026\n","  batch 12750 auc: 0.8339166666666669\n","  batch 13000 loss: 0.8318497524261474\n","  batch 13000 auc: 0.8353750000000001\n","  batch 13250 loss: 0.8251838693618775\n","  batch 13250 auc: 0.8389270833333331\n","  batch 250 loss: 1.0373180189132691\n","  batch 250 auc: 1.042145833333333\n","  batch 500 loss: 0.8246340627670288\n","  batch 500 auc: 0.8392395833333334\n","  batch 750 loss: 0.8234608969688415\n","  batch 750 auc: 0.837052083333333\n","  batch 1000 loss: 0.8318695106506347\n","  batch 1000 auc: 0.8378958333333334\n","  batch 1250 loss: 0.8298304872512817\n","  batch 1250 auc: 0.8354270833333339\n","  batch 1500 loss: 0.8348938722610474\n","  batch 1500 auc: 0.8362083333333329\n","  batch 1750 loss: 0.8332175455093384\n","  batch 1750 auc: 0.8364895833333329\n","  batch 2000 loss: 0.8351182594299317\n","  batch 2000 auc: 0.8337083333333336\n","  batch 2250 loss: 0.8303181133270263\n","  batch 2250 auc: 0.8361770833333334\n","  batch 2500 loss: 0.8276095542907714\n","  batch 2500 auc: 0.8381666666666665\n","  batch 2750 loss: 0.8346563539505005\n","  batch 2750 auc: 0.8345208333333334\n","  batch 3000 loss: 0.8399806308746338\n","  batch 3000 auc: 0.8322083333333329\n","  batch 3250 loss: 0.8339995098114014\n","  batch 3250 auc: 0.8340416666666662\n","  batch 3500 loss: 0.82715061378479\n","  batch 3500 auc: 0.8366874999999997\n","  batch 3750 loss: 0.8272090177536011\n","  batch 3750 auc: 0.8373437500000003\n","  batch 4000 loss: 0.8264933319091797\n","  batch 4000 auc: 0.8367083333333329\n","  batch 4250 loss: 0.8258540439605713\n","  batch 4250 auc: 0.8373749999999999\n","  batch 4500 loss: 0.8276284885406494\n","  batch 4500 auc: 0.8367187499999998\n"]}],"source":["ckpt_path = \"/kaggle/working/ckpt/amp_cross__2024-05-07_11:38/amp_cross__2024-05-07_06:19-epoch=02-val_loss=0.00.ckpt\"\n","if not os.path.isfile(ckpt_path):\n","    ckpt_path=None\n","trainer.fit(lightning_model, train_dataloaders=train_dataloader, ckpt_path=ckpt_path)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:27:46.372353Z","iopub.status.busy":"2024-05-07T13:27:46.371944Z","iopub.status.idle":"2024-05-07T13:28:41.930040Z","shell.execute_reply":"2024-05-07T13:28:41.929062Z","shell.execute_reply.started":"2024-05-07T13:27:46.372320Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading df_subm...\n","df_test is readed, time elapsed:  54.093584299087524\n"]}],"source":["# dm = VKMarcoDataModule(df_train=df_tr, df_test=df_te)\n","dm = VKMarcoDataModule()\n","\n","dm.setup('submit')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:28:41.932215Z","iopub.status.busy":"2024-05-07T13:28:41.931906Z","iopub.status.idle":"2024-05-07T13:28:41.936148Z","shell.execute_reply":"2024-05-07T13:28:41.935241Z","shell.execute_reply.started":"2024-05-07T13:28:41.932189Z"},"trusted":true},"outputs":[],"source":["df_te = dm.df_test"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:28:41.937573Z","iopub.status.busy":"2024-05-07T13:28:41.937194Z","iopub.status.idle":"2024-05-07T13:42:41.942468Z","shell.execute_reply":"2024-05-07T13:42:41.941351Z","shell.execute_reply.started":"2024-05-07T13:28:41.937548Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO: GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO: `Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e14572a0b92f4ce58e479c5345e1e94c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO: Restoring states from the checkpoint path at /kaggle/working/ckpt/amp_cross__2024-05-07_11:38/amp_cross__2024-05-07_11:38-epoch=03-train_loss=0.85.ckpt\n"]},{"name":"stdout","output_type":"stream","text":["train_layers_count type: <class 'int'> 2\n","labels_num type: <class 'int'> 4\n"]},{"name":"stderr","output_type":"stream","text":["INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO: Loaded model weights from the checkpoint at /kaggle/working/ckpt/amp_cross__2024-05-07_11:38/amp_cross__2024-05-07_11:38-epoch=03-train_loss=0.85.ckpt\n","/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7435cf77bd324797881e3f4f05841664","version_major":2,"version_minor":0},"text/plain":["Testing: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[{}]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["ckpt_path = \"/kaggle/working/ckpt/amp_cross__2024-05-07_11:38/amp_cross__2024-05-07_11:38-epoch=03-train_loss=0.85.ckpt\"\n","if not os.path.isfile(ckpt_path):\n","    ckpt_path=None\n","trainer = Trainer(max_epochs=config.EPOCHS, callbacks=[checkpoint_callback], limit_test_batches=1.)\n","trainer.test(lightning_model, dataloaders=dm.test_dataloader(), ckpt_path=ckpt_path)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:42:41.946641Z","iopub.status.busy":"2024-05-07T13:42:41.945732Z","iopub.status.idle":"2024-05-07T13:42:41.972116Z","shell.execute_reply":"2024-05-07T13:42:41.971236Z","shell.execute_reply.started":"2024-05-07T13:42:41.946596Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-14.9708,   0.6602,   1.2086,   0.2003],\n","        [-17.4569,   1.8869,   1.2938,  -0.7894],\n","        [-16.5205,   1.8888,   0.9219,  -0.6647],\n","        ...,\n","        [-14.9252,   1.1919,   1.2377,  -0.6348],\n","        [-16.8142,   2.1609,   1.0968,  -1.1651],\n","        [-13.0181,   0.9224,   1.0698,  -0.4613]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["lightning_model.y_test_triplet"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:42:41.973383Z","iopub.status.busy":"2024-05-07T13:42:41.973108Z","iopub.status.idle":"2024-05-07T13:42:41.984890Z","shell.execute_reply":"2024-05-07T13:42:41.983984Z","shell.execute_reply.started":"2024-05-07T13:42:41.973360Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([152692])\n"]},{"data":{"text/plain":["tensor([2, 1, 1,  ..., 2, 1, 2])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["preds = lightning_model.y_test_triplet.argmax(dim=1)\n","print(preds.shape)\n","preds"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T13:42:41.986405Z","iopub.status.busy":"2024-05-07T13:42:41.986142Z","iopub.status.idle":"2024-05-07T13:42:42.007399Z","shell.execute_reply":"2024-05-07T13:42:42.006436Z","shell.execute_reply.started":"2024-05-07T13:42:41.986384Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>query</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n","      <td>Федеральный реестр алкогольной продукции онлай...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n","      <td>Нужны реальные отзывы о Текила Montezuma Silve...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n","      <td>🍷 Продажа текилы Sauza в магазине WineStyle! П...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n","      <td>Текила – модный алкогольный напиток, ставший в...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>0 5 текила максимо де кодорниз сильвер 38</td>\n","      <td>мне тута недавно добрые люди дали попить текил...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>152687</th>\n","      <td>42768</td>\n","      <td>ապօրինի ծագում ունեցող</td>\n","      <td>null Wednesday, 13 07 2022 ՀԱՅԱՍՏԱՆ ՔԱՂԱՔԱԿԱՆ ...</td>\n","    </tr>\n","    <tr>\n","      <th>152688</th>\n","      <td>42768</td>\n","      <td>ապօրինի ծագում ունեցող</td>\n","      <td>null Հայկական ծագում ունեցող անձնանունների ցան...</td>\n","    </tr>\n","    <tr>\n","      <th>152689</th>\n","      <td>42768</td>\n","      <td>ապօրինի ծագում ունեցող</td>\n","      <td>«Ապօրինի ծագում ունեցող գույքի բռնագանձման մաս...</td>\n","    </tr>\n","    <tr>\n","      <th>152690</th>\n","      <td>42768</td>\n","      <td>ապօրինի ծագում ունեցող</td>\n","      <td>null ﻿ Երևան, 16.Հուլիս.2022, 00 : 00 Խմբագրակ...</td>\n","    </tr>\n","    <tr>\n","      <th>152691</th>\n","      <td>42768</td>\n","      <td>ապօրինի ծագում ունեցող</td>\n","      <td>ՀՀ արդարադատության նախարարության կողմից 2019 թ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>152692 rows × 3 columns</p>\n","</div>"],"text/plain":["          qid                                      query  \\\n","0           3  0 5 текила максимо де кодорниз сильвер 38   \n","1           3  0 5 текила максимо де кодорниз сильвер 38   \n","2           3  0 5 текила максимо де кодорниз сильвер 38   \n","3           3  0 5 текила максимо де кодорниз сильвер 38   \n","4           3  0 5 текила максимо де кодорниз сильвер 38   \n","...       ...                                        ...   \n","152687  42768                     ապօրինի ծագում ունեցող   \n","152688  42768                     ապօրինի ծագում ունեցող   \n","152689  42768                     ապօրինի ծագում ունեցող   \n","152690  42768                     ապօրինի ծագում ունեցող   \n","152691  42768                     ապօրինի ծագում ունեցող   \n","\n","                                                     text  \n","0       Федеральный реестр алкогольной продукции онлай...  \n","1       Нужны реальные отзывы о Текила Montezuma Silve...  \n","2       🍷 Продажа текилы Sauza в магазине WineStyle! П...  \n","3       Текила – модный алкогольный напиток, ставший в...  \n","4       мне тута недавно добрые люди дали попить текил...  \n","...                                                   ...  \n","152687  null Wednesday, 13 07 2022 ՀԱՅԱՍՏԱՆ ՔԱՂԱՔԱԿԱՆ ...  \n","152688  null Հայկական ծագում ունեցող անձնանունների ցան...  \n","152689  «Ապօրինի ծագում ունեցող գույքի բռնագանձման մաս...  \n","152690  null ﻿ Երևան, 16.Հուլիս.2022, 00 : 00 Խմբագրակ...  \n","152691  ՀՀ արդարադատության նախարարության կողմից 2019 թ...  \n","\n","[152692 rows x 3 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df_te"]},{"cell_type":"markdown","metadata":{},"source":["## Сохраненение Submit'а"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-05-07T13:55:39.618123Z","iopub.status.busy":"2024-05-07T13:55:39.617481Z","iopub.status.idle":"2024-05-07T13:56:15.037508Z","shell.execute_reply":"2024-05-07T13:56:15.035805Z","shell.execute_reply.started":"2024-05-07T13:55:39.618090Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["df_docs = pd.read_csv(docs_file, delimiter='\\t', header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:56:15.038169Z","iopub.status.idle":"2024-05-07T13:56:15.038543Z","shell.execute_reply":"2024-05-07T13:56:15.038373Z","shell.execute_reply.started":"2024-05-07T13:56:15.038359Z"},"trusted":true},"outputs":[],"source":["df_subm_queries = pd.read_csv(submission_queries, delimiter='\\t', header=None)\n","df_subm_qdocs = pd.read_csv(submission_qdocs, delimiter=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:56:15.040388Z","iopub.status.idle":"2024-05-07T13:56:15.040884Z","shell.execute_reply":"2024-05-07T13:56:15.040667Z","shell.execute_reply.started":"2024-05-07T13:56:15.040633Z"},"trusted":true},"outputs":[],"source":["df_subm = create_submission_df(df_docs, df_subm_queries, df_subm_qdocs, with_docid=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:56:15.041915Z","iopub.status.idle":"2024-05-07T13:56:15.042360Z","shell.execute_reply":"2024-05-07T13:56:15.042148Z","shell.execute_reply.started":"2024-05-07T13:56:15.042129Z"},"trusted":true},"outputs":[],"source":["df_subm['preds'] = preds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:56:15.046184Z","iopub.status.idle":"2024-05-07T13:56:15.046547Z","shell.execute_reply":"2024-05-07T13:56:15.046374Z","shell.execute_reply.started":"2024-05-07T13:56:15.046360Z"},"trusted":true},"outputs":[],"source":["df_final = df_subm.drop(['query', 'text'], axis=1)\n","df_sorted = df_final.sort_values(['qid', 'preds'], ascending=[True, False])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:56:15.047725Z","iopub.status.idle":"2024-05-07T13:56:15.048029Z","shell.execute_reply":"2024-05-07T13:56:15.047891Z","shell.execute_reply.started":"2024-05-07T13:56:15.047878Z"},"trusted":true},"outputs":[],"source":["df_sort_renamed = df_sorted.rename(columns={'qid':\"QueryId\", 'doc_id': \"DocumentId\"})\n","df_to_submit = df_sort_renamed.drop('preds', axis=1)\n","df_to_submit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:42:42.144700Z","iopub.status.idle":"2024-05-07T13:42:42.145146Z","shell.execute_reply":"2024-05-07T13:42:42.144929Z","shell.execute_reply.started":"2024-05-07T13:42:42.144910Z"},"trusted":true},"outputs":[],"source":["\n","df_to_submit.to_csv(\"submit.csv\", columns=['QueryId', 'DocumentId'], index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8428397,"sourceId":77303,"sourceType":"competition"},{"datasetId":4866312,"sourceId":8211487,"sourceType":"datasetVersion"},{"datasetId":4943857,"sourceId":8322603,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
