{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b966a947",
   "metadata": {},
   "source": [
    "# Нейросетевые модели поиска. Часть III. Векторный поиск."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784008aa",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae85e14",
   "metadata": {},
   "source": [
    "Цель домашнего задания - научиться строить индексы для векторного поиска на БОЛЬШИХ объемах данных, добиваясь при этом оптимального качества и скорости. Работать будем с уже известным датасетом MS MARCO (точнее, с сэмплом из него). Сэмпл генерируется следующим кодом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a692c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_dataset = load_dataset(\"Tevatron/msmarco-passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "i = -1\n",
    "j = -1\n",
    "for row in msmarco_dataset['train']:\n",
    "    i += 1\n",
    "    qid = i\n",
    "    query = row['query']\n",
    "    for pos_ex in row['positive_passages']:\n",
    "        j += 1\n",
    "        docid = j\n",
    "        title = pos_ex['title']\n",
    "        text = pos_ex['text']\n",
    "        mark = 1\n",
    "        rows.append([qid, query, docid, title, text, mark])\n",
    "    for neg_ex in row['negative_passages']:\n",
    "        j += 1\n",
    "        docid = j\n",
    "        title = neg_ex['title']\n",
    "        text = neg_ex['text']\n",
    "        mark = 0\n",
    "        rows.append([qid, query, docid, title, text, mark])\n",
    "df = pd.DataFrame(rows, columns=['qid', 'query', 'docid', 'title', 'text', 'mark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:300000]\n",
    "#df.to_csv('./data/homework_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d998c3",
   "metadata": {},
   "source": [
    "Баллы начисляются за выполнение следующих заданий:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de27e9",
   "metadata": {},
   "source": [
    "# Предобработка данных [1 балл]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e3789f",
   "metadata": {},
   "source": [
    "Возможно, прежде чем строить эмбеддинги из текстовых данных, стоит их предобработать? (использовать не только зону text, что-то сделать с пунктуацией, использовать зону не целиком). В случае использования только СЫРОЙ зоны text (как на семинаре) бал начислен не будет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/homework_sample.csv')\n",
    "#data = pd.read_csv('homework_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af078372",
   "metadata": {},
   "source": [
    "Объединяю title и text, удаляю пунктуацию, удаляю слова длиной меньше 4 символов (среди них артиклей и предлогов гораздо больше, чем важных для смысла), делю текст на блоки, из которых оставляю не все"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26534883",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_BRANCHES = 4\n",
    "\n",
    "rows = []\n",
    "for ln in tqdm(data.to_numpy()):\n",
    "    row = []\n",
    "    row.append(int(ln[0]))\n",
    "    row.append(ln[1])\n",
    "    row.append(ln[2])\n",
    "    \n",
    "    text = str(ln[3]) + \" \" + ln[4]\n",
    "    text.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation)))\n",
    "    tokens = [s for s in text.split() if len(s) > 3]\n",
    "    if len(tokens) == 0:\n",
    "        row.append(\" \")\n",
    "    else:\n",
    "        size = TEXT_BRANCHES * 2\n",
    "        branch = 0\n",
    "        while branch == 0:\n",
    "            size //= 2\n",
    "            branch = len(tokens) // size\n",
    "        text = \"\"\n",
    "        for i in range(0, size, 4):\n",
    "            text = text + \" \" + \" \".join(tokens[i * branch: (i + 1) * branch - 1])\n",
    "        row.append(text)\n",
    "    \n",
    "    row.append(int(ln[5]))\n",
    "    \n",
    "    rows.append(row)\n",
    "    \n",
    "data_processed = pd.DataFrame(rows, columns=['qid', 'query', 'docid', 'text', 'mark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_processed.to_csv('./data/homework_sample_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a7d42e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T23:42:00.497312Z",
     "iopub.status.busy": "2024-05-01T23:42:00.496439Z",
     "iopub.status.idle": "2024-05-01T23:42:01.534773Z",
     "shell.execute_reply": "2024-05-01T23:42:01.533333Z",
     "shell.execute_reply.started": "2024-05-01T23:42:00.497270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>text</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>0</td>\n",
       "      <td>Whitemarsh Island, Georgia Whitemarsh Island,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>1</td>\n",
       "      <td>What military strategy used pacific? strategy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>2</td>\n",
       "      <td>Whakaari White Island island</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>3</td>\n",
       "      <td>Jekyll Island Jekyll Island, 5,700 acres, sma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>4</td>\n",
       "      <td>Sibu Island Sibu Island. scuba diver Sibu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>9727</td>\n",
       "      <td>what does saddle soap do for boots</td>\n",
       "      <td>299995</td>\n",
       "      <td>Saddle Soap used clean smooth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>9727</td>\n",
       "      <td>what does saddle soap do for boots</td>\n",
       "      <td>299996</td>\n",
       "      <td>Soap Recipes Making Homemade Soap with easy, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>9727</td>\n",
       "      <td>what does saddle soap do for boots</td>\n",
       "      <td>299997</td>\n",
       "      <td>Numbness Location: Back Into Bottom Foot Heel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>9727</td>\n",
       "      <td>what does saddle soap do for boots</td>\n",
       "      <td>299998</td>\n",
       "      <td>Boot Fitting: Boots Supposed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>9727</td>\n",
       "      <td>what does saddle soap do for boots</td>\n",
       "      <td>299999</td>\n",
       "      <td>When wash your hands. wash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid                               query   docid  \\\n",
       "0          0          where is whitemarsh island       0   \n",
       "1          0          where is whitemarsh island       1   \n",
       "2          0          where is whitemarsh island       2   \n",
       "3          0          where is whitemarsh island       3   \n",
       "4          0          where is whitemarsh island       4   \n",
       "...      ...                                 ...     ...   \n",
       "299995  9727  what does saddle soap do for boots  299995   \n",
       "299996  9727  what does saddle soap do for boots  299996   \n",
       "299997  9727  what does saddle soap do for boots  299997   \n",
       "299998  9727  what does saddle soap do for boots  299998   \n",
       "299999  9727  what does saddle soap do for boots  299999   \n",
       "\n",
       "                                                     text  mark  \n",
       "0        Whitemarsh Island, Georgia Whitemarsh Island,...     1  \n",
       "1        What military strategy used pacific? strategy...     0  \n",
       "2                            Whakaari White Island island     0  \n",
       "3        Jekyll Island Jekyll Island, 5,700 acres, sma...     0  \n",
       "4               Sibu Island Sibu Island. scuba diver Sibu     0  \n",
       "...                                                   ...   ...  \n",
       "299995                      Saddle Soap used clean smooth     1  \n",
       "299996   Soap Recipes Making Homemade Soap with easy, ...     0  \n",
       "299997   Numbness Location: Back Into Bottom Foot Heel...     0  \n",
       "299998                       Boot Fitting: Boots Supposed     0  \n",
       "299999                         When wash your hands. wash     0  \n",
       "\n",
       "[300000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed = pd.read_csv('./data/homework_sample_processed.csv').fillna(\" \")\n",
    "data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "898d0d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T00:34:30.782038Z",
     "iopub.status.busy": "2024-05-02T00:34:30.781572Z",
     "iopub.status.idle": "2024-05-02T00:34:31.292221Z",
     "shell.execute_reply": "2024-05-02T00:34:31.290945Z",
     "shell.execute_reply.started": "2024-05-02T00:34:30.782003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [00:00<00:00, 755152.63it/s]\n"
     ]
    }
   ],
   "source": [
    "relevant = {}\n",
    "for ln in tqdm(data_processed.to_numpy()):\n",
    "    relevant[ln[0]] = []\n",
    "    if ln[4] == 1:\n",
    "        relevant[ln[0]].append(ln[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885413e4",
   "metadata": {},
   "source": [
    "# Подбор нейронки [1 балл]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109cbac",
   "metadata": {},
   "source": [
    "На семинаре для варки эмбеддингов использовался Universal Sentence Encoder. Возможно, стоит попробовать что-то другое? (балл будет начислен в том случае, если для варки индексов из следующих пунктов будет использована/ы другая/ие нейронки - да, использовать разные нейронки для разных индексов можно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16653def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T23:42:04.688058Z",
     "iopub.status.busy": "2024-05-01T23:42:04.687213Z",
     "iopub.status.idle": "2024-05-01T23:42:13.321411Z",
     "shell.execute_reply": "2024-05-01T23:42:13.320179Z",
     "shell.execute_reply.started": "2024-05-01T23:42:04.688014Z"
    }
   },
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9e140",
   "metadata": {},
   "source": [
    "# Метрика для оценки качества [1 балл]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978288f3",
   "metadata": {},
   "source": [
    "Нужно реализовать метрику для оценки качества индексов - ndcg@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51607063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T00:44:51.528767Z",
     "iopub.status.busy": "2024-05-02T00:44:51.528286Z",
     "iopub.status.idle": "2024-05-02T00:44:59.085938Z",
     "shell.execute_reply": "2024-05-02T00:44:59.084829Z",
     "shell.execute_reply.started": "2024-05-02T00:44:51.528735Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.retrieval import RetrievalNormalizedDCG\n",
    "\n",
    "def NDCG(preds, target, qids, k=10):\n",
    "    ndcg = RetrievalNormalizedDCG(top_k=k)\n",
    "    \n",
    "    return ndcg(torch.Tensor(preds),\n",
    "                torch.Tensor(target),\n",
    "                indexes=torch.LongTensor(qids - min(qids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544faae",
   "metadata": {},
   "source": [
    "# Варка и инференс индексов [до 9 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d7db7",
   "metadata": {},
   "source": [
    "В рамках этой части задания нужно сварить индексы 3 типов - annoy, faiss, hnswlib. Параметры можно выбирать любые (стоит ориентироваться на качество индекса, требуемую память и перф (см. ниже).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d84aef",
   "metadata": {},
   "source": [
    "За 1 индекс можно получить:\n",
    "\n",
    "    1 балл,  если индекс состоит из  300000 документов\n",
    "    2 балла, если индекс состоит из 1000000 документов\n",
    "    3 балла, если индекс состоит из 2000000 документов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6fff0",
   "metadata": {},
   "source": [
    "Важно:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae831de1",
   "metadata": {},
   "source": [
    "1. Эмбеддинги, которые кладутся в индекс, должны быть сгенерированы нейронкой и соответствовать документам из датасета, иначе баллы аннулируются (сложить 2 миллиона эмбеддингов вида [1,1,1,...,1] нельзя)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cb7b5",
   "metadata": {},
   "source": [
    "2. Чтобы получить баллы за индекс, необходимо не только сварить, но и проинференсить его: прогнать на нем набор запросов из датасета (~65k), оценить качество результата (используя метрику ndcg@10), оценить время инференса (напр., так как в семинаре). Без этого баллы начислены не будут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728fcacb",
   "metadata": {},
   "source": [
    "3. При варке и инференсе индекса нельзя использовать больше 16GB оперативной памяти (иначе начислится 0 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mat = []\n",
    "for txt in tqdm(data_processed['text'].values):\n",
    "    emb = embed([txt])\n",
    "    text_mat.append(emb[0].numpy().tolist())\n",
    "text_mat = np.array(text_mat)\n",
    "\"\"\"with open('./embeddings/text_embs.npy', 'wb') as f:\n",
    "    np.save(f, text_mat)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mat = []\n",
    "for txt in tqdm(data_processed['query'].unique()):\n",
    "    emb = embed([txt])\n",
    "    query_mat.append(emb[0].numpy().tolist())\n",
    "query_mat = np.array(query_mat)\n",
    "\"\"\"with open('./embeddings/query_embs.npy', 'wb') as f:\n",
    "    np.save(f, query_mat)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccde207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T23:42:20.633044Z",
     "iopub.status.busy": "2024-05-01T23:42:20.632601Z",
     "iopub.status.idle": "2024-05-01T23:42:21.431178Z",
     "shell.execute_reply": "2024-05-01T23:42:21.429849Z",
     "shell.execute_reply.started": "2024-05-01T23:42:20.633012Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./embeddings/text_embs.npy', 'rb') as f:\n",
    "    text_mat = np.load(f)\n",
    "with open('./embeddings/query_embs.npy', 'rb') as f:\n",
    "    query_mat = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edbb96",
   "metadata": {},
   "source": [
    "### Annoy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3a5e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T23:42:29.030184Z",
     "iopub.status.busy": "2024-05-01T23:42:29.029757Z",
     "iopub.status.idle": "2024-05-01T23:42:29.038632Z",
     "shell.execute_reply": "2024-05-01T23:42:29.037117Z",
     "shell.execute_reply.started": "2024-05-01T23:42:29.030154Z"
    }
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e22a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T23:42:46.265929Z",
     "iopub.status.busy": "2024-05-01T23:42:46.265501Z",
     "iopub.status.idle": "2024-05-01T23:47:29.359649Z",
     "shell.execute_reply": "2024-05-01T23:47:29.358377Z",
     "shell.execute_reply.started": "2024-05-01T23:42:46.265896Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [00:38<00:00, 7780.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AnnoyIndex(f=512, metric='euclidean')\n",
    "for i, vec in enumerate(tqdm(text_mat)):\n",
    "    index.add_item(i, vec)\n",
    "\n",
    "index.build(n_trees=500)\n",
    "#index.save('./indexes/sample500.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = AnnoyIndex(f=512, metric='euclidean')\n",
    "index.load('./indexes/sample500.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c668740b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T00:49:06.833233Z",
     "iopub.status.busy": "2024-05-02T00:49:06.832774Z",
     "iopub.status.idle": "2024-05-02T00:49:06.843235Z",
     "shell.execute_reply": "2024-05-02T00:49:06.841855Z",
     "shell.execute_reply.started": "2024-05-02T00:49:06.833201Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_qual(param=-1):\n",
    "    predict = []\n",
    "    qid = 0\n",
    "    number = 0\n",
    "    for ln in tqdm(data_processed.to_numpy()):\n",
    "        if ln[0] == qid:\n",
    "            number += 1\n",
    "            continue\n",
    "        \n",
    "        items = index.get_nns_by_vector(vector=query_mat[qid], n=number, search_k=param)\n",
    "        result = [int(i in relevant[qid]) for i in items]\n",
    "        predict = predict + result\n",
    "        \n",
    "        number = 1\n",
    "        qid = ln[0]\n",
    "        \n",
    "    items = index.get_nns_by_vector(vector=query_mat[qid], n=number, search_k=param)\n",
    "    result = [int(i in relevant[qid]) for i in items]\n",
    "    predict = predict + result\n",
    "    \n",
    "    \n",
    "    return NDCG(predict, data_processed['mark'].values, data_processed['qid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70bd0d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T00:49:07.569511Z",
     "iopub.status.busy": "2024-05-02T00:49:07.568145Z",
     "iopub.status.idle": "2024-05-02T00:49:33.095975Z",
     "shell.execute_reply": "2024-05-02T00:49:33.094767Z",
     "shell.execute_reply.started": "2024-05-02T00:49:07.569453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [00:21<00:00, 13966.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 s, sys: 77.4 ms, total: 25.6 s\n",
      "Wall time: 25.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1511)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "eval_qual(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cd70f",
   "metadata": {},
   "source": [
    "### hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f8bdd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:00:05.519404Z",
     "iopub.status.busy": "2024-05-02T01:00:05.518878Z",
     "iopub.status.idle": "2024-05-02T01:00:20.784105Z",
     "shell.execute_reply": "2024-05-02T01:00:20.782285Z",
     "shell.execute_reply.started": "2024-05-02T01:00:05.519363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hnswlib in /opt/conda/lib/python3.10/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from hnswlib) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 512\n",
    "index = faiss.IndexFlatL2(emb_size)\n",
    "index.add(text_mat)\n",
    "print(f\" После добавления векторов: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c357c996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:01:35.467304Z",
     "iopub.status.busy": "2024-05-02T01:01:35.466794Z",
     "iopub.status.idle": "2024-05-02T01:01:57.015042Z",
     "shell.execute_reply": "2024-05-02T01:01:57.013914Z",
     "shell.execute_reply.started": "2024-05-02T01:01:35.467266Z"
    }
   },
   "outputs": [],
   "source": [
    "index = hnswlib.Index(space = 'l2', dim = 512)\n",
    "index.init_index(max_elements = 300000, ef_construction = 20, M = 24)\n",
    "index.add_items(text_mat)\n",
    "index.set_ef(ef=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "381587c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:02:22.508272Z",
     "iopub.status.busy": "2024-05-02T01:02:22.507811Z",
     "iopub.status.idle": "2024-05-02T01:02:24.039174Z",
     "shell.execute_reply": "2024-05-02T01:02:24.037809Z",
     "shell.execute_reply.started": "2024-05-02T01:02:22.508241Z"
    }
   },
   "outputs": [],
   "source": [
    "#index.save_index(\"./indexes/hnsw_efcons20_M24.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baa63a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:03:31.903534Z",
     "iopub.status.busy": "2024-05-02T01:03:31.903022Z",
     "iopub.status.idle": "2024-05-02T01:03:33.271160Z",
     "shell.execute_reply": "2024-05-02T01:03:33.269533Z",
     "shell.execute_reply.started": "2024-05-02T01:03:31.903499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Calling load_index for an already inited index. Old index is being deallocated.\n"
     ]
    }
   ],
   "source": [
    "index.load_index(\"./indexes/hnsw_efcons20_M24.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f6b81c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:15:18.285457Z",
     "iopub.status.busy": "2024-05-02T01:15:18.284934Z",
     "iopub.status.idle": "2024-05-02T01:15:18.295950Z",
     "shell.execute_reply": "2024-05-02T01:15:18.294683Z",
     "shell.execute_reply.started": "2024-05-02T01:15:18.285422Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_qual():\n",
    "    predict = []\n",
    "    qid = 0\n",
    "    number = 0\n",
    "    for ln in tqdm(data_processed.to_numpy()):\n",
    "        if ln[0] == qid:\n",
    "            number += 1\n",
    "            continue\n",
    "        \n",
    "        items, _ = index.knn_query(np.array([query_mat[qid]]).astype(np.float32), k=number)\n",
    "        result = [int(i in relevant[qid]) for i in items[0]]\n",
    "        predict = predict + result\n",
    "        \n",
    "        number = 1\n",
    "        qid = ln[0]\n",
    "        \n",
    "    items, _ = index.knn_query(np.array([query_mat[qid]]).astype(np.float32), k=number)\n",
    "    result = [int(i in relevant[qid]) for i in items[0]]\n",
    "    predict = predict + result\n",
    "    \n",
    "    \n",
    "    \n",
    "    return NDCG(predict, data_processed['mark'].values, data_processed['qid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48106ce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T01:15:18.777020Z",
     "iopub.status.busy": "2024-05-02T01:15:18.776558Z",
     "iopub.status.idle": "2024-05-02T01:15:36.336541Z",
     "shell.execute_reply": "2024-05-02T01:15:36.335179Z",
     "shell.execute_reply.started": "2024-05-02T01:15:18.776985Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [00:13<00:00, 22044.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 78.2 ms, total: 17.6 s\n",
      "Wall time: 17.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1511)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "eval_qual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0404b",
   "metadata": {},
   "source": [
    "# Соревнование [до 10 баллов]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad64ff7",
   "metadata": {},
   "source": [
    "Проводится среди индексов размерами 2000000 документов (остальные не оцениваются) в двух дисциплинах: по качеству (величина ndcg@10) и скорости (насколько быстро удалось прогнать полный набор запросов на этом индексе)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4060db",
   "metadata": {},
   "source": [
    "Оценивается только один индекс (указывается сдающим домашку) - если вы сварили 3 индекса по 2 миллиона доков каждый, то укажите, какой участвует в соревновании (напишите в ноутбуке). Иначе выбор будет сделан рандомно из доступных вариантов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf3683",
   "metadata": {},
   "source": [
    "Разбалловка:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edef43f",
   "metadata": {},
   "source": [
    "\n",
    "За первое место по качеству: 5 баллов\n",
    "    \n",
    "За второе место по качеству: 3 балла\n",
    "    \n",
    "За все остальные места по качеству, кроме последнего: 1 балл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860d088",
   "metadata": {},
   "source": [
    "За первое место по скорости (при не последнем месте по качеству): 5 баллов\n",
    "\n",
    "За второе место по скорости (при не последнем месте по качеству): 3 балла\n",
    "\n",
    "За все остальные места по скорости (при не последнем месте по качеству), кроме последнего: 1 балл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca2df6",
   "metadata": {},
   "source": [
    "# Процедура сдачи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae70d5",
   "metadata": {},
   "source": [
    "**Вам надо:**\n",
    "\n",
    "- Форкнуть эту репу;\n",
    "- Создать бранч, в котором вы дальше будете работать;\n",
    "- Выполнить все или часть заданий ноутбука;\n",
    "- Запушить ваш бранч и поставить Pull Request.\n",
    "\n",
    "Проверяющий счекаутит вашу бранчу и проверит работу."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4920925,
     "sourceId": 8285219,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4921004,
     "sourceId": 8285432,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
