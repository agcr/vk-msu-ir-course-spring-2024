{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06efe571-c571-4301-8c84-6a19dea2b9b5",
   "metadata": {},
   "source": [
    "# Домашняя работа по теме \"Машинное обучение ранжированию\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом ДЗ мы:\n",
    "- научимся работать со стандартным датасетом для машинного обучения ранжированию [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- попробуем применить на практике все то, чему мы научились на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c146f0-de33-4b44-bb81-fcf1711ce1f7",
   "metadata": {},
   "source": [
    "## Как будет происходить сдача ДЗ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5eaff-2123-4a5b-ba12-74829b50a5b5",
   "metadata": {},
   "source": [
    "Вам надо:\n",
    "- форкнуть эту репу\n",
    "- создать бранч в котором вы дальше будете работать\n",
    "- реализовать класс Model в этом ноутбуке\n",
    "- убедиться, что ваша реализация выбивает NDCG@10 выше бейзлайна (см. ниже)\n",
    "- запушить ваш бранч и поставить Pull Request\n",
    "- в комментарии написать какой скор вы выбили\n",
    "\n",
    "В таком случае мы (организаторы):\n",
    "\n",
    "- счекаутим вашу бранчу\n",
    "- проверим что ваша реализация действительно выбивает заявленный скор\n",
    "\n",
    "Предполагается, что и вы, и мы работаем в виртаульном окружении как в семинаре про машинное обучение ранжированию: seminars/7-learning-to-rank/requirements.txt(подробнее про работу с виртуальными окружениями README в корне этой репы).\n",
    "\n",
    "Оценка:\n",
    "- За выбитый скор больше **0.507** назначаем **5** баллов, за скор больше (или равно) **0.510** назначаем максимальный балл -- 10 баллов\n",
    "- Тот из участников кто выбъет самый высокий скор получит еще +10 баллов\n",
    "\n",
    "При сдаче кода важно помнить о том, что:\n",
    "- В коде не должно быть захардкоженных с потолка взятых гиперпараметров (таких как число деревьев, learning rate и т.п.) -- обязательно должен быть представлен код который их подбирает!\n",
    "- Решение должно быть стабильно от запуска к запуску (на CPU) т.е. все seed'ы для генераторов случайных чисел должны быть фиксированы\n",
    "- Мы (организаторы) будем запускать код на CPU поэтому, даже если вы использовали для подбора параметров GPU, финальный скор надо репортить на CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import Pool,CatBoost,datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим датасет MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Строго говоря, он состоит их 2х частей:\n",
    "\n",
    "- основной датасет MSLR-WEB30K -- он содержит более 30 тыс. запросов\n",
    "- \"маленький\" датасет MSLR-WEB10K, который содержит только 10 тыс. запросов и является случайным сэмплом датасета MSLR-WEB30K\n",
    "\n",
    "в этом ДЗ мы будем работать с MSLR-WEB10K, т.к. полная версия датасета может просто не поместиться у нас в RAM (и, тем более, в память видеокарты если мы учимся на GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf35bd-9729-48bb-975d-a955b8bd1c56",
   "metadata": {},
   "source": [
    "Будем считать, что мы самостоятельно скачали датасет MSLR-WEB10K с официального сайта, поместили его в папку КОРЕНЬ-ЭТОЙ-РЕПЫ/data/mslr-web10k и раззиповали.\n",
    "\n",
    "В результате у нас должна получиться следующая структура папок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b06baa8-44fe-420b-bad5-4c6f63a66544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls ../../data\n",
    "# mslr-web10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af4d76cb-2eaa-4b48-be86-ea09a25e2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ls -lh ../../data/mslr-web10k/\n",
    "# итого 1,2G\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold1\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold2\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold3\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold4\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold5\n",
    "# -rw-r--r-- 1 andrei andrei 1,2G июл  7  2016 MSLR-WEB10K.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0a87e-eb4a-4b4a-a6b3-0419e29ae539",
   "metadata": {},
   "source": [
    "Заметим, что датасет довольно большой, в распакованном виде он весит 7.7 GB.\n",
    "\n",
    "Датасет состоит из нескольких фолдов, которые по сути представляют из себя разные разбиения одних и тех же данных на обучающее, валидационное и тестовые множеста.\n",
    "\n",
    "Дальше мы будем использовать только первый фолд: Fold1.\n",
    "\n",
    "Заглянем внутрь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa74835-7d91-4c3a-badb-e268027cff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lh ../../data/mslr-web10k/Fold1\n",
    "# итого 1,3G\n",
    "# -rw-r--r-- 1 andrei andrei 267M апр 30  2010 test.txt\n",
    "# -rw-r--r-- 1 andrei andrei 800M апр 30  2010 train.txt\n",
    "# -rw-r--r-- 1 andrei andrei 261M апр 30  2010 vali.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5ccf5-d83e-45e6-bd9b-3a6c729925c6",
   "metadata": {},
   "source": [
    "Видим, что у нас 3 файла с говорящими названиями, соответсвующими сплитам нашего датасета.\n",
    "\n",
    "Посмотрим на содержимое одного из файлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922a1401-1e31-4c01-8eae-daf673d8736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 1 ../../data/mslr-web10k/Fold1/train.txt\n",
    "#2 qid:1 1:3 2:3 3:0 4:0 5:3 6:1 7:1 8:0 9:0 10:1 11:156 12:4 13:0 14:7 15:167 16:6.931275 17:22.076928 18:19.673353 19:22.255383 20:6.926551 21:3 22:3 23:0 24:0 25:6 26:1 27:1 28:0 29:0 30:2 31:1 32:1 33:0 34:0 35:2 36:1 37:1 38:0 39:0 40:2 41:0 42:0 43:0 44:0 45:0 46:0.019231 47:0.75000 48:0 49:0 50:0.035928 51:0.00641 52:0.25000 53:0 54:0 55:0.011976 56:0.00641 57:0.25000 58:0 59:0 60:0.011976 61:0.00641 62:0.25000 63:0 64:0 65:0.011976 66:0 67:0 68:0 69:0 70:0 71:6.931275 72:22.076928 73:0 74:0 75:13.853103 76:1.152128 77:5.99246 78:0 79:0 80:2.297197 81:3.078917 82:8.517343 83:0 84:0 85:6.156595 86:2.310425 87:7.358976 88:0 89:0 90:4.617701 91:0.694726 92:1.084169 93:0 94:0 95:2.78795 96:1 97:1 98:0 99:0 100:1 101:1 102:1 103:0 104:0 105:1 106:12.941469 107:20.59276 108:0 109:0 110:16.766961 111:-18.567793 112:-7.760072 113:-20.838749 114:-25.436074 115:-14.518523 116:-21.710022 117:-21.339609 118:-24.497864 119:-27.690319 120:-20.203779 121:-15.449379 122:-4.474452 123:-23.634899 124:-28.119826 125:-13.581932 126:3 127:62 128:11089534 129:2 130:116 131:64034 132:13 133:3 134:0 135:0 136:0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f4fa9-9ba3-457f-8bf2-f9a7b3112e91",
   "metadata": {},
   "source": [
    "Видим, что данные лежат в уже знакомом нам по семинару формате:\n",
    "\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "В файле qid и все-фичи кодируются в формате КЛЮЧ:ЗНАЧЕНИЕ, напр. 130:116 -- тут 130 это номер фичи, а 116 -- ее значение.\n",
    "\n",
    "Такой формат в мире машинного обучения часто называют svm light формат (в честь когда-то популярной библиотеки SVM-Light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bba78-f04f-478b-b3dc-89c9011cb697",
   "metadata": {},
   "source": [
    "Напишем немного вспомогательного кода для загрузки этого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c29b4f-0b79-4259-b079-fdc589d77ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "    \n",
    "def load_svmlight_file(input_file, max_num_lines=0):\n",
    "    \"\"\"Loads dataset split in SVM-Light format\"\"\"\n",
    "    def _parse_field(field):\n",
    "        parts = field.split(':')\n",
    "        if len(parts) != 2:\n",
    "            raise Exception(f\"invalid number of parts in field {field}\")\n",
    "        return parts\n",
    "\n",
    "    num_features = 136\n",
    "    exp_num_fields = num_features + 2\n",
    "    num_lines = 0\n",
    "    X = []\n",
    "    with open(input_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                num_lines += 1\n",
    "                                  \n",
    "                # Parse into fields\n",
    "                fields = line.rstrip().split(' ')\n",
    "                num_fields = len(fields)\n",
    "                if num_fields != exp_num_fields:\n",
    "                    raise Exception(f\"invalid number of fields {num_fields}\")\n",
    "    \n",
    "                # Parse every field\n",
    "                x = np.zeros(exp_num_fields, dtype=np.float32)\n",
    "                label = int(fields[0])\n",
    "                x[0] = label\n",
    "                _, qid_str = _parse_field(fields[1])\n",
    "                qid = int(qid_str)\n",
    "                x[1] = qid\n",
    "                for i, field in enumerate(fields[2:]):\n",
    "                    _, feature_str = _parse_field(field)\n",
    "                    x[i+2] = float(feature_str)\n",
    "    \n",
    "                # Add new object\n",
    "                X.append(x)\n",
    "                if num_lines % 50000 == 0:\n",
    "                    print(f\"Loaded {num_lines} lines...\")\n",
    "                if max_num_lines > 0 and num_lines == max_num_lines:\n",
    "                    print(f\"WARNING: stop loading, line limit reached: max_num_lines = {max_num_lines} input_file = {input_file}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error at line {num_lines} in {input_file}\") from e\n",
    "    \n",
    "    # To pandas\n",
    "    df = pd.DataFrame(X, columns=generate_column_names(num_features))\n",
    "    print(f\"Loaded SVM-Light file {input_file}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa292cb3-e516-423c-a9b4-315123bddfea",
   "metadata": {},
   "source": [
    "И теперь загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25649947-a7ef-4cbd-8403-7e7456c28327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded 250000 lines...\n",
      "Loaded 300000 lines...\n",
      "Loaded 350000 lines...\n",
      "Loaded 400000 lines...\n",
      "Loaded 450000 lines...\n",
      "Loaded 500000 lines...\n",
      "Loaded 550000 lines...\n",
      "Loaded 600000 lines...\n",
      "Loaded 650000 lines...\n",
      "Loaded 700000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\train.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\vali.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\test.txt\n",
      "Dataset loaded from fold_dir ..\\..\\data\\mslr-web10k\\Fold1\n"
     ]
    }
   ],
   "source": [
    "# возможно здесь придётся привести папку mslr... к верхнему регистру\n",
    "# в windows пути к файлам case-insensitive\n",
    "fold_dir = pathlib.Path(\"../../data/mslr-web10k/Fold1\")\n",
    "\n",
    "df_train = load_svmlight_file(fold_dir.joinpath(\"train.txt\"))\n",
    "df_valid = load_svmlight_file(fold_dir.joinpath(\"vali.txt\"))\n",
    "df_test = load_svmlight_file(fold_dir.joinpath(\"test.txt\"))\n",
    "print(f\"Dataset loaded from fold_dir {fold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. \n",
    "\n",
    "Объявим класс модели, который надо будем заимлементить в этом ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab90707-f1b8-4283-ac22-2643baa4ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model:\n",
    "    # params = None if model will be loaded\n",
    "    def __init__(self,params=None):\n",
    "        self.model = None \n",
    "        self.params = params\n",
    "\n",
    "    def fit(self, df_train,df_val = None ):\n",
    "        X_train,y_train,q_train = self.to_catboost_dataset(df_train)\n",
    "        pool_train = Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "\n",
    "        X_val,y_val,q_val = self.to_catboost_dataset(df_val)\n",
    "        pool_val = Pool(data=X_val,label=y_val,group_id=q_val)\n",
    "\n",
    "        \n",
    "\n",
    "        self.model = CatBoost(self.params)\n",
    "\n",
    "    \n",
    "        self.model.fit(pool_train,eval_set=pool_val)\n",
    "            \n",
    "\n",
    "\n",
    "    def predict(self, df_test):\n",
    "        X_test,y_test,q_test = self.to_catboost_dataset(df_test)\n",
    "        pool_test = Pool(data=X_test, label=y_test, group_id=q_test)\n",
    "        return self.model.predict(pool_test)\n",
    "\n",
    "    # вызывать после выполнения fit\n",
    "    def save_model(self):\n",
    "        self.model.save_model(\"ranking_model\",format=\"cbm\")\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.model = CatBoost()\n",
    "        self.model.load_model(\"ranking_model\",format=\"cbm\")\n",
    "        \n",
    "    def score(self,df_test):\n",
    "        eval_metric = 'NDCG:top=10;type=Exp'\n",
    "\n",
    "        X_test,y_test,q_test = self.to_catboost_dataset(df_test)\n",
    "        y_test = df_test['label'].to_numpy()\n",
    "        q_test = df_test['qid'].to_numpy().astype('uint32')\n",
    "\n",
    "        y_predict = self.predict(df_test)\n",
    "\n",
    "        score = utils.eval_metric(y_test, y_predict, eval_metric, group_id=q_test)\n",
    "        return score[0]\n",
    "\n",
    "\n",
    "\n",
    "    def to_catboost_dataset(self, df):\n",
    "        y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "        q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "        X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "        return (X, y, q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e513b-7c4b-41bf-88f1-8bc5faf3a5dc",
   "metadata": {},
   "source": [
    "Обучение модели на лучших параметрах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b8f45c2-bbd7-40e6-89a0-41e185621f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'YetiRank:mode=Classic;num_neighbours=2', 'iterations': 2000, 'depth': 9, 'learning_rate': 0.05, 'min_data_in_leaf': 1, 'use_best_model': True, 'eval_metric': 'NDCG:top=10;type=Exp', 'early_stopping_rounds': 100, 'random_seed': 22, 'verbose': 10, 'l2_leaf_reg': 0.03}\n",
      "0:\ttest: 0.3400908\tbest: 0.3400908 (0)\ttotal: 461ms\tremaining: 15m 22s\n",
      "10:\ttest: 0.4356727\tbest: 0.4356727 (10)\ttotal: 4.8s\tremaining: 14m 28s\n",
      "20:\ttest: 0.4536279\tbest: 0.4536279 (20)\ttotal: 9.23s\tremaining: 14m 29s\n",
      "30:\ttest: 0.4639935\tbest: 0.4639935 (30)\ttotal: 13.6s\tremaining: 14m 23s\n",
      "40:\ttest: 0.4732485\tbest: 0.4732485 (40)\ttotal: 18s\tremaining: 14m 21s\n",
      "50:\ttest: 0.4779903\tbest: 0.4779903 (50)\ttotal: 22.5s\tremaining: 14m 18s\n",
      "60:\ttest: 0.4841248\tbest: 0.4841248 (60)\ttotal: 27.7s\tremaining: 14m 39s\n",
      "70:\ttest: 0.4883553\tbest: 0.4883553 (70)\ttotal: 32.8s\tremaining: 14m 52s\n",
      "80:\ttest: 0.4914837\tbest: 0.4914837 (80)\ttotal: 38s\tremaining: 15m\n",
      "90:\ttest: 0.4940050\tbest: 0.4940050 (90)\ttotal: 43.1s\tremaining: 15m 4s\n",
      "100:\ttest: 0.4950362\tbest: 0.4954199 (97)\ttotal: 48.2s\tremaining: 15m 6s\n",
      "110:\ttest: 0.4968181\tbest: 0.4972491 (106)\ttotal: 53.3s\tremaining: 15m 7s\n",
      "120:\ttest: 0.4987543\tbest: 0.4987543 (120)\ttotal: 58.3s\tremaining: 15m 5s\n",
      "130:\ttest: 0.4996140\tbest: 0.4996271 (128)\ttotal: 1m 3s\tremaining: 15m 4s\n",
      "140:\ttest: 0.5005681\tbest: 0.5005681 (140)\ttotal: 1m 8s\tremaining: 15m 2s\n",
      "150:\ttest: 0.5020922\tbest: 0.5020922 (150)\ttotal: 1m 13s\tremaining: 15m\n",
      "160:\ttest: 0.5025728\tbest: 0.5028717 (159)\ttotal: 1m 18s\tremaining: 14m 57s\n",
      "170:\ttest: 0.5035581\tbest: 0.5036531 (169)\ttotal: 1m 23s\tremaining: 14m 54s\n",
      "180:\ttest: 0.5046382\tbest: 0.5049045 (179)\ttotal: 1m 28s\tremaining: 14m 51s\n",
      "190:\ttest: 0.5050963\tbest: 0.5050963 (190)\ttotal: 1m 33s\tremaining: 14m 47s\n",
      "200:\ttest: 0.5057287\tbest: 0.5057287 (200)\ttotal: 1m 38s\tremaining: 14m 43s\n",
      "210:\ttest: 0.5064230\tbest: 0.5065470 (209)\ttotal: 1m 43s\tremaining: 14m 39s\n",
      "220:\ttest: 0.5073649\tbest: 0.5073649 (220)\ttotal: 1m 48s\tremaining: 14m 35s\n",
      "230:\ttest: 0.5082766\tbest: 0.5085423 (228)\ttotal: 1m 53s\tremaining: 14m 31s\n",
      "240:\ttest: 0.5081822\tbest: 0.5086903 (236)\ttotal: 1m 58s\tremaining: 14m 27s\n",
      "250:\ttest: 0.5086146\tbest: 0.5086903 (236)\ttotal: 2m 3s\tremaining: 14m 23s\n",
      "260:\ttest: 0.5086792\tbest: 0.5088393 (252)\ttotal: 2m 8s\tremaining: 14m 19s\n",
      "270:\ttest: 0.5089349\tbest: 0.5090134 (264)\ttotal: 2m 14s\tremaining: 14m 15s\n",
      "280:\ttest: 0.5095919\tbest: 0.5095919 (280)\ttotal: 2m 19s\tremaining: 14m 10s\n",
      "290:\ttest: 0.5096910\tbest: 0.5097267 (289)\ttotal: 2m 24s\tremaining: 14m 6s\n",
      "300:\ttest: 0.5098723\tbest: 0.5099276 (297)\ttotal: 2m 29s\tremaining: 14m 2s\n",
      "310:\ttest: 0.5100578\tbest: 0.5102211 (302)\ttotal: 2m 34s\tremaining: 13m 57s\n",
      "320:\ttest: 0.5105259\tbest: 0.5105259 (320)\ttotal: 2m 39s\tremaining: 13m 53s\n",
      "330:\ttest: 0.5103669\tbest: 0.5105376 (328)\ttotal: 2m 44s\tremaining: 13m 48s\n",
      "340:\ttest: 0.5109159\tbest: 0.5109159 (340)\ttotal: 2m 49s\tremaining: 13m 44s\n",
      "350:\ttest: 0.5113973\tbest: 0.5114454 (345)\ttotal: 2m 54s\tremaining: 13m 39s\n",
      "360:\ttest: 0.5114409\tbest: 0.5116902 (355)\ttotal: 2m 59s\tremaining: 13m 34s\n",
      "370:\ttest: 0.5114897\tbest: 0.5116902 (355)\ttotal: 3m 4s\tremaining: 13m 30s\n",
      "380:\ttest: 0.5114139\tbest: 0.5116902 (355)\ttotal: 3m 9s\tremaining: 13m 25s\n",
      "390:\ttest: 0.5112917\tbest: 0.5118765 (383)\ttotal: 3m 14s\tremaining: 13m 20s\n",
      "400:\ttest: 0.5116823\tbest: 0.5118765 (383)\ttotal: 3m 19s\tremaining: 13m 16s\n",
      "410:\ttest: 0.5123304\tbest: 0.5123304 (410)\ttotal: 3m 24s\tremaining: 13m 11s\n",
      "420:\ttest: 0.5122536\tbest: 0.5126520 (417)\ttotal: 3m 29s\tremaining: 13m 6s\n",
      "430:\ttest: 0.5131945\tbest: 0.5136808 (428)\ttotal: 3m 34s\tremaining: 13m 2s\n",
      "440:\ttest: 0.5127857\tbest: 0.5136808 (428)\ttotal: 3m 39s\tremaining: 12m 57s\n",
      "450:\ttest: 0.5132421\tbest: 0.5136808 (428)\ttotal: 3m 44s\tremaining: 12m 52s\n",
      "460:\ttest: 0.5134966\tbest: 0.5136808 (428)\ttotal: 3m 50s\tremaining: 12m 47s\n",
      "470:\ttest: 0.5135214\tbest: 0.5136839 (461)\ttotal: 3m 55s\tremaining: 12m 42s\n",
      "480:\ttest: 0.5134989\tbest: 0.5136839 (461)\ttotal: 4m\tremaining: 12m 38s\n",
      "490:\ttest: 0.5135035\tbest: 0.5140996 (485)\ttotal: 4m 5s\tremaining: 12m 33s\n",
      "500:\ttest: 0.5136073\tbest: 0.5140996 (485)\ttotal: 4m 10s\tremaining: 12m 28s\n",
      "510:\ttest: 0.5140779\tbest: 0.5142881 (508)\ttotal: 4m 15s\tremaining: 12m 23s\n",
      "520:\ttest: 0.5140225\tbest: 0.5142881 (508)\ttotal: 4m 20s\tremaining: 12m 18s\n",
      "530:\ttest: 0.5137501\tbest: 0.5142881 (508)\ttotal: 4m 25s\tremaining: 12m 14s\n",
      "540:\ttest: 0.5140847\tbest: 0.5142881 (508)\ttotal: 4m 30s\tremaining: 12m 9s\n",
      "550:\ttest: 0.5144080\tbest: 0.5144080 (550)\ttotal: 4m 35s\tremaining: 12m 4s\n",
      "560:\ttest: 0.5142842\tbest: 0.5144080 (550)\ttotal: 4m 40s\tremaining: 11m 59s\n",
      "570:\ttest: 0.5141957\tbest: 0.5144794 (566)\ttotal: 4m 45s\tremaining: 11m 54s\n",
      "580:\ttest: 0.5148806\tbest: 0.5148806 (580)\ttotal: 4m 50s\tremaining: 11m 50s\n",
      "590:\ttest: 0.5144376\tbest: 0.5148806 (580)\ttotal: 4m 55s\tremaining: 11m 45s\n",
      "600:\ttest: 0.5143898\tbest: 0.5148806 (580)\ttotal: 5m\tremaining: 11m 40s\n",
      "610:\ttest: 0.5154487\tbest: 0.5154798 (608)\ttotal: 5m 6s\tremaining: 11m 35s\n",
      "620:\ttest: 0.5154141\tbest: 0.5156387 (614)\ttotal: 5m 11s\tremaining: 11m 30s\n",
      "630:\ttest: 0.5151683\tbest: 0.5156387 (614)\ttotal: 5m 16s\tremaining: 11m 25s\n",
      "640:\ttest: 0.5153947\tbest: 0.5156387 (614)\ttotal: 5m 21s\tremaining: 11m 21s\n",
      "650:\ttest: 0.5152388\tbest: 0.5156387 (614)\ttotal: 5m 26s\tremaining: 11m 16s\n",
      "660:\ttest: 0.5152344\tbest: 0.5156387 (614)\ttotal: 5m 31s\tremaining: 11m 12s\n",
      "670:\ttest: 0.5156233\tbest: 0.5156901 (669)\ttotal: 5m 36s\tremaining: 11m 7s\n",
      "680:\ttest: 0.5155885\tbest: 0.5158633 (678)\ttotal: 5m 41s\tremaining: 11m 2s\n",
      "690:\ttest: 0.5155950\tbest: 0.5158633 (678)\ttotal: 5m 46s\tremaining: 10m 57s\n",
      "700:\ttest: 0.5151261\tbest: 0.5158633 (678)\ttotal: 5m 51s\tremaining: 10m 52s\n",
      "710:\ttest: 0.5154741\tbest: 0.5158633 (678)\ttotal: 5m 56s\tremaining: 10m 47s\n",
      "720:\ttest: 0.5159633\tbest: 0.5162049 (718)\ttotal: 6m 2s\tremaining: 10m 42s\n",
      "730:\ttest: 0.5160223\tbest: 0.5162492 (728)\ttotal: 6m 7s\tremaining: 10m 37s\n",
      "740:\ttest: 0.5156267\tbest: 0.5162762 (734)\ttotal: 6m 12s\tremaining: 10m 32s\n",
      "750:\ttest: 0.5153215\tbest: 0.5162762 (734)\ttotal: 6m 17s\tremaining: 10m 27s\n",
      "760:\ttest: 0.5158122\tbest: 0.5162762 (734)\ttotal: 6m 22s\tremaining: 10m 22s\n",
      "770:\ttest: 0.5158246\tbest: 0.5162762 (734)\ttotal: 6m 27s\tremaining: 10m 17s\n",
      "780:\ttest: 0.5158685\tbest: 0.5162762 (734)\ttotal: 6m 32s\tremaining: 10m 12s\n",
      "790:\ttest: 0.5159792\tbest: 0.5162762 (734)\ttotal: 6m 37s\tremaining: 10m 7s\n",
      "800:\ttest: 0.5163988\tbest: 0.5165748 (799)\ttotal: 6m 42s\tremaining: 10m 2s\n",
      "810:\ttest: 0.5164720\tbest: 0.5165748 (799)\ttotal: 6m 47s\tremaining: 9m 57s\n",
      "820:\ttest: 0.5170125\tbest: 0.5170125 (820)\ttotal: 6m 52s\tremaining: 9m 53s\n",
      "830:\ttest: 0.5173589\tbest: 0.5174547 (829)\ttotal: 6m 57s\tremaining: 9m 47s\n",
      "840:\ttest: 0.5173557\tbest: 0.5177211 (833)\ttotal: 7m 3s\tremaining: 9m 43s\n",
      "850:\ttest: 0.5177903\tbest: 0.5178818 (849)\ttotal: 7m 8s\tremaining: 9m 37s\n",
      "860:\ttest: 0.5180015\tbest: 0.5181054 (853)\ttotal: 7m 13s\tremaining: 9m 33s\n",
      "870:\ttest: 0.5180946\tbest: 0.5183752 (867)\ttotal: 7m 18s\tremaining: 9m 28s\n",
      "880:\ttest: 0.5177385\tbest: 0.5183752 (867)\ttotal: 7m 23s\tremaining: 9m 22s\n",
      "890:\ttest: 0.5180709\tbest: 0.5183752 (867)\ttotal: 7m 28s\tremaining: 9m 17s\n",
      "900:\ttest: 0.5180888\tbest: 0.5183752 (867)\ttotal: 7m 33s\tremaining: 9m 12s\n",
      "910:\ttest: 0.5179754\tbest: 0.5183752 (867)\ttotal: 7m 38s\tremaining: 9m 7s\n",
      "920:\ttest: 0.5179379\tbest: 0.5183752 (867)\ttotal: 7m 43s\tremaining: 9m 2s\n",
      "930:\ttest: 0.5181877\tbest: 0.5183752 (867)\ttotal: 7m 48s\tremaining: 8m 57s\n",
      "940:\ttest: 0.5185988\tbest: 0.5185988 (940)\ttotal: 7m 53s\tremaining: 8m 52s\n",
      "950:\ttest: 0.5178994\tbest: 0.5186500 (941)\ttotal: 7m 58s\tremaining: 8m 47s\n",
      "960:\ttest: 0.5181229\tbest: 0.5186500 (941)\ttotal: 8m 3s\tremaining: 8m 42s\n",
      "970:\ttest: 0.5181863\tbest: 0.5186500 (941)\ttotal: 8m 8s\tremaining: 8m 37s\n",
      "980:\ttest: 0.5184159\tbest: 0.5186500 (941)\ttotal: 8m 13s\tremaining: 8m 32s\n",
      "990:\ttest: 0.5188778\tbest: 0.5188778 (990)\ttotal: 8m 18s\tremaining: 8m 27s\n",
      "1000:\ttest: 0.5182424\tbest: 0.5189929 (992)\ttotal: 8m 23s\tremaining: 8m 22s\n",
      "1010:\ttest: 0.5183170\tbest: 0.5189929 (992)\ttotal: 8m 28s\tremaining: 8m 17s\n",
      "1020:\ttest: 0.5185259\tbest: 0.5189929 (992)\ttotal: 8m 33s\tremaining: 8m 12s\n",
      "1030:\ttest: 0.5183897\tbest: 0.5189929 (992)\ttotal: 8m 38s\tremaining: 8m 7s\n",
      "1040:\ttest: 0.5183283\tbest: 0.5189929 (992)\ttotal: 8m 43s\tremaining: 8m 2s\n",
      "1050:\ttest: 0.5180908\tbest: 0.5189929 (992)\ttotal: 8m 48s\tremaining: 7m 57s\n",
      "1060:\ttest: 0.5183342\tbest: 0.5189929 (992)\ttotal: 8m 53s\tremaining: 7m 52s\n",
      "1070:\ttest: 0.5181943\tbest: 0.5189929 (992)\ttotal: 8m 58s\tremaining: 7m 47s\n",
      "1080:\ttest: 0.5178539\tbest: 0.5189929 (992)\ttotal: 9m 3s\tremaining: 7m 42s\n",
      "1090:\ttest: 0.5182224\tbest: 0.5189929 (992)\ttotal: 9m 8s\tremaining: 7m 37s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5189929491\n",
      "bestIteration = 992\n",
      "\n",
      "Shrink model to first 993 iterations.\n",
      "Model fit: elapsed = 552.458\n",
      "Скор модели на тестовом датасете\n",
      "0.510022621403315\n"
     ]
    }
   ],
   "source": [
    "# ячейка для обучения с лучшими параметрами \n",
    "# eё также не надо запускать, если вы хотите просто проверить скор модели \n",
    "import json \n",
    "\n",
    "with open(\"best_hyp.json\",\"r\") as param_file:\n",
    "    best_params = json.load(param_file)\n",
    "\n",
    "\n",
    "print(best_params)\n",
    "model = Model(best_params)\n",
    "\n",
    "\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(df_train, df_valid)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")\n",
    "\n",
    "# сохраняем обученную модель\n",
    "model.save_model()\n",
    "\n",
    "print(\"Скор модели на тестовом датасете\")\n",
    "print(model.score(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eed2f73",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Model.__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ячейка для проверки скора \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# предварительно надо выполнить ячейки связанные с импортированием библиотек и загрузкой + обработкой датасета\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mscore(df_test))\n",
      "\u001b[1;31mTypeError\u001b[0m: Model.__init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "# ячейка для проверки скора \n",
    "# предварительно надо выполнить ячейки связанные с импортированием библиотек и \n",
    "# загрузкой + обработкой датасета\n",
    "\n",
    "with open(\"best_hyp.json\",\"r\") as param_file:\n",
    "    best_params = json.load(param_file)\n",
    "\n",
    "model = Model(params = None)\n",
    "\n",
    "\n",
    "model.load_model(best_params)\n",
    "\n",
    "print(model.score(df_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Ожидаем, что ваша модель покажет результаты выше бейзлайна!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
