{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06efe571-c571-4301-8c84-6a19dea2b9b5",
   "metadata": {},
   "source": [
    "# Домашняя работа по теме \"Машинное обучение ранжированию\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом ДЗ мы:\n",
    "- научимся работать со стандартным датасетом для машинного обучения ранжированию [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- попробуем применить на практике все то, чему мы научились на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c146f0-de33-4b44-bb81-fcf1711ce1f7",
   "metadata": {},
   "source": [
    "## Как будет происходить сдача ДЗ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5eaff-2123-4a5b-ba12-74829b50a5b5",
   "metadata": {},
   "source": [
    "Вам надо:\n",
    "- форкнуть эту репу\n",
    "- создать бранч в котором вы дальше будете работать\n",
    "- реализовать класс Model в этом ноутбуке\n",
    "- убедиться, что ваша реализация выбивает NDCG@10 выше бейзлайна (см. ниже)\n",
    "- запушить ваш бранч и поставить Pull Request\n",
    "- в комментарии написать какой скор вы выбили\n",
    "\n",
    "В таком случае мы (организаторы):\n",
    "\n",
    "- счекаутим вашу бранчу\n",
    "- проверим что ваша реализация действительно выбивает заявленный скор\n",
    "\n",
    "Предполагается, что и вы, и мы работаем в виртаульном окружении как в семинаре про машинное обучение ранжированию: seminars/7-learning-to-rank/requirements.txt(подробнее про работу с виртуальными окружениями README в корне этой репы).\n",
    "\n",
    "Оценка:\n",
    "- За выбитый скор больше **0.507** назначаем **5** баллов, за скор больше (или равно) **0.510** назначаем максимальный балл -- 10 баллов\n",
    "- Тот из участников кто выбъет самый высокий скор получит еще +10 баллов\n",
    "\n",
    "При сдаче кода важно помнить о том, что:\n",
    "- В коде не должно быть захардкоженных с потолка взятых гиперпараметров (таких как число деревьев, learning rate и т.п.) -- обязательно должен быть представлен код который их подбирает!\n",
    "- Решение должно быть стабильно от запуска к запуску (на CPU) т.е. все seed'ы для генераторов случайных чисел должны быть фиксированы\n",
    "- Мы (организаторы) будем запускать код на CPU поэтому, даже если вы использовали для подбора параметров GPU, финальный скор надо репортить на CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from timeit import default_timer as timer\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import datasets, utils, Pool, CatBoost\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3360d8bf-8981-47a6-b68e-952f9e025062",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt\n",
    "clear_output()\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим датасет MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Строго говоря, он состоит их 2х частей:\n",
    "\n",
    "- основной датасет MSLR-WEB30K -- он содержит более 30 тыс. запросов\n",
    "- \"маленький\" датасет MSLR-WEB10K, который содержит только 10 тыс. запросов и является случайным сэмплом датасета MSLR-WEB30K\n",
    "\n",
    "в этом ДЗ мы будем работать с MSLR-WEB10K, т.к. полная версия датасета может просто не поместиться у нас в RAM (и, тем более, в память видеокарты если мы учимся на GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf35bd-9729-48bb-975d-a955b8bd1c56",
   "metadata": {},
   "source": [
    "Будем считать, что мы самостоятельно скачали датасет MSLR-WEB10K с официального сайта, поместили его в папку КОРЕНЬ-ЭТОЙ-РЕПЫ/data/mslr-web10k и раззиповали.\n",
    "\n",
    "В результате у нас должна получиться следующая структура папок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b06baa8-44fe-420b-bad5-4c6f63a66544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mslr-web10k  MSLR-WEB10K.zip\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4d76cb-2eaa-4b48-be86-ea09a25e2fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20K\n",
      "drwxr-xr-x. 2 maksim maksim 4,0K апр 28  2010 Fold1\n",
      "drwxr-xr-x. 2 maksim maksim 4,0K апр 28  2010 Fold2\n",
      "drwxr-xr-x. 2 maksim maksim 4,0K апр 28  2010 Fold3\n",
      "drwxr-xr-x. 2 maksim maksim 4,0K апр 28  2010 Fold4\n",
      "drwxr-xr-x. 2 maksim maksim 4,0K апр 28  2010 Fold5\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../../data/mslr-web10k/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0a87e-eb4a-4b4a-a6b3-0419e29ae539",
   "metadata": {},
   "source": [
    "Заметим, что датасет довольно большой, в распакованном виде он весит 7.7 GB.\n",
    "\n",
    "Датасет состоит из нескольких фолдов, которые по сути представляют из себя разные разбиения одних и тех же данных на обучающее, валидационное и тестовые множеста.\n",
    "\n",
    "Дальше мы будем использовать только первый фолд: Fold1.\n",
    "\n",
    "Заглянем внутрь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa74835-7d91-4c3a-badb-e268027cff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,3G\n",
      "-rw-r--r--. 1 maksim maksim 267M апр 30  2010 test.txt\n",
      "-rw-r--r--. 1 maksim maksim 800M апр 30  2010 train.txt\n",
      "-rw-r--r--. 1 maksim maksim 261M апр 30  2010 vali.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../../data/mslr-web10k/Fold1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5ccf5-d83e-45e6-bd9b-3a6c729925c6",
   "metadata": {},
   "source": [
    "Видим, что у нас 3 файла с говорящими названиями, соответсвующими сплитам нашего датасета.\n",
    "\n",
    "Посмотрим на содержимое одного из файлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922a1401-1e31-4c01-8eae-daf673d8736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 qid:1 1:3 2:3 3:0 4:0 5:3 6:1 7:1 8:0 9:0 10:1 11:156 12:4 13:0 14:7 15:167 16:6.931275 17:22.076928 18:19.673353 19:22.255383 20:6.926551 21:3 22:3 23:0 24:0 25:6 26:1 27:1 28:0 29:0 30:2 31:1 32:1 33:0 34:0 35:2 36:1 37:1 38:0 39:0 40:2 41:0 42:0 43:0 44:0 45:0 46:0.019231 47:0.75000 48:0 49:0 50:0.035928 51:0.00641 52:0.25000 53:0 54:0 55:0.011976 56:0.00641 57:0.25000 58:0 59:0 60:0.011976 61:0.00641 62:0.25000 63:0 64:0 65:0.011976 66:0 67:0 68:0 69:0 70:0 71:6.931275 72:22.076928 73:0 74:0 75:13.853103 76:1.152128 77:5.99246 78:0 79:0 80:2.297197 81:3.078917 82:8.517343 83:0 84:0 85:6.156595 86:2.310425 87:7.358976 88:0 89:0 90:4.617701 91:0.694726 92:1.084169 93:0 94:0 95:2.78795 96:1 97:1 98:0 99:0 100:1 101:1 102:1 103:0 104:0 105:1 106:12.941469 107:20.59276 108:0 109:0 110:16.766961 111:-18.567793 112:-7.760072 113:-20.838749 114:-25.436074 115:-14.518523 116:-21.710022 117:-21.339609 118:-24.497864 119:-27.690319 120:-20.203779 121:-15.449379 122:-4.474452 123:-23.634899 124:-28.119826 125:-13.581932 126:3 127:62 128:11089534 129:2 130:116 131:64034 132:13 133:3 134:0 135:0 136:0 \n"
     ]
    }
   ],
   "source": [
    "!head -n 1 ../../data/mslr-web10k/Fold1/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f4fa9-9ba3-457f-8bf2-f9a7b3112e91",
   "metadata": {},
   "source": [
    "Видим, что данные лежат в уже знакомом нам по семинару формате:\n",
    "\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "В файле qid и все-фичи кодируются в формате КЛЮЧ:ЗНАЧЕНИЕ, напр. 130:116 -- тут 130 это номер фичи, а 116 -- ее значение.\n",
    "\n",
    "Такой формат в мире машинного обучения часто называют svm light формат (в честь когда-то популярной библиотеки SVM-Light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bba78-f04f-478b-b3dc-89c9011cb697",
   "metadata": {},
   "source": [
    "Напишем немного вспомогательного кода для загрузки этого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c29b4f-0b79-4259-b079-fdc589d77ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "    \n",
    "def load_svmlight_file(input_file, max_num_lines=0):\n",
    "    \"\"\"Loads dataset split in SVM-Light format\"\"\"\n",
    "    def _parse_field(field):\n",
    "        parts = field.split(':')\n",
    "        if len(parts) != 2:\n",
    "            raise Exception(f\"invalid number of parts in field {field}\")\n",
    "        return parts\n",
    "\n",
    "    num_features = 136\n",
    "    exp_num_fields = num_features + 2\n",
    "    num_lines = 0\n",
    "    X = []\n",
    "    with open(input_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                num_lines += 1\n",
    "                                  \n",
    "                # Parse into fields\n",
    "                fields = line.rstrip().split(' ')\n",
    "                num_fields = len(fields)\n",
    "                if num_fields != exp_num_fields:\n",
    "                    raise Exception(f\"invalid number of fields {num_fields}\")\n",
    "    \n",
    "                # Parse every field\n",
    "                x = np.zeros(exp_num_fields, dtype=np.float32)\n",
    "                label = int(fields[0])\n",
    "                x[0] = label\n",
    "                _, qid_str = _parse_field(fields[1])\n",
    "                qid = int(qid_str)\n",
    "                x[1] = qid\n",
    "                for i, field in enumerate(fields[2:]):\n",
    "                    _, feature_str = _parse_field(field)\n",
    "                    x[i+2] = float(feature_str)\n",
    "    \n",
    "                # Add new object\n",
    "                X.append(x)\n",
    "                if num_lines % 50000 == 0:\n",
    "                    print(f\"Loaded {num_lines} lines...\")\n",
    "                if max_num_lines > 0 and num_lines == max_num_lines:\n",
    "                    print(f\"WARNING: stop loading, line limit reached: max_num_lines = {max_num_lines} input_file = {input_file}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error at line {num_lines} in {input_file}\") from e\n",
    "    \n",
    "    # To pandas\n",
    "    df = pd.DataFrame(X, columns=generate_column_names(num_features))\n",
    "    print(f\"Loaded SVM-Light file {input_file}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa292cb3-e516-423c-a9b4-315123bddfea",
   "metadata": {},
   "source": [
    "И теперь загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25649947-a7ef-4cbd-8403-7e7456c28327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded 250000 lines...\n",
      "Loaded 300000 lines...\n",
      "Loaded 350000 lines...\n",
      "Loaded 400000 lines...\n",
      "Loaded 450000 lines...\n",
      "Loaded 500000 lines...\n",
      "Loaded 550000 lines...\n",
      "Loaded 600000 lines...\n",
      "Loaded 650000 lines...\n",
      "Loaded 700000 lines...\n",
      "Loaded SVM-Light file ../../data/mslr-web10k/Fold1/train.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ../../data/mslr-web10k/Fold1/vali.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ../../data/mslr-web10k/Fold1/test.txt\n",
      "Dataset loaded from fold_dir ../../data/mslr-web10k/Fold1\n"
     ]
    }
   ],
   "source": [
    "fold_dir = pathlib.Path(\"../../data/mslr-web10k/Fold1\")\n",
    "\n",
    "df_train = load_svmlight_file(fold_dir.joinpath(\"train.txt\"))\n",
    "df_valid = load_svmlight_file(fold_dir.joinpath(\"vali.txt\"))\n",
    "df_test = load_svmlight_file(fold_dir.joinpath(\"test.txt\"))\n",
    "print(f\"Dataset loaded from fold_dir {fold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994de0-9f4a-4582-91f4-8ae1813b0df3",
   "metadata": {},
   "source": [
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b053cf6f-71de-41a9-a255-6e6ce91ea0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  qid  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    2.0  1.0        3.0        3.0        0.0        0.0        3.0   \n",
      "1    2.0  1.0        3.0        0.0        3.0        0.0        3.0   \n",
      "2    0.0  1.0        3.0        0.0        2.0        0.0        3.0   \n",
      "3    2.0  1.0        3.0        0.0        3.0        0.0        3.0   \n",
      "4    1.0  1.0        3.0        0.0        3.0        0.0        3.0   \n",
      "\n",
      "   feature_6  feature_7  feature_8  ...  feature_127  feature_128  \\\n",
      "0        1.0        1.0   0.000000  ...         62.0   11089534.0   \n",
      "1        1.0        0.0   1.000000  ...         54.0   11089534.0   \n",
      "2        1.0        0.0   0.666667  ...         45.0          3.0   \n",
      "3        1.0        0.0   1.000000  ...         56.0   11089534.0   \n",
      "4        1.0        0.0   1.000000  ...         64.0          5.0   \n",
      "\n",
      "   feature_129  feature_130  feature_131  feature_132  feature_133  \\\n",
      "0          2.0        116.0      64034.0         13.0          3.0   \n",
      "1          2.0        124.0      64034.0          1.0          2.0   \n",
      "2          1.0        124.0       3344.0         14.0         67.0   \n",
      "3         13.0        123.0      63933.0          1.0          3.0   \n",
      "4          7.0        256.0      49697.0          1.0         13.0   \n",
      "\n",
      "   feature_134  feature_135  feature_136  \n",
      "0          0.0          0.0          0.0  \n",
      "1          0.0          0.0          0.0  \n",
      "2          0.0          0.0          0.0  \n",
      "3          0.0          0.0          0.0  \n",
      "4          0.0          0.0          0.0  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051e93-845b-45f1-bad8-21020180737e",
   "metadata": {},
   "source": [
    "Т.е. теперь мы видим что данные доступны в точно таком же виде, как это было в семинаре."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Проведем небольшой EDA.\n",
    "\n",
    "Всего у нас 723 тыс. документов в трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa2ad7b6-a90a-4eda-a47f-ec9b407cd12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 723412 entries, 0 to 723411\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float32(138)\n",
      "memory usage: 380.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b79a0-72f8-4c15-9580-9c7c3c22910a",
   "metadata": {},
   "source": [
    "235 тыс. документов в валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2979156-c309-43b9-95a0-d15bc9e594e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235259 entries, 0 to 235258\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float32(138)\n",
      "memory usage: 123.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_valid.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360312-89be-4d21-af28-7c24e7871e89",
   "metadata": {},
   "source": [
    "И 241 тыс. документов в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d64e99fd-93a4-4a60-af94-7e81c7615504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241521 entries, 0 to 241520\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float32(138)\n",
      "memory usage: 127.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7932d-b65e-4b33-b468-c4ef727f4aa6",
   "metadata": {},
   "source": [
    "Сколько у нас запросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c337181-5898-4889-8e4d-ccc872aea83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 6000 train, 2000 valid and 2000 test queries\n"
     ]
    }
   ],
   "source": [
    "num_queries_train = df_train['qid'].nunique()\n",
    "num_queries_valid = df_valid['qid'].nunique()\n",
    "num_queries_test = df_test['qid'].nunique()\n",
    "print(f\"Got {num_queries_train} train, {num_queries_valid} valid and {num_queries_test} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. \n",
    "\n",
    "Объявим класс модели, который надо будем заимлементить в этом ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ab90707-f1b8-4283-ac22-2643baa4ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, df_train, df_valid):\n",
    "        pass\n",
    "\n",
    "    def predict(self, df_test):\n",
    "        return np.random.rand(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e513b-7c4b-41bf-88f1-8bc5faf3a5dc",
   "metadata": {},
   "source": [
    "Создадим и применим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b8f45c2-bbd7-40e6-89a0-41e185621f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit: elapsed = 0.000\n",
      "Predicted: y_hat_test.shape = (241521,)\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = Model()\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(df_train, df_valid)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(df_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric = NDCG:top=10;type=Exp score = 0.227\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "\n",
    "# Get test targets and groups\n",
    "y_test = df_test['label'].to_numpy()\n",
    "q_test = df_test['qid'].to_numpy().astype('uint32')\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Ожидаем, что ваша модель покажет результаты выше бейзлайна!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69f047-dd1a-4794-8b63-600f56e6ef93",
   "metadata": {},
   "source": [
    "## Настоящая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbadbc-fefb-43c4-8034-41fbc4825a91",
   "metadata": {},
   "source": [
    "Создание датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8aacd74-dd97-48f6-9fe4-ddd26e5386db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_catboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_catboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_catboost_dataset(df_test)\n",
    "X_valid, y_valid, q_valid = to_catboost_dataset(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95dbaf96-747d-4daf-917d-546760cc7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_train = Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "pool_test = Pool(data=X_test, label=y_test, group_id=q_test)\n",
    "pool_valid = Pool(data=X_valid, label=y_valid, group_id=q_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938e655-635c-4e5f-9c91-74fbd627aee5",
   "metadata": {},
   "source": [
    "Параметры по-умолчанию дополнены, в функцию, создающую модель, теперь можно передавать словарь параметров, а не только метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0017bd57-d325-419c-949e-436007daa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRIC = 'NDCG:top=10;type=Exp'\n",
    "\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    'n_estimators': 1000,            # maximum possible number of trees\n",
    "    'eval_metric': EVAL_METRIC,    # # metric used for early stopping\n",
    "    'random_seed': 123,\n",
    "    'verbose': 10,\n",
    "    'eta': 0.1,\n",
    "    'max_bin': 64,\n",
    "    'max_depth': 4,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "\n",
    "def create_model(loss_function, p=DEFAULT_PARAMS):\n",
    "    params = copy.deepcopy(p)\n",
    "\n",
    "    # Temporary directory that is used by catboost to store additional information\n",
    "    catboost_info_dir = f\"/tmp/catboost_info.{loss_function.lower()}\"\n",
    "\n",
    "    params.update({\n",
    "        'loss_function': loss_function,\n",
    "        'train_dir': str(catboost_info_dir),\n",
    "    })\n",
    "    return CatBoost(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00400de6-d596-44c5-ac8a-c788b6c3370f",
   "metadata": {},
   "source": [
    "Класс модели почти без изменений. Используются DEFAULT_PARAMS, если не заданы другие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4046cf1a-e778-4e4e-95b4-3937d5d368c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, params=DEFAULT_PARAMS):\n",
    "        self._model = create_model(\"YetiRank\", params)\n",
    "\n",
    "    def fit(self, df_train, df_valid):\n",
    "        self._model.fit(df_train, eval_set=df_valid, use_best_model=True)\n",
    "\n",
    "    def predict(self, df_test):\n",
    "        return self._model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e29a3-3bbc-4aaf-bc2f-2366833ba1ce",
   "metadata": {},
   "source": [
    "Функция quality создаёт модель, обучает её и возвращает метрику (с минусом для минимизации) для валидационной части. Эта функция будет оптимизироваться с помощью HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8fd8481e-af3f-4ee3-abd2-501994cb2847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(p):\n",
    "    params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "    params.update({\n",
    "        'n_estimators': p[\"n_estimators\"],\n",
    "        'eta': p[\"eta\"],\n",
    "        'max_bin': p[\"max_bin\"],\n",
    "        'max_depth': p[\"max_depth\"]\n",
    "    })\n",
    "    model = Model(params)\n",
    "    model.fit(pool_train, pool_valid)\n",
    "    valid_hat = model.predict(pool_valid)\n",
    "\n",
    "    return -utils.eval_metric(y_valid, valid_hat, 'NDCG:top=10;type=Exp', group_id=q_valid)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347ffaa-de88-4364-a8ae-4d72eaad55f0",
   "metadata": {},
   "source": [
    "Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "585c7997-8ea1-452c-b506-e00cee6035cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.027068389291964895, 'max_bin': 235.0, 'max_depth': 9.0, 'n_estimators': 1427.0}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', low=500, high=1500, q=1)),\n",
    "    'eta': hp.uniform('eta', low=0.02, high=0.4),\n",
    "    'max_bin': scope.int(hp.quniform('max_bin', low=63, high=257, q=1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', low=4, high=10, q=1))\n",
    "}\n",
    "    \n",
    "best = fmin(fn=quality, space=space, algo=tpe.suggest, max_evals=10, show_progressbar=True)\n",
    "clear_output()\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106735b-d617-4c5c-bc6f-c8572fa646ba",
   "metadata": {},
   "source": [
    "лучшие параметры: {'eta': 0.027068389291964895, 'max_bin': 235.0, 'max_depth': 9.0, 'n_estimators': 1427.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e18dc1-69e0-426f-900f-38f51f1b6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'eta': 0.027068389291964895, 'max_bin': 235.0, 'max_depth': 9.0, 'n_estimators': 1427.0} # чтобы не запускать подбор каждый раз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98415286-d470-416d-9c9c-1d7f0a937905",
   "metadata": {},
   "source": [
    "Убучаем модель с подобранными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "29a573c3-2e9f-433a-8e81-4abec059356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit: elapsed = 2109.588\n",
      "Predicted: y_hat_test.shape = (241521,)\n"
     ]
    }
   ],
   "source": [
    "params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "params.update({\n",
    "    'n_estimators': int(best['n_estimators']),\n",
    "    'eta': best['eta'],\n",
    "    'max_bin': int(best['max_bin']),\n",
    "    'max_depth': int(best['max_depth'])\n",
    "            })\n",
    "\n",
    "# Create model\n",
    "model = Model(params)\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, pool_valid)\n",
    "elapsed = timer() - start\n",
    "clear_output()\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(pool_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32727b28-dcd1-4268-8af2-03b419befd84",
   "metadata": {},
   "source": [
    "Вычисляем метрики качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "28104a1b-42e4-4921-be8e-25e25013df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric = NDCG:top=10;type=Exp score = 0.510\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487fba67-bb4e-4216-a098-2be0f216e5e1",
   "metadata": {},
   "source": [
    "Результат - 0.510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628198e-f9d9-4fdd-904a-0d35fd76ff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
