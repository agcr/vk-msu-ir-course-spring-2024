{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06efe571-c571-4301-8c84-6a19dea2b9b5",
   "metadata": {},
   "source": [
    "# Домашняя работа по теме \"Машинное обучение ранжированию\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом ДЗ мы:\n",
    "- научимся работать со стандартным датасетом для машинного обучения ранжированию [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- попробуем применить на практике все то, чему мы научились на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c146f0-de33-4b44-bb81-fcf1711ce1f7",
   "metadata": {},
   "source": [
    "## Как будет происходить сдача ДЗ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5eaff-2123-4a5b-ba12-74829b50a5b5",
   "metadata": {},
   "source": [
    "Вам надо:\n",
    "- форкнуть эту репу\n",
    "- создать бранч в котором вы дальше будете работать\n",
    "- реализовать класс Model в этом ноутбуке\n",
    "- убедиться, что ваша реализация выбивает NDCG@10 выше бейзлайна (см. ниже)\n",
    "- запушить ваш бранч и поставить Pull Request\n",
    "- в комментарии написать какой скор вы выбили\n",
    "\n",
    "В таком случае мы (организаторы):\n",
    "\n",
    "- счекаутим вашу бранчу\n",
    "- проверим что ваша реализация действительно выбивает заявленный скор\n",
    "\n",
    "Предполагается, что и вы, и мы работаем в виртаульном окружении как в семинаре про машинное обучение ранжированию: seminars/7-learning-to-rank/requirements.txt(подробнее про работу с виртуальными окружениями README в корне этой репы).\n",
    "\n",
    "Оценка:\n",
    "- За выбитый скор больше **0.507** назначаем **5** баллов, за скор больше (или равно) **0.510** назначаем максимальный балл -- 10 баллов\n",
    "- Тот из участников кто выбъет самый высокий скор получит еще +10 баллов\n",
    "\n",
    "При сдаче кода важно помнить о том, что:\n",
    "- В коде не должно быть захардкоженных с потолка взятых гиперпараметров (таких как число деревьев, learning rate и т.п.) -- обязательно должен быть представлен код который их подбирает!\n",
    "- Решение должно быть стабильно от запуска к запуску (на CPU) т.е. все seed'ы для генераторов случайных чисел должны быть фиксированы\n",
    "- Мы (организаторы) будем запускать код на CPU поэтому, даже если вы использовали для подбора параметров GPU, финальный скор надо репортить на CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import Pool,CatBoost,datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим датасет MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Строго говоря, он состоит их 2х частей:\n",
    "\n",
    "- основной датасет MSLR-WEB30K -- он содержит более 30 тыс. запросов\n",
    "- \"маленький\" датасет MSLR-WEB10K, который содержит только 10 тыс. запросов и является случайным сэмплом датасета MSLR-WEB30K\n",
    "\n",
    "в этом ДЗ мы будем работать с MSLR-WEB10K, т.к. полная версия датасета может просто не поместиться у нас в RAM (и, тем более, в память видеокарты если мы учимся на GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf35bd-9729-48bb-975d-a955b8bd1c56",
   "metadata": {},
   "source": [
    "Будем считать, что мы самостоятельно скачали датасет MSLR-WEB10K с официального сайта, поместили его в папку КОРЕНЬ-ЭТОЙ-РЕПЫ/data/mslr-web10k и раззиповали.\n",
    "\n",
    "В результате у нас должна получиться следующая структура папок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b06baa8-44fe-420b-bad5-4c6f63a66544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls ../../data\n",
    "# mslr-web10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4d76cb-2eaa-4b48-be86-ea09a25e2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ls -lh ../../data/mslr-web10k/\n",
    "# итого 1,2G\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold1\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold2\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold3\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold4\n",
    "# drwxr-xr-x 2 andrei andrei 4,0K апр 28  2010 Fold5\n",
    "# -rw-r--r-- 1 andrei andrei 1,2G июл  7  2016 MSLR-WEB10K.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0a87e-eb4a-4b4a-a6b3-0419e29ae539",
   "metadata": {},
   "source": [
    "Заметим, что датасет довольно большой, в распакованном виде он весит 7.7 GB.\n",
    "\n",
    "Датасет состоит из нескольких фолдов, которые по сути представляют из себя разные разбиения одних и тех же данных на обучающее, валидационное и тестовые множеста.\n",
    "\n",
    "Дальше мы будем использовать только первый фолд: Fold1.\n",
    "\n",
    "Заглянем внутрь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa74835-7d91-4c3a-badb-e268027cff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lh ../../data/mslr-web10k/Fold1\n",
    "# итого 1,3G\n",
    "# -rw-r--r-- 1 andrei andrei 267M апр 30  2010 test.txt\n",
    "# -rw-r--r-- 1 andrei andrei 800M апр 30  2010 train.txt\n",
    "# -rw-r--r-- 1 andrei andrei 261M апр 30  2010 vali.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5ccf5-d83e-45e6-bd9b-3a6c729925c6",
   "metadata": {},
   "source": [
    "Видим, что у нас 3 файла с говорящими названиями, соответсвующими сплитам нашего датасета.\n",
    "\n",
    "Посмотрим на содержимое одного из файлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922a1401-1e31-4c01-8eae-daf673d8736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 1 ../../data/mslr-web10k/Fold1/train.txt\n",
    "#2 qid:1 1:3 2:3 3:0 4:0 5:3 6:1 7:1 8:0 9:0 10:1 11:156 12:4 13:0 14:7 15:167 16:6.931275 17:22.076928 18:19.673353 19:22.255383 20:6.926551 21:3 22:3 23:0 24:0 25:6 26:1 27:1 28:0 29:0 30:2 31:1 32:1 33:0 34:0 35:2 36:1 37:1 38:0 39:0 40:2 41:0 42:0 43:0 44:0 45:0 46:0.019231 47:0.75000 48:0 49:0 50:0.035928 51:0.00641 52:0.25000 53:0 54:0 55:0.011976 56:0.00641 57:0.25000 58:0 59:0 60:0.011976 61:0.00641 62:0.25000 63:0 64:0 65:0.011976 66:0 67:0 68:0 69:0 70:0 71:6.931275 72:22.076928 73:0 74:0 75:13.853103 76:1.152128 77:5.99246 78:0 79:0 80:2.297197 81:3.078917 82:8.517343 83:0 84:0 85:6.156595 86:2.310425 87:7.358976 88:0 89:0 90:4.617701 91:0.694726 92:1.084169 93:0 94:0 95:2.78795 96:1 97:1 98:0 99:0 100:1 101:1 102:1 103:0 104:0 105:1 106:12.941469 107:20.59276 108:0 109:0 110:16.766961 111:-18.567793 112:-7.760072 113:-20.838749 114:-25.436074 115:-14.518523 116:-21.710022 117:-21.339609 118:-24.497864 119:-27.690319 120:-20.203779 121:-15.449379 122:-4.474452 123:-23.634899 124:-28.119826 125:-13.581932 126:3 127:62 128:11089534 129:2 130:116 131:64034 132:13 133:3 134:0 135:0 136:0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f4fa9-9ba3-457f-8bf2-f9a7b3112e91",
   "metadata": {},
   "source": [
    "Видим, что данные лежат в уже знакомом нам по семинару формате:\n",
    "\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "В файле qid и все-фичи кодируются в формате КЛЮЧ:ЗНАЧЕНИЕ, напр. 130:116 -- тут 130 это номер фичи, а 116 -- ее значение.\n",
    "\n",
    "Такой формат в мире машинного обучения часто называют svm light формат (в честь когда-то популярной библиотеки SVM-Light)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970bba78-f04f-478b-b3dc-89c9011cb697",
   "metadata": {},
   "source": [
    "Напишем немного вспомогательного кода для загрузки этого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c29b4f-0b79-4259-b079-fdc589d77ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "    \n",
    "def load_svmlight_file(input_file, max_num_lines=0):\n",
    "    \"\"\"Loads dataset split in SVM-Light format\"\"\"\n",
    "    def _parse_field(field):\n",
    "        parts = field.split(':')\n",
    "        if len(parts) != 2:\n",
    "            raise Exception(f\"invalid number of parts in field {field}\")\n",
    "        return parts\n",
    "\n",
    "    num_features = 136\n",
    "    exp_num_fields = num_features + 2\n",
    "    num_lines = 0\n",
    "    X = []\n",
    "    with open(input_file, 'rt') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                num_lines += 1\n",
    "                                  \n",
    "                # Parse into fields\n",
    "                fields = line.rstrip().split(' ')\n",
    "                num_fields = len(fields)\n",
    "                if num_fields != exp_num_fields:\n",
    "                    raise Exception(f\"invalid number of fields {num_fields}\")\n",
    "    \n",
    "                # Parse every field\n",
    "                x = np.zeros(exp_num_fields, dtype=np.float32)\n",
    "                label = int(fields[0])\n",
    "                x[0] = label\n",
    "                _, qid_str = _parse_field(fields[1])\n",
    "                qid = int(qid_str)\n",
    "                x[1] = qid\n",
    "                for i, field in enumerate(fields[2:]):\n",
    "                    _, feature_str = _parse_field(field)\n",
    "                    x[i+2] = float(feature_str)\n",
    "    \n",
    "                # Add new object\n",
    "                X.append(x)\n",
    "                if num_lines % 50000 == 0:\n",
    "                    print(f\"Loaded {num_lines} lines...\")\n",
    "                if max_num_lines > 0 and num_lines == max_num_lines:\n",
    "                    print(f\"WARNING: stop loading, line limit reached: max_num_lines = {max_num_lines} input_file = {input_file}\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"error at line {num_lines} in {input_file}\") from e\n",
    "    \n",
    "    # To pandas\n",
    "    df = pd.DataFrame(X, columns=generate_column_names(num_features))\n",
    "    print(f\"Loaded SVM-Light file {input_file}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa292cb3-e516-423c-a9b4-315123bddfea",
   "metadata": {},
   "source": [
    "И теперь загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25649947-a7ef-4cbd-8403-7e7456c28327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded 250000 lines...\n",
      "Loaded 300000 lines...\n",
      "Loaded 350000 lines...\n",
      "Loaded 400000 lines...\n",
      "Loaded 450000 lines...\n",
      "Loaded 500000 lines...\n",
      "Loaded 550000 lines...\n",
      "Loaded 600000 lines...\n",
      "Loaded 650000 lines...\n",
      "Loaded 700000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\train.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\vali.txt\n",
      "Loaded 50000 lines...\n",
      "Loaded 100000 lines...\n",
      "Loaded 150000 lines...\n",
      "Loaded 200000 lines...\n",
      "Loaded SVM-Light file ..\\..\\data\\mslr-web10k\\Fold1\\test.txt\n",
      "Dataset loaded from fold_dir ..\\..\\data\\mslr-web10k\\Fold1\n"
     ]
    }
   ],
   "source": [
    "# возможно здесь придётся привести папку mslr... к верхнему регистру\n",
    "# в windows пути к файлам case-insensitive\n",
    "fold_dir = pathlib.Path(\"../../data/mslr-web10k/Fold1\")\n",
    "\n",
    "df_train = load_svmlight_file(fold_dir.joinpath(\"train.txt\"))\n",
    "df_valid = load_svmlight_file(fold_dir.joinpath(\"vali.txt\"))\n",
    "df_test = load_svmlight_file(fold_dir.joinpath(\"test.txt\"))\n",
    "print(f\"Dataset loaded from fold_dir {fold_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. \n",
    "\n",
    "Объявим класс модели, который надо будем заимлементить в этом ДЗ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab90707-f1b8-4283-ac22-2643baa4ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model:\n",
    "    # params = None if model will be loaded\n",
    "    def __init__(self,params=None):\n",
    "        self.model = None \n",
    "        self.params = params\n",
    "\n",
    "    def fit(self, df_train,df_val = None ):\n",
    "        X_train,y_train,q_train = self.to_catboost_dataset(df_train)\n",
    "        pool_train = Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "\n",
    "        X_val,y_val,q_val = self.to_catboost_dataset(df_val)\n",
    "        pool_val = Pool(data=X_val,label=y_val,group_id=q_val)\n",
    "\n",
    "        \n",
    "\n",
    "        self.model = CatBoost(self.params)\n",
    "\n",
    "    \n",
    "        self.model.fit(pool_train,eval_set=pool_val)\n",
    "            \n",
    "\n",
    "\n",
    "    def predict(self, df_test):\n",
    "        X_test,y_test,q_test = self.to_catboost_dataset(df_test)\n",
    "        pool_test = Pool(data=X_test, label=y_test, group_id=q_test)\n",
    "        return self.model.predict(pool_test)\n",
    "\n",
    "    # вызывать после выполнения fit\n",
    "    def save_model(self):\n",
    "        self.model.save_model(\"ranking_model\",format=\"cbm\")\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.model = CatBoost()\n",
    "        self.model.load_model(\"ranking_model\",format=\"cbm\")\n",
    "        \n",
    "    def score(self,df_test):\n",
    "        eval_metric = 'NDCG:top=10;type=Exp'\n",
    "\n",
    "        X_test,y_test,q_test = self.to_catboost_dataset(df_test)\n",
    "        y_test = df_test['label'].to_numpy()\n",
    "        q_test = df_test['qid'].to_numpy().astype('uint32')\n",
    "\n",
    "        y_predict = self.predict(df_test)\n",
    "\n",
    "        score = utils.eval_metric(y_test, y_predict, eval_metric, group_id=q_test)\n",
    "        return score[0]\n",
    "\n",
    "\n",
    "\n",
    "    def to_catboost_dataset(self, df):\n",
    "        y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "        q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "        X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "        return (X, y, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f684f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2923646\tbest: 0.2923646 (0)\ttotal: 424ms\tremaining: 14m 6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     14\u001b[0m param_set \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYetiRank:mode=Classic;num_neighbours=2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2000\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     26\u001b[0m }\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(param_set)\n\u001b[1;32m---> 29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(df_train,df_valid)\n\u001b[0;32m     30\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(df_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, df_train, df_val)\u001b[0m\n\u001b[0;32m     12\u001b[0m pool_val \u001b[38;5;241m=\u001b[39m Pool(data\u001b[38;5;241m=\u001b[39mX_val,label\u001b[38;5;241m=\u001b[39my_val,group_id\u001b[38;5;241m=\u001b[39mq_val)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m CatBoost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(pool_train,eval_set\u001b[38;5;241m=\u001b[39mpool_val)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\site-packages\\catboost\\core.py:2567\u001b[0m, in \u001b[0;36mCatBoost.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cat_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, text_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, embedding_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pairs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, group_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2438\u001b[0m         group_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subgroup_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pairs_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2439\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logging_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, column_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2440\u001b[0m         verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, metric_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2441\u001b[0m         save_snapshot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, snapshot_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, snapshot_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, init_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2442\u001b[0m         log_cout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, log_cerr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2443\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;124;03m    Fit the CatBoost model.\u001b[39;00m\n\u001b[0;32m   2445\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[38;5;124;03m    model : CatBoost\u001b[39;00m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id,\n\u001b[0;32m   2568\u001b[0m                      pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file,\n\u001b[0;32m   2569\u001b[0m                      column_description, verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   2570\u001b[0m                      save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\site-packages\\catboost\\core.py:2396\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2393\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(\n\u001b[0;32m   2397\u001b[0m         train_pool,\n\u001b[0;32m   2398\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2399\u001b[0m         params,\n\u001b[0;32m   2400\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2401\u001b[0m         train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2402\u001b[0m     )\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2405\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\ml\\Lib\\site-packages\\catboost\\core.py:1776\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[38;5;241m.\u001b[39m_object \u001b[38;5;28;01mif\u001b[39;00m init_model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1777\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Приблизительный подбор лучших параметров модели \n",
    "# не надо запускать, если вы просто хотите проверить скор модели \n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "best_params = {}\n",
    "best_score = 0 \n",
    "\n",
    "\n",
    "# перебирать iterations нет смысла при включенном use_best_model\n",
    "for depth in np.arange(6,10,1):\n",
    "    for lr in np.logspace(-2,-1,5):\n",
    "        for reg_value in np.logspace(-2,0,6):\n",
    "            param_set = {\n",
    "                \"loss_function\" : \"YetiRank:mode=Classic;num_neighbours=2\",\n",
    "                \"iterations\": 2000,\n",
    "                \"depth\" :depth,\n",
    "                \"learning_rate\" :0.05,\n",
    "                \"min_data_in_leaf\" : 1,\n",
    "                \"use_best_model\" : True,\n",
    "                \"eval_metric\": \"NDCG:top=10;type=Exp\",\n",
    "                \"early_stopping_rounds\" : 200,\n",
    "                \"random_seed\": 22,\n",
    "                \"verbose\": 10,\n",
    "                \"l2_leaf_reg\": 0.01\n",
    "            }\n",
    "\n",
    "            model = Model(param_set)\n",
    "            model.fit(df_train,df_valid)\n",
    "            score = model.score(df_test)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = deepcopy(param_set)\n",
    "\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e513b-7c4b-41bf-88f1-8bc5faf3a5dc",
   "metadata": {},
   "source": [
    "Обучение модели на лучших параметрах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8f45c2-bbd7-40e6-89a0-41e185621f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.3400908\tbest: 0.3400908 (0)\ttotal: 449ms\tremaining: 14m 58s\n",
      "10:\ttest: 0.4356727\tbest: 0.4356727 (10)\ttotal: 4.92s\tremaining: 14m 49s\n",
      "20:\ttest: 0.4536279\tbest: 0.4536279 (20)\ttotal: 9.29s\tremaining: 14m 35s\n",
      "30:\ttest: 0.4639935\tbest: 0.4639935 (30)\ttotal: 13.8s\tremaining: 14m 38s\n",
      "40:\ttest: 0.4732485\tbest: 0.4732485 (40)\ttotal: 18.4s\tremaining: 14m 40s\n",
      "50:\ttest: 0.4779903\tbest: 0.4779903 (50)\ttotal: 23.1s\tremaining: 14m 43s\n",
      "60:\ttest: 0.4841248\tbest: 0.4841248 (60)\ttotal: 27.9s\tremaining: 14m 47s\n",
      "70:\ttest: 0.4883553\tbest: 0.4883553 (70)\ttotal: 32.4s\tremaining: 14m 39s\n",
      "80:\ttest: 0.4914837\tbest: 0.4914837 (80)\ttotal: 37.2s\tremaining: 14m 40s\n",
      "90:\ttest: 0.4940050\tbest: 0.4940050 (90)\ttotal: 42s\tremaining: 14m 41s\n",
      "100:\ttest: 0.4950362\tbest: 0.4954199 (97)\ttotal: 47.2s\tremaining: 14m 47s\n",
      "110:\ttest: 0.4968181\tbest: 0.4972491 (106)\ttotal: 51.8s\tremaining: 14m 42s\n",
      "120:\ttest: 0.4987543\tbest: 0.4987543 (120)\ttotal: 56.5s\tremaining: 14m 37s\n",
      "130:\ttest: 0.4996140\tbest: 0.4996271 (128)\ttotal: 1m\tremaining: 14m 30s\n",
      "140:\ttest: 0.5005681\tbest: 0.5005681 (140)\ttotal: 1m 5s\tremaining: 14m 24s\n",
      "150:\ttest: 0.5020922\tbest: 0.5020922 (150)\ttotal: 1m 10s\tremaining: 14m 18s\n",
      "160:\ttest: 0.5025728\tbest: 0.5028717 (159)\ttotal: 1m 14s\tremaining: 14m 12s\n",
      "170:\ttest: 0.5035581\tbest: 0.5036531 (169)\ttotal: 1m 20s\tremaining: 14m 16s\n",
      "180:\ttest: 0.5046382\tbest: 0.5049045 (179)\ttotal: 1m 26s\tremaining: 14m 29s\n",
      "190:\ttest: 0.5050963\tbest: 0.5050963 (190)\ttotal: 1m 33s\tremaining: 14m 40s\n",
      "200:\ttest: 0.5057287\tbest: 0.5057287 (200)\ttotal: 1m 39s\tremaining: 14m 50s\n",
      "210:\ttest: 0.5064230\tbest: 0.5065470 (209)\ttotal: 1m 45s\tremaining: 14m 56s\n",
      "220:\ttest: 0.5073649\tbest: 0.5073649 (220)\ttotal: 1m 51s\tremaining: 15m 1s\n",
      "230:\ttest: 0.5082766\tbest: 0.5085423 (228)\ttotal: 1m 58s\tremaining: 15m 6s\n",
      "240:\ttest: 0.5081822\tbest: 0.5086903 (236)\ttotal: 2m 4s\tremaining: 15m 7s\n",
      "250:\ttest: 0.5086146\tbest: 0.5086903 (236)\ttotal: 2m 10s\tremaining: 15m 12s\n",
      "260:\ttest: 0.5086792\tbest: 0.5088393 (252)\ttotal: 2m 17s\tremaining: 15m 14s\n",
      "270:\ttest: 0.5089349\tbest: 0.5090134 (264)\ttotal: 2m 23s\tremaining: 15m 16s\n",
      "280:\ttest: 0.5095919\tbest: 0.5095919 (280)\ttotal: 2m 29s\tremaining: 15m 16s\n",
      "290:\ttest: 0.5096910\tbest: 0.5097267 (289)\ttotal: 2m 36s\tremaining: 15m 17s\n",
      "300:\ttest: 0.5098723\tbest: 0.5099276 (297)\ttotal: 2m 42s\tremaining: 15m 17s\n",
      "310:\ttest: 0.5100578\tbest: 0.5102211 (302)\ttotal: 2m 48s\tremaining: 15m 17s\n",
      "320:\ttest: 0.5105259\tbest: 0.5105259 (320)\ttotal: 2m 55s\tremaining: 15m 17s\n",
      "330:\ttest: 0.5103669\tbest: 0.5105376 (328)\ttotal: 3m 1s\tremaining: 15m 16s\n",
      "340:\ttest: 0.5109159\tbest: 0.5109159 (340)\ttotal: 3m 8s\tremaining: 15m 14s\n",
      "350:\ttest: 0.5113973\tbest: 0.5114454 (345)\ttotal: 3m 14s\tremaining: 15m 13s\n",
      "360:\ttest: 0.5114409\tbest: 0.5116902 (355)\ttotal: 3m 20s\tremaining: 15m 10s\n",
      "370:\ttest: 0.5114897\tbest: 0.5116902 (355)\ttotal: 3m 26s\tremaining: 15m 8s\n",
      "380:\ttest: 0.5114139\tbest: 0.5116902 (355)\ttotal: 3m 33s\tremaining: 15m 6s\n",
      "390:\ttest: 0.5112917\tbest: 0.5118765 (383)\ttotal: 3m 39s\tremaining: 15m 3s\n",
      "400:\ttest: 0.5116823\tbest: 0.5118765 (383)\ttotal: 3m 45s\tremaining: 15m\n",
      "410:\ttest: 0.5123304\tbest: 0.5123304 (410)\ttotal: 3m 52s\tremaining: 14m 57s\n",
      "420:\ttest: 0.5122536\tbest: 0.5126520 (417)\ttotal: 3m 58s\tremaining: 14m 53s\n",
      "430:\ttest: 0.5131945\tbest: 0.5136808 (428)\ttotal: 4m 4s\tremaining: 14m 49s\n",
      "440:\ttest: 0.5127857\tbest: 0.5136808 (428)\ttotal: 4m 10s\tremaining: 14m 45s\n",
      "450:\ttest: 0.5132421\tbest: 0.5136808 (428)\ttotal: 4m 16s\tremaining: 14m 42s\n",
      "460:\ttest: 0.5134966\tbest: 0.5136808 (428)\ttotal: 4m 23s\tremaining: 14m 38s\n",
      "470:\ttest: 0.5135214\tbest: 0.5136839 (461)\ttotal: 4m 29s\tremaining: 14m 34s\n",
      "480:\ttest: 0.5134989\tbest: 0.5136839 (461)\ttotal: 4m 35s\tremaining: 14m 30s\n",
      "490:\ttest: 0.5135035\tbest: 0.5140996 (485)\ttotal: 4m 42s\tremaining: 14m 27s\n",
      "500:\ttest: 0.5136073\tbest: 0.5140996 (485)\ttotal: 4m 48s\tremaining: 14m 22s\n",
      "510:\ttest: 0.5140779\tbest: 0.5142881 (508)\ttotal: 4m 54s\tremaining: 14m 17s\n",
      "520:\ttest: 0.5140225\tbest: 0.5142881 (508)\ttotal: 5m\tremaining: 14m 12s\n",
      "530:\ttest: 0.5137501\tbest: 0.5142881 (508)\ttotal: 5m 6s\tremaining: 14m 8s\n",
      "540:\ttest: 0.5140847\tbest: 0.5142881 (508)\ttotal: 5m 12s\tremaining: 14m 3s\n",
      "550:\ttest: 0.5144080\tbest: 0.5144080 (550)\ttotal: 5m 19s\tremaining: 13m 59s\n",
      "560:\ttest: 0.5142842\tbest: 0.5144080 (550)\ttotal: 5m 25s\tremaining: 13m 55s\n",
      "570:\ttest: 0.5141957\tbest: 0.5144794 (566)\ttotal: 5m 31s\tremaining: 13m 50s\n",
      "580:\ttest: 0.5148806\tbest: 0.5148806 (580)\ttotal: 5m 38s\tremaining: 13m 45s\n",
      "590:\ttest: 0.5144376\tbest: 0.5148806 (580)\ttotal: 5m 44s\tremaining: 13m 41s\n",
      "600:\ttest: 0.5143898\tbest: 0.5148806 (580)\ttotal: 5m 51s\tremaining: 13m 37s\n",
      "610:\ttest: 0.5154487\tbest: 0.5154798 (608)\ttotal: 5m 55s\tremaining: 13m 29s\n",
      "620:\ttest: 0.5154141\tbest: 0.5156387 (614)\ttotal: 6m\tremaining: 13m 20s\n",
      "630:\ttest: 0.5151683\tbest: 0.5156387 (614)\ttotal: 6m 4s\tremaining: 13m 11s\n",
      "640:\ttest: 0.5153947\tbest: 0.5156387 (614)\ttotal: 6m 9s\tremaining: 13m 3s\n",
      "650:\ttest: 0.5152388\tbest: 0.5156387 (614)\ttotal: 6m 14s\tremaining: 12m 55s\n",
      "660:\ttest: 0.5152344\tbest: 0.5156387 (614)\ttotal: 6m 18s\tremaining: 12m 46s\n",
      "670:\ttest: 0.5156233\tbest: 0.5156901 (669)\ttotal: 6m 23s\tremaining: 12m 38s\n",
      "680:\ttest: 0.5155885\tbest: 0.5158633 (678)\ttotal: 6m 27s\tremaining: 12m 30s\n",
      "690:\ttest: 0.5155950\tbest: 0.5158633 (678)\ttotal: 6m 32s\tremaining: 12m 23s\n",
      "700:\ttest: 0.5151261\tbest: 0.5158633 (678)\ttotal: 6m 36s\tremaining: 12m 15s\n",
      "710:\ttest: 0.5154741\tbest: 0.5158633 (678)\ttotal: 6m 41s\tremaining: 12m 8s\n",
      "720:\ttest: 0.5159633\tbest: 0.5162049 (718)\ttotal: 6m 46s\tremaining: 12m\n",
      "730:\ttest: 0.5160223\tbest: 0.5162492 (728)\ttotal: 6m 50s\tremaining: 11m 53s\n",
      "740:\ttest: 0.5156267\tbest: 0.5162762 (734)\ttotal: 6m 55s\tremaining: 11m 45s\n",
      "750:\ttest: 0.5153215\tbest: 0.5162762 (734)\ttotal: 6m 59s\tremaining: 11m 38s\n",
      "760:\ttest: 0.5158122\tbest: 0.5162762 (734)\ttotal: 7m 4s\tremaining: 11m 31s\n",
      "770:\ttest: 0.5158246\tbest: 0.5162762 (734)\ttotal: 7m 9s\tremaining: 11m 24s\n",
      "780:\ttest: 0.5158685\tbest: 0.5162762 (734)\ttotal: 7m 13s\tremaining: 11m 17s\n",
      "790:\ttest: 0.5159792\tbest: 0.5162762 (734)\ttotal: 7m 18s\tremaining: 11m 10s\n",
      "800:\ttest: 0.5163988\tbest: 0.5165748 (799)\ttotal: 7m 23s\tremaining: 11m 3s\n",
      "810:\ttest: 0.5164720\tbest: 0.5165748 (799)\ttotal: 7m 27s\tremaining: 10m 56s\n",
      "820:\ttest: 0.5170125\tbest: 0.5170125 (820)\ttotal: 7m 32s\tremaining: 10m 49s\n",
      "830:\ttest: 0.5173589\tbest: 0.5174547 (829)\ttotal: 7m 36s\tremaining: 10m 42s\n",
      "840:\ttest: 0.5173557\tbest: 0.5177211 (833)\ttotal: 7m 41s\tremaining: 10m 36s\n",
      "850:\ttest: 0.5177903\tbest: 0.5178818 (849)\ttotal: 7m 46s\tremaining: 10m 29s\n",
      "860:\ttest: 0.5180015\tbest: 0.5181054 (853)\ttotal: 7m 50s\tremaining: 10m 22s\n",
      "870:\ttest: 0.5180946\tbest: 0.5183752 (867)\ttotal: 7m 55s\tremaining: 10m 16s\n",
      "880:\ttest: 0.5177385\tbest: 0.5183752 (867)\ttotal: 8m\tremaining: 10m 9s\n",
      "890:\ttest: 0.5180709\tbest: 0.5183752 (867)\ttotal: 8m 4s\tremaining: 10m 3s\n",
      "900:\ttest: 0.5180888\tbest: 0.5183752 (867)\ttotal: 8m 9s\tremaining: 9m 56s\n",
      "910:\ttest: 0.5179754\tbest: 0.5183752 (867)\ttotal: 8m 14s\tremaining: 9m 50s\n",
      "920:\ttest: 0.5179379\tbest: 0.5183752 (867)\ttotal: 8m 18s\tremaining: 9m 44s\n",
      "930:\ttest: 0.5181877\tbest: 0.5183752 (867)\ttotal: 8m 23s\tremaining: 9m 37s\n",
      "940:\ttest: 0.5185988\tbest: 0.5185988 (940)\ttotal: 8m 27s\tremaining: 9m 31s\n",
      "950:\ttest: 0.5178994\tbest: 0.5186500 (941)\ttotal: 8m 32s\tremaining: 9m 25s\n",
      "960:\ttest: 0.5181229\tbest: 0.5186500 (941)\ttotal: 8m 37s\tremaining: 9m 19s\n",
      "970:\ttest: 0.5181863\tbest: 0.5186500 (941)\ttotal: 8m 41s\tremaining: 9m 12s\n",
      "980:\ttest: 0.5184159\tbest: 0.5186500 (941)\ttotal: 8m 46s\tremaining: 9m 6s\n",
      "990:\ttest: 0.5188778\tbest: 0.5188778 (990)\ttotal: 8m 50s\tremaining: 9m\n",
      "1000:\ttest: 0.5182424\tbest: 0.5189929 (992)\ttotal: 8m 55s\tremaining: 8m 54s\n",
      "1010:\ttest: 0.5183170\tbest: 0.5189929 (992)\ttotal: 9m\tremaining: 8m 48s\n",
      "1020:\ttest: 0.5185259\tbest: 0.5189929 (992)\ttotal: 9m 4s\tremaining: 8m 42s\n",
      "1030:\ttest: 0.5183897\tbest: 0.5189929 (992)\ttotal: 9m 9s\tremaining: 8m 36s\n",
      "1040:\ttest: 0.5183283\tbest: 0.5189929 (992)\ttotal: 9m 14s\tremaining: 8m 30s\n",
      "1050:\ttest: 0.5180908\tbest: 0.5189929 (992)\ttotal: 9m 18s\tremaining: 8m 24s\n",
      "1060:\ttest: 0.5183342\tbest: 0.5189929 (992)\ttotal: 9m 23s\tremaining: 8m 18s\n",
      "1070:\ttest: 0.5181943\tbest: 0.5189929 (992)\ttotal: 9m 27s\tremaining: 8m 12s\n",
      "1080:\ttest: 0.5178539\tbest: 0.5189929 (992)\ttotal: 9m 32s\tremaining: 8m 6s\n",
      "1090:\ttest: 0.5182224\tbest: 0.5189929 (992)\ttotal: 9m 37s\tremaining: 8m\n",
      "1100:\ttest: 0.5179778\tbest: 0.5189929 (992)\ttotal: 9m 41s\tremaining: 7m 55s\n",
      "1110:\ttest: 0.5179968\tbest: 0.5189929 (992)\ttotal: 9m 46s\tremaining: 7m 49s\n",
      "1120:\ttest: 0.5174244\tbest: 0.5189929 (992)\ttotal: 9m 51s\tremaining: 7m 43s\n",
      "1130:\ttest: 0.5177557\tbest: 0.5189929 (992)\ttotal: 9m 55s\tremaining: 7m 37s\n",
      "1140:\ttest: 0.5175467\tbest: 0.5189929 (992)\ttotal: 10m\tremaining: 7m 32s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.5189929491\n",
      "bestIteration = 992\n",
      "\n",
      "Shrink model to first 993 iterations.\n",
      "Model fit: elapsed = 603.069\n",
      "Скор модели на тестовом датасете\n",
      "0.510022621403315\n"
     ]
    }
   ],
   "source": [
    "# ячейка для обучения с лучшими параметрами \n",
    "# eё также не надо запускать, если вы хотите просто проверить скор модели \n",
    "import json \n",
    "\n",
    "with open(\"best_hyp.json\",\"r\") as param_file:\n",
    "    best_params = json.load(param_file)\n",
    "\n",
    "\n",
    "model = Model(best_params)\n",
    "\n",
    "\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(df_train, df_valid)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")\n",
    "\n",
    "# сохраняем обученную модель\n",
    "model.save_model()\n",
    "\n",
    "print(\"Скор модели на тестовом датасете\")\n",
    "print(model.score(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eed2f73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ячейка для проверки скора \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# предварительно надо выполнить ячейки связанные с импортированием библиотек и \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# загрузкой + обработкой датасета\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_hyp.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m param_file:\n\u001b[1;32m----> 6\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(param_file)\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model(best_params)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# ячейка для проверки скора \n",
    "# предварительно надо выполнить ячейки связанные с импортированием библиотек и \n",
    "# загрузкой + обработкой датасета\n",
    "\n",
    "with open(\"best_hyp.json\",\"r\") as param_file:\n",
    "    best_params = json.load(param_file)\n",
    "\n",
    "model = Model(params = None)\n",
    "\n",
    "\n",
    "model.load_model(best_params)\n",
    "\n",
    "print(model.score(df_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Ожидаем, что ваша модель покажет результаты выше бейзлайна!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
