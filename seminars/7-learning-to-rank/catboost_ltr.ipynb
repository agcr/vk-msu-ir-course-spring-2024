{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02e2af1-998e-4b33-8220-62270916d947",
   "metadata": {},
   "source": [
    "# Машинное обучение ранжированию с помощью библиотеки CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом примере мы:\n",
    "- увидим как выглядят датасеты для машинного обучения ранжированию, на примере стандартного датасета [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "- познакомимся с библиотекой **CatBoost**\n",
    "- научимся решать задачу машинного обучения ранжирования используя алгоритмы, реализованные в **CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Библиотека CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcdafd-ae04-41ff-97ee-cab61fee61aa",
   "metadata": {},
   "source": [
    "Полезные ссылки:\n",
    "- домашняя страница: https://catboost.ai/\n",
    "- официальный тюториал по машинному обучению ранжированию: https://github.com/catboost/tutorials/blob/master/ranking/ranking_tutorial.ipynb\n",
    "- полный список доступных для оптимизации метрик и лоссов: https://catboost.ai/en/docs/concepts/loss-functions-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd118ff-063c-42fd-8883-64ab2d738202",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import catboost\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Дальше мы будем работать с датасетом MSLR.\n",
    "\n",
    "Полный датасет можно скачать с официального сайта: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "\n",
    "Мы этого делать не будем т.к. в CatBoost уже встроена возможность загрузить небольшой сабсет MSLR, с которым мы и будем работать дальше.\n",
    "\n",
    "Загрузим этот сабсет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61225ba7-5615-4e17-93e3-cbf592d3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = datasets.msrank_10k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86994de0-9f4a-4582-91f4-8ae1813b0df3",
   "metadata": {},
   "source": [
    "Датасет представляет собой обычный табличный датасет из 130 колонок:\n",
    "- В первой колонке лежит таргет (оценка асессора), по 5-балльной шкале релевантности: от 0 до 4 (включительно)\n",
    "- Во второй колонке лежит ID запроса, по которому можно сгруппировать все оценки документов в рамках одного и того же запроса\n",
    "- Дальше идет вектор из 128 фичей (таких как значения BM25 и т.п.), их точная природа нам сейчас на важна\n",
    "\n",
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b053cf6f-71de-41a9-a255-6e6ce91ea0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8         9    ...  128       129  \\\n",
      "0  2.0    1    3    3    0    0    3  1.0  1.0  0.000000  ...   62  11089534   \n",
      "1  2.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   54  11089534   \n",
      "2  0.0    1    3    0    2    0    3  1.0  0.0  0.666667  ...   45         3   \n",
      "3  2.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   56  11089534   \n",
      "4  1.0    1    3    0    3    0    3  1.0  0.0  1.000000  ...   64         5   \n",
      "\n",
      "   130  131    132  133  134  135  136  137  \n",
      "0    2  116  64034   13    3    0    0  0.0  \n",
      "1    2  124  64034    1    2    0    0  0.0  \n",
      "2    1  124   3344   14   67    0    0  0.0  \n",
      "3   13  123  63933    1    3    0    0  0.0  \n",
      "4    7  256  49697    1   13    0    0  0.0  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d21-056f-42d8-a007-966444ab0996",
   "metadata": {},
   "source": [
    "Для удобства присвоим колонкам говорящие имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027e3c18-6103-4914-a872-cbc7879fce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "# Assign column names\n",
    "columns = generate_column_names(num_features=136)\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cb1b-4ad1-438f-b6d8-fd1676c34683",
   "metadata": {},
   "source": [
    "Теперь наши данные выглядят красивее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916f781c-8850-4dae-b619-cdc7ac0cc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  qid  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    2.0    1          3          3          0          0          3   \n",
      "1    2.0    1          3          0          3          0          3   \n",
      "2    0.0    1          3          0          2          0          3   \n",
      "3    2.0    1          3          0          3          0          3   \n",
      "4    1.0    1          3          0          3          0          3   \n",
      "\n",
      "   feature_6  feature_7  feature_8  ...  feature_127  feature_128  \\\n",
      "0        1.0        1.0   0.000000  ...           62     11089534   \n",
      "1        1.0        0.0   1.000000  ...           54     11089534   \n",
      "2        1.0        0.0   0.666667  ...           45            3   \n",
      "3        1.0        0.0   1.000000  ...           56     11089534   \n",
      "4        1.0        0.0   1.000000  ...           64            5   \n",
      "\n",
      "   feature_129  feature_130  feature_131  feature_132  feature_133  \\\n",
      "0            2          116        64034           13            3   \n",
      "1            2          124        64034            1            2   \n",
      "2            1          124         3344           14           67   \n",
      "3           13          123        63933            1            3   \n",
      "4            7          256        49697            1           13   \n",
      "\n",
      "   feature_134  feature_135  feature_136  \n",
      "0            0            0          0.0  \n",
      "1            0            0          0.0  \n",
      "2            0            0          0.0  \n",
      "3            0            0          0.0  \n",
      "4            0            0          0.0  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Проведем небольшой EDA.\n",
    "\n",
    "Всего у нас 10000 документов в трейне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2ad7b6-a90a-4eda-a47f-ec9b407cd12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float64(97), int64(41)\n",
      "memory usage: 10.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e360312-89be-4d21-af28-7c24e7871e89",
   "metadata": {},
   "source": [
    "И 10000 документов в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64e99fd-93a4-4a60-af94-7e81c7615504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 138 entries, label to feature_136\n",
      "dtypes: float64(97), int64(41)\n",
      "memory usage: 10.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7932d-b65e-4b33-b468-c4ef727f4aa6",
   "metadata": {},
   "source": [
    "Сколько у нас запросов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c337181-5898-4889-8e4d-ccc872aea83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 87 train and 88 test queries\n"
     ]
    }
   ],
   "source": [
    "num_queries_train = df_train['qid'].nunique()\n",
    "num_queries_test = df_test['qid'].nunique()\n",
    "print(f\"Got {num_queries_train} train and {num_queries_test} test queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd93a2-8714-473c-9a0a-259749f651a3",
   "metadata": {},
   "source": [
    "Получается, у нас примерно по 100 документов на запрос.\n",
    "\n",
    "Это типично, когда, например, для сбора датасета обкачивались и заливались на оценку топ-100 документов поисковой выдачи по случайным запросам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8ba6b-aef3-4a13-884e-65da7f014abd",
   "metadata": {},
   "source": [
    "Теперь посмотрим на распределение таргетов (оценок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e427aaa-d453-4843-b824-4ebfb7897955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    5481\n",
      "1.0    3000\n",
      "2.0    1326\n",
      "3.0     142\n",
      "4.0      51\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec1d3dc2-54f6-46d1-b238-daed3743a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0.0    5755\n",
      "1.0    2830\n",
      "2.0    1221\n",
      "3.0     148\n",
      "4.0      46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fddaa-d7ba-453a-aa5f-5bc834be9951",
   "metadata": {},
   "source": [
    "Теперь нам надо представить датасет в формате, который можно подавать на вход катбустовой модели.  \n",
    "Для этого придется разделить его на 3 части:\n",
    "\n",
    "- **y** -- вектор таргетов\n",
    "- **X** -- тензор из фичей\n",
    "- **q** -- вектор из ID запросов, которые позволяют сгруппировать все документы, которые относятся к одному и тому же запросу\n",
    "\n",
    "CatBoost требует, чтобы в векторе **q** одинаковые ID запроса шли подряд (но в отличие от, например, xgboost, не требует их строгой сортированности). Однако в нашем случае никаких дополнительных действий не потребуется т.к. датасет уже и так отсортирован по qid.\n",
    "\n",
    "Убедимся в этом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e672a4fc-7cf6-4ee5-a598-286dde967d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df_train['qid'].is_monotonic_increasing)\n",
    "print(df_test['qid'].is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11ffa59a-97c7-4e73-b10f-c7d722e6ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by='qid', inplace=True)\n",
    "df_test.sort_values(by='qid', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885edf-16c5-4e99-b376-61e72e1b2b93",
   "metadata": {},
   "source": [
    "Сконвертируем датасет в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f15870f-9459-48d7-a69d-5cd26c23f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_catboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_catboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_catboost_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем pointwise модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. Мы начнем с простой pointwise модели которая в качестве лосса использует обычное RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0534f6-713f-4fa1-83c6-5d20104c1495",
   "metadata": {},
   "source": [
    "Подготовим пулы катбуста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22758401-b1aa-4eee-a6d5-2dfc257ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_train = catboost.Pool(data=X_train, label=y_train, group_id=q_train)\n",
    "pool_test = catboost.Pool(data=X_test, label=y_test, group_id=q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f73c0-7873-4676-aad0-7eeb1f1a78f7",
   "metadata": {},
   "source": [
    "Зададим целевую метрику, которую будем оптимизировать.  \n",
    "В нашем случае будем использовать NDCG@10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d34305a-86c9-429b-b571-dd3d132c5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRIC = 'NDCG:top=10;type=Exp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb13c5-d705-4f42-85cd-e19e5ea66e1f",
   "metadata": {},
   "source": [
    "Подготовим параметры обучения модели, в т.ч.:\n",
    "- целевую метрику\n",
    "- сид генератора случайных чисел\n",
    "- число итераций, после которого останавливаем обучение если в течение данного числа итераций мы не наблюдаем улучшения целевой метрики на валидационном множестве\n",
    "\n",
    "Если хотим обучаться на GPU, то еще надо добавить параметр *task_type=GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1842e3be-6a55-4baf-a2e7-6bf63a2a2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'iterations': 1000,            # maximum possible number of trees\n",
    "    'early_stopping_rounds': 100,  # stop if metric does not improve for N rounds\n",
    "    'eval_metric': EVAL_METRIC,    # # metric used for early stopping\n",
    "    'random_seed': 22,\n",
    "    'verbose': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3700ad-b190-4ea5-aa5f-e2999284f73f",
   "metadata": {},
   "source": [
    "Мы будем обучать разные модели, использующие разные лоссы, соответствующие разным алгоритмам машинного обучения ранжированию.  \n",
    "Напишем функцию, которая позволит кастомизировать модель под нужный лосс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1caad53-8a10-4a91-bfd5-58399c0fd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(loss_function):\n",
    "    params = copy.deepcopy(DEFAULT_PARAMS)\n",
    "\n",
    "    # Temporary directory that is used by catboost to store additional information\n",
    "    catboost_info_dir = f\"/tmp/catboost_info.{loss_function.lower()}\"\n",
    "\n",
    "    params.update({\n",
    "        'loss_function': loss_function,\n",
    "        # 'train_dir': str(catboost_info_dir),\n",
    "    })\n",
    "    return catboost.CatBoost(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a3880-e714-4d18-a1a9-9234d01db4dc",
   "metadata": {},
   "source": [
    "Создадим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebd5d6e5-e4cb-4d31-940c-06e6be853ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoost object at 0x00000179016905C0>\n"
     ]
    }
   ],
   "source": [
    "model = create_model('RMSE')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9414a4-c51b-41f1-8d7f-e7eb3fca9446",
   "metadata": {},
   "source": [
    "И зафитим ее на нашем обучающем множестве.\n",
    "\n",
    "Количество деревьев будет выбрано автоматически с использованием т.н. early stopping -- процесс обучения будем остановлен после того, как на валидационном множестве перестанет расти наша целевая метрика (т.е. NDCG). Обратите внимание что в данном случае целевая метрика (NDCG) отличается от лосса, который мы оптизириуем (RMSE).\n",
    "\n",
    "Для этого передадим в функцию fit() в качестве валидационного множества (параметр eval_set) наш тест-сет.\n",
    "\n",
    "ВНИМАНИЕ: строго говоря, так делать нельзя т.к. приведет к переобучению. По хорошему, мы должны были сначала разбить наш трейн на собственно обучающее и валидационное множества, и передавать в eval_set уже это валидационное множества. А тест-сет надо было сохранить и использовать уже только в самом конце для подсчета финальных скоров. Однако, для простоты, мы так делать не будем, и оставим все это в качестве упражнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f093276-08d9-462a-af6a-39a7e6fd0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.073096\n",
      "0:\ttest: 0.2493536\tbest: 0.2493536 (0)\ttotal: 161ms\tremaining: 2m 40s\n",
      "10:\ttest: 0.3825128\tbest: 0.3886914 (9)\ttotal: 296ms\tremaining: 26.6s\n",
      "20:\ttest: 0.3867278\tbest: 0.3886914 (9)\ttotal: 414ms\tremaining: 19.3s\n",
      "30:\ttest: 0.3896056\tbest: 0.3896056 (30)\ttotal: 541ms\tremaining: 16.9s\n",
      "40:\ttest: 0.3973093\tbest: 0.3983815 (39)\ttotal: 662ms\tremaining: 15.5s\n",
      "50:\ttest: 0.4030989\tbest: 0.4063283 (46)\ttotal: 786ms\tremaining: 14.6s\n",
      "60:\ttest: 0.4085673\tbest: 0.4085673 (60)\ttotal: 906ms\tremaining: 13.9s\n",
      "70:\ttest: 0.4053967\tbest: 0.4108300 (65)\ttotal: 1.04s\tremaining: 13.7s\n",
      "80:\ttest: 0.4091555\tbest: 0.4134532 (75)\ttotal: 1.22s\tremaining: 13.8s\n",
      "90:\ttest: 0.4050574\tbest: 0.4134532 (75)\ttotal: 1.41s\tremaining: 14.1s\n",
      "100:\ttest: 0.4087148\tbest: 0.4134532 (75)\ttotal: 1.56s\tremaining: 13.9s\n",
      "110:\ttest: 0.4114762\tbest: 0.4134532 (75)\ttotal: 1.74s\tremaining: 13.9s\n",
      "120:\ttest: 0.4098458\tbest: 0.4140502 (112)\ttotal: 1.88s\tremaining: 13.7s\n",
      "130:\ttest: 0.4117132\tbest: 0.4140502 (112)\ttotal: 2.03s\tremaining: 13.5s\n",
      "140:\ttest: 0.4130498\tbest: 0.4142162 (139)\ttotal: 2.15s\tremaining: 13.1s\n",
      "150:\ttest: 0.4098606\tbest: 0.4151538 (141)\ttotal: 2.29s\tremaining: 12.9s\n",
      "160:\ttest: 0.4108536\tbest: 0.4151538 (141)\ttotal: 2.41s\tremaining: 12.6s\n",
      "170:\ttest: 0.4121530\tbest: 0.4151538 (141)\ttotal: 2.54s\tremaining: 12.3s\n",
      "180:\ttest: 0.4127425\tbest: 0.4151538 (141)\ttotal: 2.67s\tremaining: 12.1s\n",
      "190:\ttest: 0.4086853\tbest: 0.4151538 (141)\ttotal: 2.8s\tremaining: 11.9s\n",
      "200:\ttest: 0.4125806\tbest: 0.4151538 (141)\ttotal: 2.92s\tremaining: 11.6s\n",
      "210:\ttest: 0.4135679\tbest: 0.4162982 (209)\ttotal: 3.08s\tremaining: 11.5s\n",
      "220:\ttest: 0.4143735\tbest: 0.4166803 (212)\ttotal: 3.26s\tremaining: 11.5s\n",
      "230:\ttest: 0.4110314\tbest: 0.4166803 (212)\ttotal: 3.4s\tremaining: 11.3s\n",
      "240:\ttest: 0.4146108\tbest: 0.4166803 (212)\ttotal: 3.52s\tremaining: 11.1s\n",
      "250:\ttest: 0.4157122\tbest: 0.4167856 (248)\ttotal: 3.65s\tremaining: 10.9s\n",
      "260:\ttest: 0.4170053\tbest: 0.4187076 (257)\ttotal: 3.77s\tremaining: 10.7s\n",
      "270:\ttest: 0.4149611\tbest: 0.4187076 (257)\ttotal: 3.89s\tremaining: 10.5s\n",
      "280:\ttest: 0.4140893\tbest: 0.4187076 (257)\ttotal: 4.02s\tremaining: 10.3s\n",
      "290:\ttest: 0.4145595\tbest: 0.4187076 (257)\ttotal: 4.16s\tremaining: 10.1s\n",
      "300:\ttest: 0.4166590\tbest: 0.4187076 (257)\ttotal: 4.28s\tremaining: 9.94s\n",
      "310:\ttest: 0.4175529\tbest: 0.4193710 (307)\ttotal: 4.41s\tremaining: 9.77s\n",
      "320:\ttest: 0.4151739\tbest: 0.4193710 (307)\ttotal: 4.53s\tremaining: 9.58s\n",
      "330:\ttest: 0.4133305\tbest: 0.4193710 (307)\ttotal: 4.66s\tremaining: 9.41s\n",
      "340:\ttest: 0.4090984\tbest: 0.4193710 (307)\ttotal: 4.78s\tremaining: 9.23s\n",
      "350:\ttest: 0.4113411\tbest: 0.4193710 (307)\ttotal: 4.91s\tremaining: 9.07s\n",
      "360:\ttest: 0.4148409\tbest: 0.4193710 (307)\ttotal: 5.03s\tremaining: 8.9s\n",
      "370:\ttest: 0.4153601\tbest: 0.4193710 (307)\ttotal: 5.16s\tremaining: 8.76s\n",
      "380:\ttest: 0.4147780\tbest: 0.4193710 (307)\ttotal: 5.29s\tremaining: 8.59s\n",
      "390:\ttest: 0.4144435\tbest: 0.4193710 (307)\ttotal: 5.41s\tremaining: 8.43s\n",
      "400:\ttest: 0.4144872\tbest: 0.4193710 (307)\ttotal: 5.53s\tremaining: 8.26s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4193709975\n",
      "bestIteration = 307\n",
      "\n",
      "Shrink model to first 308 iterations.\n",
      "Model fit: num_trees = 308 elapsed = 5.794\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: num_trees = {model.tree_count_} elapsed = {elapsed:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913ae1-7037-453f-9a12-e1b4666d1bf3",
   "metadata": {},
   "source": [
    "Видим, что модель состоит из 308 деревьев, и лучший скор NDCG@10 на тесте равен **0.419**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b40b16-abdf-4ad7-a452-daf875366e76",
   "metadata": {},
   "source": [
    "При желании, мы теперь можем сохранить модель в формате cbm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd4b6fac-7747-4dd4-93d6-c035a8e7a299",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd1 in position 10: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/model.cbm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# model = catboost.CatBoost()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# model.load_model(model_file)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Hobby\\vk-msu-ir-course-spring-2024\\.venvs\\7\\Lib\\site-packages\\catboost\\core.py:3409\u001b[0m, in \u001b[0;36mCatBoost.save_model\u001b[1;34m(self, fname, format, export_parameters, pool)\u001b[0m\n\u001b[0;32m   3402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, Pool):\n\u001b[0;32m   3403\u001b[0m     pool \u001b[38;5;241m=\u001b[39m Pool(\n\u001b[0;32m   3404\u001b[0m         data\u001b[38;5;241m=\u001b[39mpool,\n\u001b[0;32m   3405\u001b[0m         cat_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cat_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3406\u001b[0m         text_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_text_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3407\u001b[0m         embedding_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3408\u001b[0m     )\n\u001b[1;32m-> 3409\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Hobby\\vk-msu-ir-course-spring-2024\\.venvs\\7\\Lib\\site-packages\\catboost\\core.py:1893\u001b[0m, in \u001b[0;36m_CatBoostBase._save_model\u001b[1;34m(self, output_file, format, export_parameters, pool)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m export_parameters:\n\u001b[0;32m   1891\u001b[0m     params_string \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(export_parameters, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m_NumpyAwareEncoder)\n\u001b[1;32m-> 1893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_catboost.pyx:5210\u001b[0m, in \u001b[0;36m_catboost._CatBoost._save_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5222\u001b[0m, in \u001b[0;36m_catboost._CatBoost._save_model\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd1 in position 10: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "model_file = \"/tmp/model.cbm\"\n",
    "\n",
    "# Save model\n",
    "model.save_model(model_file)\n",
    "\n",
    "# Load model\n",
    "# model = catboost.CatBoost()\n",
    "# model.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89c7a-0987-4831-98f1-989f75240acf",
   "metadata": {},
   "source": [
    "Получим предикты модели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e00327b-7005-44dc-990f-bc9ec5573368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: y_hat_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = model.predict(pool_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric = NDCG:top=10;type=Exp score = 0.419\n",
      "metric = DCG:top=10;type=Exp score = 8.600\n",
      "metric = MAP:top=10 score = 0.524\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp', 'DCG:top=10;type=Exp', 'MAP:top=10']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6fd2e-a19e-492b-aec1-d8824184f980",
   "metadata": {},
   "source": [
    "Мы видим, что значение NDCG@10 на тесте совпало с тем, что вывел сам катбуст во время обучения модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e160-40b5-4609-a01e-c1c0613fc175",
   "metadata": {},
   "source": [
    "## Обучаем YetiRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48a3c-095c-4db0-8d49-8ed7fd488625",
   "metadata": {},
   "source": [
    "Теперь проделаем все то же самое, но на этот раз с использованием алгоритма YetiRank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce16b132-99ce-499b-bcdd-539d67008f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.2873437\tbest: 0.2873437 (0)\ttotal: 35.1ms\tremaining: 35.1s\n",
      "10:\ttest: 0.3811494\tbest: 0.3828752 (9)\ttotal: 269ms\tremaining: 24.2s\n",
      "20:\ttest: 0.3886236\tbest: 0.3914324 (15)\ttotal: 490ms\tremaining: 22.8s\n",
      "30:\ttest: 0.3891378\tbest: 0.3914324 (15)\ttotal: 711ms\tremaining: 22.2s\n",
      "40:\ttest: 0.3946586\tbest: 0.3954174 (34)\ttotal: 930ms\tremaining: 21.8s\n",
      "50:\ttest: 0.4024181\tbest: 0.4024181 (50)\ttotal: 1.16s\tremaining: 21.5s\n",
      "60:\ttest: 0.4049030\tbest: 0.4049030 (60)\ttotal: 1.38s\tremaining: 21.2s\n",
      "70:\ttest: 0.4146104\tbest: 0.4151574 (69)\ttotal: 1.6s\tremaining: 21s\n",
      "80:\ttest: 0.4153313\tbest: 0.4167823 (73)\ttotal: 1.82s\tremaining: 20.7s\n",
      "90:\ttest: 0.4221178\tbest: 0.4221178 (90)\ttotal: 2.08s\tremaining: 20.8s\n",
      "100:\ttest: 0.4244372\tbest: 0.4253389 (96)\ttotal: 2.38s\tremaining: 21.2s\n",
      "110:\ttest: 0.4244111\tbest: 0.4262510 (102)\ttotal: 2.62s\tremaining: 21s\n",
      "120:\ttest: 0.4231627\tbest: 0.4273284 (117)\ttotal: 2.83s\tremaining: 20.6s\n",
      "130:\ttest: 0.4235735\tbest: 0.4273284 (117)\ttotal: 3.07s\tremaining: 20.3s\n",
      "140:\ttest: 0.4290479\tbest: 0.4290479 (140)\ttotal: 3.29s\tremaining: 20s\n",
      "150:\ttest: 0.4259348\tbest: 0.4292489 (142)\ttotal: 3.52s\tremaining: 19.8s\n",
      "160:\ttest: 0.4298337\tbest: 0.4298337 (160)\ttotal: 3.76s\tremaining: 19.6s\n",
      "170:\ttest: 0.4291537\tbest: 0.4298337 (160)\ttotal: 4.04s\tremaining: 19.6s\n",
      "180:\ttest: 0.4284904\tbest: 0.4298337 (160)\ttotal: 4.26s\tremaining: 19.3s\n",
      "190:\ttest: 0.4326139\tbest: 0.4326139 (190)\ttotal: 4.49s\tremaining: 19s\n",
      "200:\ttest: 0.4382603\tbest: 0.4382603 (200)\ttotal: 4.7s\tremaining: 18.7s\n",
      "210:\ttest: 0.4329245\tbest: 0.4382603 (200)\ttotal: 4.96s\tremaining: 18.5s\n",
      "220:\ttest: 0.4302271\tbest: 0.4382603 (200)\ttotal: 5.18s\tremaining: 18.2s\n",
      "230:\ttest: 0.4323059\tbest: 0.4382603 (200)\ttotal: 5.41s\tremaining: 18s\n",
      "240:\ttest: 0.4314998\tbest: 0.4382603 (200)\ttotal: 5.63s\tremaining: 17.7s\n",
      "250:\ttest: 0.4352094\tbest: 0.4390531 (246)\ttotal: 5.86s\tremaining: 17.5s\n",
      "260:\ttest: 0.4329797\tbest: 0.4390531 (246)\ttotal: 6.14s\tremaining: 17.4s\n",
      "270:\ttest: 0.4392437\tbest: 0.4392437 (270)\ttotal: 6.36s\tremaining: 17.1s\n",
      "280:\ttest: 0.4365695\tbest: 0.4392437 (270)\ttotal: 6.58s\tremaining: 16.8s\n",
      "290:\ttest: 0.4337799\tbest: 0.4392437 (270)\ttotal: 6.8s\tremaining: 16.6s\n",
      "300:\ttest: 0.4288542\tbest: 0.4392437 (270)\ttotal: 7.03s\tremaining: 16.3s\n",
      "310:\ttest: 0.4302285\tbest: 0.4392437 (270)\ttotal: 7.25s\tremaining: 16.1s\n",
      "320:\ttest: 0.4311300\tbest: 0.4392437 (270)\ttotal: 7.47s\tremaining: 15.8s\n",
      "330:\ttest: 0.4317181\tbest: 0.4392437 (270)\ttotal: 7.7s\tremaining: 15.6s\n",
      "340:\ttest: 0.4305578\tbest: 0.4392437 (270)\ttotal: 7.94s\tremaining: 15.3s\n",
      "350:\ttest: 0.4251084\tbest: 0.4392437 (270)\ttotal: 8.22s\tremaining: 15.2s\n",
      "360:\ttest: 0.4262432\tbest: 0.4392437 (270)\ttotal: 8.43s\tremaining: 14.9s\n",
      "370:\ttest: 0.4300689\tbest: 0.4392437 (270)\ttotal: 8.66s\tremaining: 14.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.4392437097\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "Model fit: elapsed = 8.829 num_trees = 271\n",
      "Predicted: y_hat_test.shape = (10000,)\n",
      "\n",
      "Evaluated:\n",
      "metric = NDCG:top=10;type=Exp score = 0.439\n",
      "metric = DCG:top=10;type=Exp score = 8.951\n",
      "metric = MAP:top=10 score = 0.541\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = create_model('YetiRank')\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(pool_train, eval_set=pool_test, use_best_model=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f} num_trees = {model.tree_count_}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(pool_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nEvaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Видно, что теперь модель обучается значительно дольше.\n",
    "\n",
    "Сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = **0.419**\n",
    "- а YetiRank выбивает уже NDCG@10 = **0.439**!\n",
    "\n",
    "Таким образом мы наглядно видим преимущество pairwise/listwise-подхода над \"наивным\" pointwise-подходом."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
