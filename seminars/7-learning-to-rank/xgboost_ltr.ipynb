{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02e2af1-998e-4b33-8220-62270916d947",
   "metadata": {},
   "source": [
    "# Машинное обучение ранжированию с помощью библиотеки XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d0fd7-e327-4713-847c-3dfe4b2dba1d",
   "metadata": {},
   "source": [
    "В этом примере мы:\n",
    "\n",
    "- познакомимся с библиотекой **XGBoost**\n",
    "- научимся решать задачу машинного обучения ранжирования используя алгоритмы, реализованные в **XGBoost**\n",
    "\n",
    "Будем использовать стандартный датасет [MSLR](https://www.microsoft.com/en-us/research/project/mslr/)\n",
    "\n",
    "Подробности про формат датасета можно найти в соседнем тюториале *catboost_ltr.ipynb* по машинному обучению ранжированию с помощью библиотеки **CatBoost**, предполагаем что мы его уже прошли."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ecb13-3efd-4a4b-8e1b-9527e993d2fc",
   "metadata": {},
   "source": [
    "## Библиотека XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786f8ea-2175-40ac-8bdf-f2bd1c346444",
   "metadata": {},
   "source": [
    "Полезные ссылки:\n",
    "- Вся документация: https://xgboost.readthedocs.io/en/stable/\n",
    "- Тюториал по learning to rank: https://xgboost.readthedocs.io/en/latest/tutorials/learning_to_rank.html\n",
    "- Полноценный пример: https://xgboost.readthedocs.io/en/latest/python/examples/learning_to_rank.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db45aa-1306-4dc6-ace5-c34e973cc171",
   "metadata": {},
   "source": [
    "## Пререквизиты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5045e6-040a-4863-a095-46cf2cfc1813",
   "metadata": {},
   "source": [
    "Импортируем все что нам понадобится для дальнейшей работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1626b56-ac20-486e-90dc-087240c96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import xgboost as xgb\n",
    "# We'll use catboost to download dataset and to compute metrics\n",
    "from catboost import datasets, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0470ece-0248-41bd-8ac9-971730df1a6d",
   "metadata": {},
   "source": [
    "## Датасет MSLR (Microsoft Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393310a-8f54-4eb4-9fb5-ab2775f28799",
   "metadata": {},
   "source": [
    "Загрузим встроенный в катбуст сабсет датасета MSLR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61225ba7-5615-4e17-93e3-cbf592d3e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = datasets.msrank_10k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef0d21-056f-42d8-a007-966444ab0996",
   "metadata": {},
   "source": [
    "Для удобства присвоим колонкам говорящие имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027e3c18-6103-4914-a872-cbc7879fce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_column_names(num_features):\n",
    "    \"\"\"Generates column names for LETOR-like datasets\"\"\"\n",
    "    columns = ['label', 'qid']\n",
    "    for i in range(num_features):\n",
    "        column = f\"feature_{i+1}\"\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "# Assign column names\n",
    "columns = generate_column_names(num_features=136)\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7cb1b-4ad1-438f-b6d8-fd1676c34683",
   "metadata": {},
   "source": [
    "Теперь наши данные выглядят красивее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916f781c-8850-4dae-b619-cdc7ac0cc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  qid  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    2.0    1          3          3          0          0          3   \n",
      "1    2.0    1          3          0          3          0          3   \n",
      "2    0.0    1          3          0          2          0          3   \n",
      "3    2.0    1          3          0          3          0          3   \n",
      "4    1.0    1          3          0          3          0          3   \n",
      "\n",
      "   feature_6  feature_7  feature_8  ...  feature_127  feature_128  \\\n",
      "0        1.0        1.0   0.000000  ...           62     11089534   \n",
      "1        1.0        0.0   1.000000  ...           54     11089534   \n",
      "2        1.0        0.0   0.666667  ...           45            3   \n",
      "3        1.0        0.0   1.000000  ...           56     11089534   \n",
      "4        1.0        0.0   1.000000  ...           64            5   \n",
      "\n",
      "   feature_129  feature_130  feature_131  feature_132  feature_133  \\\n",
      "0            2          116        64034           13            3   \n",
      "1            2          124        64034            1            2   \n",
      "2            1          124         3344           14           67   \n",
      "3           13          123        63933            1            3   \n",
      "4            7          256        49697            1           13   \n",
      "\n",
      "   feature_134  feature_135  feature_136  \n",
      "0            0            0          0.0  \n",
      "1            0            0          0.0  \n",
      "2            0            0          0.0  \n",
      "3            0            0          0.0  \n",
      "4            0            0          0.0  \n",
      "\n",
      "[5 rows x 138 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1545d-0999-4bb2-9d72-9cd9b10fb9fc",
   "metadata": {},
   "source": [
    "Всего у нас:\n",
    "\n",
    "- 87 запросов и 10000 документов в трейне\n",
    "- 88 запросов и 10000 документов в тесте\n",
    "- 130 колонок: таргет (оценка асессора), ID запроса (qid) и вектор из 128 фичей\n",
    "- таргет принимает значения в интервале \\[0,4\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fddaa-d7ba-453a-aa5f-5bc834be9951",
   "metadata": {},
   "source": [
    "Теперь нам надо представить датасет в формате, который можно подавать на вход модели xgboost.\n",
    "\n",
    "По полной аналогии с тем как мы это делали для catboost, придется разделить его на 3 части:\n",
    "\n",
    "- **y** -- вектор таргетов\n",
    "- **X** -- тензор из фичей\n",
    "- **q** -- вектор из ID запросов, которые позволяют сгруппировать все документы, которые относятся к одному и тому же запросу\n",
    "\n",
    "Заметим, что xgboost, в отличие от catboost, требует строгой отсортированности по ID запроса. Однако в данном случае нам повезло и датасет уже и так отсортирован по qid.\n",
    "\n",
    "Убедимся в этом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e672a4fc-7cf6-4ee5-a598-286dde967d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(df_train['qid'].is_monotonic_increasing)\n",
    "print(df_test['qid'].is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70885edf-16c5-4e99-b376-61e72e1b2b93",
   "metadata": {},
   "source": [
    "Сконвертируем датасет в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f15870f-9459-48d7-a69d-5cd26c23f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_xgboost_dataset(df):\n",
    "    y = df['label'].to_numpy()                       # Label: [0-4]\n",
    "    q = df['qid'].to_numpy().astype('uint32')        # Query Id\n",
    "    X = df.drop(columns=['label', 'qid']).to_numpy() # 136 features\n",
    "    return (X, y, q)\n",
    "\n",
    "X_train, y_train, q_train = to_xgboost_dataset(df_train)\n",
    "X_test, y_test, q_test = to_xgboost_dataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae868e-319b-4070-adfb-ecce7ae94205",
   "metadata": {},
   "source": [
    "## Обучаем pointwise модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2cf9a4-0c23-4d99-bc92-7cf08a8bf37f",
   "metadata": {},
   "source": [
    "Теперь можно приступить непосредственно к обучению модели. Мы начнем с простой pointwise модели которая в качестве лосса использует обычное RMSE.\n",
    "\n",
    "Количество деревьев будем выбирать автоматически с использованием т.н. early stopping -- процесс обучения будем остановлен после того, как на валидационном множестве перестанет расти наша целевая метрика.  \n",
    "В качестве целевой метрики, в отличие от примера с catboost, будем использовать не NDCG@10 а RMSE т.к. *XGBRegressor* не имеет информации о группах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0534f6-713f-4fa1-83c6-5d20104c1495",
   "metadata": {},
   "source": [
    "Создадим объект модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22758401-b1aa-4eee-a6d5-2dfc257ec7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,             # maximum possible number of trees\n",
    "    objective='reg:squarederror',  # RMSE\n",
    "    eval_metric=['rmse'],          # metric used for early stopping\n",
    "    early_stopping_rounds=10,      # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9414a4-c51b-41f1-8d7f-e7eb3fca9446",
   "metadata": {},
   "source": [
    "И зафитим ее на нашем обучающем множестве.  \n",
    "Т.к. мы используем early stopping то передадим в функцию fit() в качестве валидационного множества (параметр eval_set) наш тест-сет (строго говоря так делать нельзя, но мы в данном примере не стремимся к строгости, подробнее этот момент расписан в тюториале про машинное обучение ранжированию с помощью catboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f093276-08d9-462a-af6a-39a7e6fd0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.77005\n",
      "[1]\tvalidation_0-rmse:0.75590\n",
      "[2]\tvalidation_0-rmse:0.74978\n",
      "[3]\tvalidation_0-rmse:0.74625\n",
      "[4]\tvalidation_0-rmse:0.74403\n",
      "[5]\tvalidation_0-rmse:0.74302\n",
      "[6]\tvalidation_0-rmse:0.74237\n",
      "[7]\tvalidation_0-rmse:0.74230\n",
      "[8]\tvalidation_0-rmse:0.74380\n",
      "[9]\tvalidation_0-rmse:0.74397\n",
      "[10]\tvalidation_0-rmse:0.74430\n",
      "[11]\tvalidation_0-rmse:0.74684\n",
      "[12]\tvalidation_0-rmse:0.74729\n",
      "[13]\tvalidation_0-rmse:0.74711\n",
      "[14]\tvalidation_0-rmse:0.74812\n",
      "[15]\tvalidation_0-rmse:0.74948\n",
      "[16]\tvalidation_0-rmse:0.75021\n",
      "[17]\tvalidation_0-rmse:0.75092\n",
      "Model fit: elapsed = 0.528\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913ae1-7037-453f-9a12-e1b4666d1bf3",
   "metadata": {},
   "source": [
    "Посмотрим, сколько деревьев содержит модель. Это немного сложнее чем было с катбустом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a0b61d-0cc6-4671-97f5-5c2fe55f81a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: num_trees = 18 best_iteration = 7 best_score = 0.742\n"
     ]
    }
   ],
   "source": [
    "num_trees = len(model.get_booster().get_dump())\n",
    "print(f\"Model params: num_trees = {num_trees} best_iteration = {model.best_iteration} best_score = {model.best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52632b78-fe55-4d29-8ad9-6d372d74fe97",
   "metadata": {},
   "source": [
    "Видно, что всего модель содержит 18 деревьев, но лучший скор на валидации достигается уже после применения 7 из них.  \n",
    "Поэтому на этапе инференса будет использоваться всего 7 деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b40b16-abdf-4ad7-a452-daf875366e76",
   "metadata": {},
   "source": [
    "При желании, мы можем сохранить эту модель в формате json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4b6fac-7747-4dd4-93d6-c035a8e7a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/tmp/model.xgb.json\"\n",
    "\n",
    "# Save model\n",
    "model.save_model(model_file)\n",
    "\n",
    "# Load model\n",
    "# model = xgb.XGBRegressor()\n",
    "# model.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb89c7a-0987-4831-98f1-989f75240acf",
   "metadata": {},
   "source": [
    "Получим предикты модели на тестовом множестве:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e00327b-7005-44dc-990f-bc9ec5573368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: y_hat_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = model.predict(X_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a2f92-6d18-45b8-8a38-d8ca5c3238b1",
   "metadata": {},
   "source": [
    "Теперь, имея предикты, можно посчитать метрики качества, тут для удобства и единообразия будем использовать catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe53d6fb-d8a0-4e9b-8f8f-48977a5dcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric = NDCG:top=10;type=Exp score = 0.383\n",
      "metric = DCG:top=10;type=Exp score = 7.725\n",
      "metric = MAP:top=10 score = 0.487\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_hat, q):\n",
    "    # List of metrics to evaluate\n",
    "    eval_metrics = ['NDCG:top=10;type=Exp', 'DCG:top=10;type=Exp', 'MAP:top=10']\n",
    "    \n",
    "    for eval_metric in eval_metrics:\n",
    "        scores = utils.eval_metric(y_true, y_hat, eval_metric, group_id=q)\n",
    "    \n",
    "        # Print scores\n",
    "        print(f\"metric = {eval_metric} score = {scores[0]:.3f}\")\n",
    "    \n",
    "# Compute metrics on test\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6fd2e-a19e-492b-aec1-d8824184f980",
   "metadata": {},
   "source": [
    "Видим, что значение NDCG на тесте получилось значительно хуже, чем у катбуста (но, при желании, можно сделать сильно лучше если потюнить параметры модели)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e160-40b5-4609-a01e-c1c0613fc175",
   "metadata": {},
   "source": [
    "## Обучаем pairwise модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f48a3c-095c-4db0-8d49-8ed7fd488625",
   "metadata": {},
   "source": [
    "Теперь проделаем все то же самое, но с использованием алгоритма RankNet.  \n",
    "\n",
    "Для этого вместо *XGBRegressor* будем использовать класс *XGBRanker*, которому в качестве objective передадим 'rank:pairwise'.  \n",
    "\n",
    "Также, теперь мы:\n",
    "\n",
    "- должны передавать в метод fit() наш вектор **q**, чтобы модель могла сгруппировать документы по запросу\n",
    "- в качестве целевой метрики для early stopping можно использовать NDCG@10 а не RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce16b132-99ce-499b-bcdd-539d67008f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-ndcg@10:0.32002\n",
      "[1]\tvalidation_0-ndcg@10:0.32549\n",
      "[2]\tvalidation_0-ndcg@10:0.36129\n",
      "[3]\tvalidation_0-ndcg@10:0.35295\n",
      "[4]\tvalidation_0-ndcg@10:0.35903\n",
      "[5]\tvalidation_0-ndcg@10:0.36624\n",
      "[6]\tvalidation_0-ndcg@10:0.35605\n",
      "[7]\tvalidation_0-ndcg@10:0.36034\n",
      "[8]\tvalidation_0-ndcg@10:0.36515\n",
      "[9]\tvalidation_0-ndcg@10:0.36406\n",
      "[10]\tvalidation_0-ndcg@10:0.36592\n",
      "[11]\tvalidation_0-ndcg@10:0.37081\n",
      "[12]\tvalidation_0-ndcg@10:0.37719\n",
      "[13]\tvalidation_0-ndcg@10:0.37609\n",
      "[14]\tvalidation_0-ndcg@10:0.37223\n",
      "[15]\tvalidation_0-ndcg@10:0.37988\n",
      "[16]\tvalidation_0-ndcg@10:0.38136\n",
      "[17]\tvalidation_0-ndcg@10:0.38383\n",
      "[18]\tvalidation_0-ndcg@10:0.38399\n",
      "[19]\tvalidation_0-ndcg@10:0.38742\n",
      "[20]\tvalidation_0-ndcg@10:0.38553\n",
      "[21]\tvalidation_0-ndcg@10:0.38148\n",
      "[22]\tvalidation_0-ndcg@10:0.38043\n",
      "[23]\tvalidation_0-ndcg@10:0.37618\n",
      "[24]\tvalidation_0-ndcg@10:0.37409\n",
      "[25]\tvalidation_0-ndcg@10:0.37729\n",
      "[26]\tvalidation_0-ndcg@10:0.36836\n",
      "[27]\tvalidation_0-ndcg@10:0.36914\n",
      "[28]\tvalidation_0-ndcg@10:0.37111\n",
      "Model fit: elapsed = 0.760 num_trees = 19\n",
      "Predicted: y_hat_test.shape = (10000,)\n",
      "\n",
      "Evaluated:\n",
      "metric = NDCG:top=10;type=Exp score = 0.387\n",
      "metric = DCG:top=10;type=Exp score = 7.780\n",
      "metric = MAP:top=10 score = 0.503\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = xgb.XGBRanker(\n",
    "    n_estimators=1000,          # maximum possible number of trees\n",
    "    objective='rank:pairwise',  # RankNet objective\n",
    "    eval_metric=[\"ndcg@10\"],    # metric used for early stopping\n",
    "    early_stopping_rounds=10,   # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, qid=q_train, eval_set=[(X_test, y_test)], eval_qid=[q_test], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f} num_trees = {model.best_iteration}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(X_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nEvaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d6c3-80d6-4a6a-ab23-f67b70fc883f",
   "metadata": {},
   "source": [
    "Сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = **0.383**\n",
    "- а RankNet выбивает уже NDCG@10 = **0.387**\n",
    "\n",
    "Мы опять видим (совсем небольшое) преимущество listwise-подхода над \"наивным\" pointwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f624da-ba38-4179-94ba-d94f0ee43567",
   "metadata": {},
   "source": [
    "И, наконец, попробуем полноценный LambdaRank, для этого:\n",
    "\n",
    "- в качестве objective будем использовать значение 'rank:ndcg'\n",
    "- будем использовать дополнительные параметры lambdarank_pair_method и lambdarank_num_pair_per_sample (про них можно почитать в [документации](https://xgboost.readthedocs.io/en/latest/tutorials/learning_to_rank.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d1e723-de86-463d-9a95-e882ea94c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-ndcg@10:0.27110\n",
      "[1]\tvalidation_0-ndcg@10:0.34484\n",
      "[2]\tvalidation_0-ndcg@10:0.35342\n",
      "[3]\tvalidation_0-ndcg@10:0.36961\n",
      "[4]\tvalidation_0-ndcg@10:0.37509\n",
      "[5]\tvalidation_0-ndcg@10:0.38522\n",
      "[6]\tvalidation_0-ndcg@10:0.39158\n",
      "[7]\tvalidation_0-ndcg@10:0.39954\n",
      "[8]\tvalidation_0-ndcg@10:0.39468\n",
      "[9]\tvalidation_0-ndcg@10:0.39764\n",
      "[10]\tvalidation_0-ndcg@10:0.39399\n",
      "[11]\tvalidation_0-ndcg@10:0.39063\n",
      "[12]\tvalidation_0-ndcg@10:0.39061\n",
      "[13]\tvalidation_0-ndcg@10:0.39648\n",
      "[14]\tvalidation_0-ndcg@10:0.40214\n",
      "[15]\tvalidation_0-ndcg@10:0.40002\n",
      "[16]\tvalidation_0-ndcg@10:0.39901\n",
      "[17]\tvalidation_0-ndcg@10:0.39175\n",
      "[18]\tvalidation_0-ndcg@10:0.40457\n",
      "[19]\tvalidation_0-ndcg@10:0.40528\n",
      "[20]\tvalidation_0-ndcg@10:0.40556\n",
      "[21]\tvalidation_0-ndcg@10:0.41136\n",
      "[22]\tvalidation_0-ndcg@10:0.41160\n",
      "[23]\tvalidation_0-ndcg@10:0.41619\n",
      "[24]\tvalidation_0-ndcg@10:0.41421\n",
      "[25]\tvalidation_0-ndcg@10:0.40828\n",
      "[26]\tvalidation_0-ndcg@10:0.40973\n",
      "[27]\tvalidation_0-ndcg@10:0.41216\n",
      "[28]\tvalidation_0-ndcg@10:0.40768\n",
      "[29]\tvalidation_0-ndcg@10:0.40729\n",
      "[30]\tvalidation_0-ndcg@10:0.41440\n",
      "[31]\tvalidation_0-ndcg@10:0.41058\n",
      "[32]\tvalidation_0-ndcg@10:0.41169\n",
      "Model fit: elapsed = 0.773 num_trees = 23\n",
      "Predicted: y_hat_test.shape = (10000,)\n",
      "\n",
      "Evaluated:\n",
      "metric = NDCG:top=10;type=Exp score = 0.416\n",
      "metric = DCG:top=10;type=Exp score = 8.445\n",
      "metric = MAP:top=10 score = 0.518\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = xgb.XGBRanker(\n",
    "    n_estimators=1000,          # maximum possible number of trees\n",
    "    objective='rank:ndcg',      # LambdaRank objective\n",
    "    lambdarank_pair_method='topk',\n",
    "    lambdarank_num_pair_per_sample=20,\n",
    "    eval_metric=[\"ndcg@10\"],    # metric used for early stopping\n",
    "    early_stopping_rounds=10,   # stop if eval_metric does not improve for N rounds\n",
    "    random_state=22,\n",
    ")\n",
    "\n",
    "# Fit\n",
    "start = timer()\n",
    "model.fit(X_train, y_train, qid=q_train, eval_set=[(X_test, y_test)], eval_qid=[q_test], verbose=True)\n",
    "elapsed = timer() - start\n",
    "print(f\"Model fit: elapsed = {elapsed:.3f} num_trees = {model.best_iteration}\")\n",
    "\n",
    "# Predict\n",
    "y_hat_test = model.predict(X_test)\n",
    "print(f\"Predicted: y_hat_test.shape = {y_hat_test.shape}\")\n",
    "\n",
    "# Compute metrics on test\n",
    "print(\"\\nEvaluated:\")\n",
    "compute_metrics(y_test, y_hat_test, q_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806742a-7f08-4cec-a3a7-dd082097bef4",
   "metadata": {},
   "source": [
    "Еще раз сравним результаты:\n",
    "\n",
    "- RMSE модель выбила NDCG@10 = **0.383**\n",
    "- RankNet выбивает уже NDCG@10 = **0.387**\n",
    "- LambdaRank гораздо лучше всех и выбивает **0.416**\n",
    "\n",
    "Однако, обратим внимание, что, несмотря на то, что pairwise подходы опять победили, абсолютные значения NDCG@10 даже у LambdaRank хуже того, что выбивала простая регрессия в catboost (**0.419**), не говоря уже от YetiRank!\n",
    "\n",
    "Видно, что \"из коробки\" catboost показывает результаты значительно лучше, чем xgboost.  \n",
    "Справедливости ради заметим, что мы в наших примерах совсем не пытались тюнить гиперпараметры -- если это проделать, то из xgboost можно \"выжать\" скоры значительно выше.  \n",
    "Тем не менее, по нашему опыту, на данный момент catboost действительно является лучшим инструментом для решения задачи ранжирования."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
