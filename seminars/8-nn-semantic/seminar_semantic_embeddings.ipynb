{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8af9e95",
   "metadata": {},
   "source": [
    "## Семинар: Нейросетевые модели поиска. Часть I.\n",
    "\n",
    "\n",
    "В этом семинаре мы изучим библиотеку [gensim](https://radimrehurek.com/gensim/auto_examples/index.html#documentation) для получения эмбеддингов слов и попробуем использовать их для обучения DSSM.\n",
    "\n",
    "### Работа с gensim\n",
    "\n",
    "Скачаем датасет MS MARCO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c27300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from datasets import load_dataset\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8192806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_dataset = load_dataset(\"Tevatron/msmarco-passage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792aa834",
   "metadata": {},
   "source": [
    "Считаем датасет и сконвертируем в удобный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee2df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_pandas(dataset):\n",
    "    rows = []\n",
    "    for i, row in tqdm(enumerate(dataset)):\n",
    "        current_row = []\n",
    "        for pos_sample in row['positive_passages']:\n",
    "            current_row = []\n",
    "            current_row.append(i) # qid\n",
    "            current_row.append(row['query']) # query\n",
    "            current_row.append(pos_sample['text']) # text\n",
    "            current_row.append(1.) # label\n",
    "            rows.append(current_row)\n",
    "\n",
    "        for neg_sample in row['negative_passages']:\n",
    "            current_row = []\n",
    "            current_row.append(i) # qid\n",
    "            current_row.append(row['query']) # query\n",
    "            current_row.append(neg_sample['text']) # text\n",
    "            current_row.append(0.) # label\n",
    "            rows.append(current_row)\n",
    "    print(len(rows))\n",
    "\n",
    "    return pd.DataFrame(rows, columns=['qid', 'query', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82161817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8297add86f4bc39a30f3419e4dd07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12346948\n"
     ]
    }
   ],
   "source": [
    "data = dataset_pandas(msmarco_dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8dd2b",
   "metadata": {},
   "source": [
    "Разделим датасет на train / val / test. Разделяем с группировкой по сессиям (запросам)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb16dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 400_000\n",
    "TEST_SIZE=3_000\n",
    "\n",
    "test_data = data[(DATASET_SIZE  - TEST_SIZE < data['qid']) & (data['qid'] <= DATASET_SIZE)]\n",
    "val_data = data[(DATASET_SIZE - 2 * TEST_SIZE < data['qid']) & (data['qid'] <= DATASET_SIZE - TEST_SIZE)]\n",
    "train_data = data[data['qid'] <= DATASET_SIZE - 2 * TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb801aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>Whitemarsh Island, Georgia. Whitemarsh Island ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>the strategy of island hopping was used by the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>For the island near Dunedin, see White Island,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>Jekyll Island, at 5,700 acres, is the smallest...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>Sibu Island. A scuba diver at Sibu Island. Sib...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                       query  \\\n",
       "0    0  where is whitemarsh island   \n",
       "1    0  where is whitemarsh island   \n",
       "2    0  where is whitemarsh island   \n",
       "3    0  where is whitemarsh island   \n",
       "4    0  where is whitemarsh island   \n",
       "\n",
       "                                                text  label  \n",
       "0  Whitemarsh Island, Georgia. Whitemarsh Island ...    1.0  \n",
       "1  the strategy of island hopping was used by the...    0.0  \n",
       "2  For the island near Dunedin, see White Island,...    0.0  \n",
       "3  Jekyll Island, at 5,700 acres, is the smallest...    0.0  \n",
       "4  Sibu Island. A scuba diver at Sibu Island. Sib...    0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d5d85",
   "metadata": {},
   "source": [
    "Используя библиотеку gensim, получим эмбеддинги для всех запросов и документов.\n",
    "\n",
    "Посмотрим, какие предобученные модели уже есть в gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799515fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "gensim.downloader.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188129fe",
   "metadata": {},
   "source": [
    "Используем fasttext-wiki-news-subwords-300:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f03f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_model = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c09b20",
   "metadata": {},
   "source": [
    "Получим эмбеддинги запросов и документов как среднее значение эмбеддингов токенов в них.\n",
    "\n",
    "Затем, посчитаем метрику MRR@10 и сравним с bm25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab01ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedder_model_predictions(dataset):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "\n",
    "    query_embeddings = np.stack(dataset[\"query\"].apply(lambda text: embedder_model.get_mean_vector(tokenizer.tokenize(text), ignore_missing=True)).values)\n",
    "    query_embeddings = query_embeddings / np.linalg.norm(query_embeddings, axis=-1, keepdims=True)\n",
    "\n",
    "    document_embeddings = np.stack(dataset[\"text\"].apply(lambda text: embedder_model.get_mean_vector(tokenizer.tokenize(text), ignore_missing=True)).values)\n",
    "    document_embeddings = document_embeddings / np.linalg.norm(document_embeddings, axis=-1, keepdims=True)\n",
    "\n",
    "    scores = (query_embeddings * document_embeddings).sum(axis=-1)\n",
    "    return scores\n",
    "\n",
    "embedder_model_predictions = get_embedder_model_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01dadd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca836b4d6e5416b99a7dc9837fb3904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_bm25_model_predictions(dataset):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokenized_corpus = [tokenizer.tokenize(doc) for doc in dataset['text'].values]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    queries = dataset['query'].unique()\n",
    "    bm25_preds = np.zeros(len(test_data))\n",
    "    for query in tqdm(queries):\n",
    "        tokenized_query = tokenizer.tokenize(query)\n",
    "        doc_scores = bm25.get_scores(tokenized_query)\n",
    "        mask = test_data['query'] == query\n",
    "        bm25_preds[mask] = doc_scores[mask]\n",
    "    return bm25_preds\n",
    "\n",
    "bm25_model_predictions = get_bm25_model_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a8f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.retrieval import RetrievalMRR\n",
    "\n",
    "\n",
    "def MRR(preds, target, qids):\n",
    "    mrr = RetrievalMRR(top_k=10)\n",
    "    return mrr(torch.Tensor(preds), torch.Tensor(target),\n",
    "               indexes=torch.LongTensor(qids - min(qids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94e62d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 MRR@10: 0.317946\n",
      "Embeddings MRR@10: 0.207176\n"
     ]
    }
   ],
   "source": [
    "print(f\"BM25 MRR@10: {MRR(bm25_model_predictions, test_data['label'].values, test_data['qid'].values):4f}\")\n",
    "print(f\"Embeddings MRR@10: {MRR(embedder_model_predictions, test_data['label'].values, test_data['qid'].values):4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bcf212",
   "metadata": {},
   "source": [
    "Попробуем нормализовать и смешать предсказания bm25 и эмбеддингов, чтобы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4079c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble MRR@10: 0.319093\n"
     ]
    }
   ],
   "source": [
    "bm25_model_predictions_normed = (bm25_model_predictions - bm25_model_predictions.min()) / (bm25_model_predictions.max() - bm25_model_predictions.min())\n",
    "embedder_model_predictions = (embedder_model_predictions - embedder_model_predictions.min()) / (embedder_model_predictions.max() - embedder_model_predictions.min())\n",
    "\n",
    "merged_predictions = bm25_model_predictions_normed + embedder_model_predictions * 0.01\n",
    "print(f\"Ensamble MRR@10: {MRR(merged_predictions, test_data['label'].values, test_data['qid'].values):4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb1df2",
   "metadata": {},
   "source": [
    "Дальнейшие пути улучшения:\n",
    "* Попробовать усреднять эмбеддинги слов с весами tf-idf;\n",
    "* Перебрать коэффициент усреднения предиктов bm25 и embedder_model;\n",
    "* Сделать нормализацию скоров независимо в рамках каждого запроса;\n",
    "* Использовать другие методы ансамблирования моделей ранжирования."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
